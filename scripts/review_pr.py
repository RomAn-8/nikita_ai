#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–≤—å—é Pull Request —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG –∏ MCP.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/review_pr.py <owner> <repo> <pr_number> <github_token>

–ü—Ä–∏–º–µ—Ä:
    python scripts/review_pr.py RomAn-8 nikita_ai 123 $GITHUB_TOKEN
"""

import asyncio
import json
import logging
import os
import re
import sys
from pathlib import Path
from typing import Any

import httpx

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π bot
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º config
# –≠—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ GitHub Actions, –≥–¥–µ .env —Ñ–∞–π–ª–∞ –Ω–µ—Ç
# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π TELEGRAM_BOT_TOKEN, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ config
if not os.getenv("TELEGRAM_BOT_TOKEN"):
    os.environ["TELEGRAM_BOT_TOKEN"] = "dummy_token_for_script"

from bot.config import OPENROUTER_API_KEY, OPENROUTER_MODEL, RAG_SIM_THRESHOLD, RAG_TOP_K, EMBEDDING_MODEL
from bot.embeddings import search_relevant_chunks, has_embeddings
from bot.mcp_client import get_pr_diff, get_pr_files, get_pr_info
from bot.openrouter import chat_completion

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def extract_keywords_from_text(text: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è RAG –ø–æ–∏—Å–∫–∞."""
    # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–º–µ—Ç–∫—É
    text = re.sub(r"```[\s\S]*?```", "", text)
    text = re.sub(r"`[^`]+`", "", text)
    text = re.sub(r"#+\s*", "", text)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏–π, –∫–ª–∞—Å—Å–æ–≤, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    patterns = [
        r"def\s+(\w+)",  # —Ñ—É–Ω–∫—Ü–∏–∏
        r"class\s+(\w+)",  # –∫–ª–∞—Å—Å—ã
        r"(\w+)\s*=",  # –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        r"@(\w+)",  # –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
    ]
    
    keywords = set()
    for pattern in patterns:
        matches = re.findall(pattern, text)
        keywords.update(matches)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ)
    words = re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]{2,}\b", text)
    stop_words = {"the", "and", "or", "but", "for", "with", "from", "this", "that", "are", "was", "were", "been", "have", "has", "had", "will", "would", "should", "could", "may", "might", "must", "can"}
    keywords.update(w.lower() for w in words if w.lower() not in stop_words and len(w) > 3)
    
    return " ".join(list(keywords)[:20])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤


async def get_rag_context(pr_info: dict[str, Any], pr_files: list[dict[str, Any]], pr_diff: str) -> str:
    """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç RAG –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
    if not has_embeddings(EMBEDDING_MODEL):
        logger.warning("No embeddings found in database. Skipping RAG context.")
        return ""
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è RAG
    queries = []
    
    # 1. –ü–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏ –æ–ø–∏—Å–∞–Ω–∏—é PR
    if pr_info.get("title"):
        queries.append(pr_info["title"])
    if pr_info.get("body"):
        queries.append(pr_info["body"][:500])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    
    # 2. –ü–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
    file_names = [f.get("filename", "") for f in pr_files]
    if file_names:
        queries.append(" ".join(file_names))
    
    # 3. –ü–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏–∑ diff
    if pr_diff:
        keywords = extract_keywords_from_text(pr_diff[:2000])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if keywords:
            queries.append(keywords)
    
    # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    all_chunks = []
    seen_chunks = set()
    
    for query in queries:
        if not query.strip():
            continue
        
        try:
            chunks = search_relevant_chunks(
                query,
                model=EMBEDDING_MODEL,
                top_k=RAG_TOP_K,
                min_similarity=RAG_SIM_THRESHOLD,
                apply_threshold=True,
            )
            
            for chunk in chunks:
                chunk_key = (chunk["doc_name"], chunk["chunk_index"])
                if chunk_key not in seen_chunks:
                    seen_chunks.add(chunk_key)
                    all_chunks.append(chunk)
        except Exception as e:
            logger.warning(f"Error searching chunks for query '{query[:50]}...': {e}")
            continue
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if not all_chunks:
        return ""
    
    context_parts = ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞:\n"]
    for i, chunk in enumerate(all_chunks[:5], 1):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 —á–∞–Ω–∫–æ–≤
        context_parts.append(f"[–î–æ–∫—É–º–µ–Ω—Ç {i}: {chunk['doc_name']}, —Ñ—Ä–∞–≥–º–µ–Ω—Ç {chunk['chunk_index']}, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å {chunk['similarity']:.3f}]")
        context_parts.append(chunk["text"])
        context_parts.append("")
    
    return "\n".join(context_parts)


def format_pr_files(files: list[dict[str, Any]]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞."""
    if not files:
        return "–ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."
    
    parts = ["–ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:"]
    for file_info in files:
        filename = file_info.get("filename", "unknown")
        status = file_info.get("status", "unknown")
        additions = file_info.get("additions", 0)
        deletions = file_info.get("deletions", 0)
        parts.append(f"- {filename} ({status}): +{additions}/-{deletions}")
    
    return "\n".join(parts)


def create_review_prompt(pr_info: dict[str, Any], pr_files: list[dict[str, Any]], pr_diff: str, rag_context: str) -> list[dict[str, str]]:
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–≤—å—é."""
    
    system_prompt = """–¢—ã - –æ–ø—ã—Ç–Ω—ã–π code reviewer, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç Pull Request –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –ù–∞–π—Ç–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –±–∞–≥–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–¥–∞ —Å—Ç–∏–ª—é –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞
3. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏—è
4. –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
## üîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
- [–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞ –∏ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ]

## üí° –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
- [–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

## ‚ùì –í–æ–ø—Ä–æ—Å—ã
- [–í–æ–ø—Ä–æ—Å—ã –∫ –∞–≤—Ç–æ—Ä—É PR]

## ‚úÖ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
- [–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ —Ö–æ—Ä–æ—à–æ]

–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–º –∏ –≤–µ–∂–ª–∏–≤—ã–º. –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Ç–∞–∫ –∏ –Ω–∞–ø–∏—à–∏."""

    user_parts = []
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PR
    user_parts.append(f"## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PR")
    user_parts.append(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {pr_info.get('title', 'N/A')}")
    user_parts.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {pr_info.get('body', 'N/A')[:500]}")
    user_parts.append(f"–ê–≤—Ç–æ—Ä: {pr_info.get('author', 'N/A')}")
    user_parts.append(f"–í–µ—Ç–∫–∏: {pr_info.get('head_branch', 'N/A')} ‚Üí {pr_info.get('base_branch', 'N/A')}")
    user_parts.append("")
    
    # –§–∞–π–ª—ã
    user_parts.append(format_pr_files(pr_files))
    user_parts.append("")
    
    # RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if rag_context:
        user_parts.append(rag_context)
        user_parts.append("")
    
    # Diff
    user_parts.append("## Diff –∏–∑–º–µ–Ω–µ–Ω–∏–π")
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä diff (GitHub API –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π diff)
    max_diff_length = 15000
    if len(pr_diff) > max_diff_length:
        user_parts.append(f"[Diff –æ–±—Ä–µ–∑–∞–Ω, –ø–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {max_diff_length} —Å–∏–º–≤–æ–ª–æ–≤]")
        pr_diff = pr_diff[:max_diff_length] + "\n... [diff –æ–±—Ä–µ–∑–∞–Ω]"
    user_parts.append("```diff")
    user_parts.append(pr_diff)
    user_parts.append("```")
    
    user_content = "\n".join(user_parts)
    
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content},
    ]


async def post_review_comment(owner: str, repo: str, pr_number: int, github_token: str, review_text: str) -> bool:
    """–ü—É–±–ª–∏–∫—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å —Ä–µ–≤—å—é –≤ PR —á–µ—Ä–µ–∑ GitHub API."""
    url = f"https://api.github.com/repos/{owner}/{repo}/issues/{pr_number}/comments"
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "Authorization": f"token {github_token}",
        "User-Agent": "nikita_ai-review-bot/1.0",
    }
    
    body = {
        "body": review_text,
    }
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, headers=headers, json=body)
            response.raise_for_status()
            logger.info(f"Review comment posted successfully to PR #{pr_number}")
            return True
    except httpx.HTTPStatusError as e:
        logger.error(f"Failed to post comment: {e.response.status_code} - {e.response.text}")
        return False
    except Exception as e:
        logger.error(f"Exception posting comment: {e}")
        return False


async def review_pr(owner: str, repo: str, pr_number: int, github_token: str) -> int:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–≤—å—é PR."""
    logger.info(f"Starting review for PR #{pr_number} in {owner}/{repo}")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ PR —á–µ—Ä–µ–∑ MCP
    logger.info("Fetching PR data via MCP...")
    pr_info = await get_pr_info(owner, repo, pr_number, github_token)
    if not pr_info:
        logger.error("Failed to get PR info via MCP")
        return 1
    
    pr_files = await get_pr_files(owner, repo, pr_number, github_token)
    if pr_files is None:
        logger.error("Failed to get PR files via MCP")
        return 1
    
    pr_diff = await get_pr_diff(owner, repo, pr_number, github_token)
    if not pr_diff:
        logger.error("Failed to get PR diff via MCP")
        return 1
    
    logger.info(f"PR: {pr_info.get('title', 'N/A')}")
    logger.info(f"Files changed: {len(pr_files)}")
    logger.info(f"Diff length: {len(pr_diff)} characters")
    
    # 2. –ü–æ–ª—É—á–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
    logger.info("Searching for relevant documentation via RAG...")
    rag_context = await get_rag_context(pr_info, pr_files, pr_diff)
    if rag_context:
        logger.info("Found relevant documentation via RAG")
    else:
        logger.info("No relevant documentation found via RAG")
    
    # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–≤—å—é —á–µ—Ä–µ–∑ LLM
    logger.info("Generating review via LLM...")
    messages = create_review_prompt(pr_info, pr_files, pr_diff, rag_context)
    
    try:
        review_text = chat_completion(messages, temperature=0.3, model=OPENROUTER_MODEL)
        if not review_text or not review_text.strip():
            logger.error("LLM returned empty review")
            return 1
        
        logger.info(f"Review generated ({len(review_text)} characters)")
    except Exception as e:
        logger.error(f"Error generating review: {e}")
        return 1
    
    # 4. –ü—É–±–ª–∏–∫—É–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –≤ PR
    logger.info("Posting review comment to PR...")
    success = await post_review_comment(owner, repo, pr_number, github_token, review_text)
    
    if success:
        logger.info("Review completed successfully!")
        return 0
    else:
        logger.error("Failed to post review comment")
        return 1


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å–∫—Ä–∏–ø—Ç–∞."""
    if len(sys.argv) != 5:
        print("Usage: python scripts/review_pr.py <owner> <repo> <pr_number> <github_token>")
        sys.exit(1)
    
    owner = sys.argv[1]
    repo = sys.argv[2]
    try:
        pr_number = int(sys.argv[3])
    except ValueError:
        print(f"Error: PR number must be an integer, got: {sys.argv[3]}")
        sys.exit(1)
    github_token = sys.argv[4]
    
    # –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç, –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if not github_token:
        github_token = os.getenv("GB_TOKEN", "").strip() or os.getenv("GITHUB_TOKEN", "").strip()
    
    if not github_token:
        print("Error: GitHub token is required. Set GB_TOKEN or GITHUB_TOKEN environment variable, or pass as 4th argument.")
        sys.exit(1)
    
    exit_code = asyncio.run(review_pr(owner, repo, pr_number, github_token))
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
