# Архитектура проекта nikita_ai

## Общая структура

```
nikita_ai/
├── bot/
│   ├── main.py              # Основной файл бота, обработчики команд
│   ├── config.py            # Конфигурация (API ключи, настройки)
│   ├── embeddings.py        # Модуль для работы с RAG и эмбеддингами
│   ├── openrouter.py        # Клиент для OpenRouter API
│   ├── summarizer.py        # Модуль для сжатия истории (summary mode)
│   ├── mcp_client.py        # Клиент для MCP сервера (git_branch)
│   ├── mcp_weather.py       # MCP клиент для погоды
│   ├── mcp_news.py          # MCP клиент для новостей
│   ├── mcp_docker.py        # MCP клиент для Docker
│   └── bot_memory.sqlite3   # База данных (история, эмбеддинги)
├── docs/                    # Документация проекта
│   ├── code-style.md        # Правила стиля кода
│   ├── code-examples.md     # Примеры кода
│   └── architecture.md      # Этот файл
└── README.md                # Основная документация
```

## Основные компоненты

### 1. Telegram Bot (main.py)

**Ответственность:**
- Обработка команд и сообщений от пользователей
- Управление режимами работы (text, json, summary, rag, etc.)
- Координация работы различных модулей

**Ключевые функции:**
- `on_text()` - обработка текстовых сообщений
- `help_cmd()` - команда /help с RAG
- `rag_model_cmd()` - активация режима RAG
- `embed_create_cmd()` - создание эмбеддингов

### 2. RAG система (embeddings.py)

**Ответственность:**
- Индексация документов (разбиение на чанки, создание эмбеддингов)
- Поиск релевантных фрагментов по запросу пользователя
- Хранение эмбеддингов в базе данных

**Ключевые функции:**
- `process_readme_file()` - обработка одного файла
- `search_relevant_chunks()` - поиск по эмбеддингам
- `split_into_chunks()` - разбиение текста на чанки

**База данных:**
- Таблица `doc_chunks` - хранит чанки документов с эмбеддингами

### 3. MCP интеграция

**Ответственность:**
- Подключение к MCP серверу (python-sdk)
- Вызов MCP инструментов (git_branch, weather, news, docker)

**Модули:**
- `mcp_client.py` - базовый клиент для git_branch
- `mcp_weather.py` - клиент для погоды
- `mcp_news.py` - клиент для новостей
- `mcp_docker.py` - клиент для Docker

**Протокол:**
- Streamable HTTP на `http://127.0.0.1:8000/mcp`

### 4. База данных (bot_memory.sqlite3)

**Таблицы:**
- `chat_history` - история сообщений пользователей
- `chat_settings` - настройки чата (температура, память, модель)
- `summary` - сжатые версии истории для summary mode
- `doc_chunks` - чанки документов с эмбеддингами

## Потоки данных

### Индексация документации

```
Пользователь → /embed_create → отправка .md файла
    ↓
on_document() → скачивание файла
    ↓
process_readme_file() → нормализация → разбиение на чанки
    ↓
generate_embeddings_batch() → OpenRouter API
    ↓
Сохранение в doc_chunks
```

### Поиск через RAG

```
Пользователь → /help <вопрос>
    ↓
search_relevant_chunks() → генерация эмбеддинга запроса
    ↓
Поиск в doc_chunks → вычисление similarity
    ↓
Фильтрация по порогу → формирование контекста
    ↓
LLM запрос → ответ пользователю
```

### Получение git ветки через MCP

```
Пользователь → /help Какая текущая ветка?
    ↓
get_git_branch() → MCP сервер (http://127.0.0.1:8000/mcp)
    ↓
call_tool("git_branch") → python-sdk MCP сервер
    ↓
git branch --show-current → возврат результата
    ↓
Добавление в контекст ответа
```

## Режимы работы

### text
- Обычный режим чата
- Сохранение истории в БД
- Использование памяти (опционально)

### json
- Каждый ответ в формате JSON
- Используется для структурированных данных

### summary
- Сжатие истории через summarizer
- Экономия токенов при длинных диалогах

### rag
- Поиск по эмбеддингам перед ответом
- Три подрежима: с фильтром, без фильтра, без RAG

## Конфигурация

Все настройки в `.env`:
- `TELEGRAM_BOT_TOKEN` - токен бота
- `OPENROUTER_API_KEY` - ключ API
- `OPENROUTER_MODEL` - модель LLM
- `RAG_SIM_THRESHOLD` - порог похожести для RAG
- `RAG_TOP_K` - количество возвращаемых чанков
- `EMBEDDING_MODEL` - модель для эмбеддингов
