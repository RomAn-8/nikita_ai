# –¢–µ—Å—Ç–æ–≤—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è PR

import os
import json
import re
import sqlite3
import logging
import requests
from datetime import datetime, timezone
from pathlib import Path

from telegram import Update, BotCommand
from telegram.error import TimedOut, BadRequest
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from telegram.request import HTTPXRequest

from .config import TELEGRAM_BOT_TOKEN, OPENROUTER_API_KEY, OPENROUTER_MODEL, RAG_SIM_THRESHOLD, RAG_TOP_K, EMBEDDING_MODEL, OLLAMA_BASE_URL, OLLAMA_MODEL, OLLAMA_TIMEOUT, OLLAMA_TEMPERATURE, OLLAMA_NUM_CTX, OLLAMA_NUM_PREDICT, OLLAMA_SYSTEM_PROMPT, ANALYZE_MODEL, ME_MODEL, USER_PROFILE_PATH
from .openrouter import chat_completion, chat_completion_raw
from .tokens_test import tokens_test_cmd, tokens_next_cmd, tokens_stop_cmd, tokens_test_intercept

# NEW: summary-mode
from .summarizer import MODE_SUMMARY, build_messages_with_summary, maybe_compress_history, clear_summary, summary_debug_cmd
from .mcp_weather import get_weather_via_mcp  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–≥–æ–¥—ã
from .mcp_news import get_news_via_mcp  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π
from .mcp_docker import site_up_via_mcp, site_screenshot_via_mcp, site_down_via_mcp  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Docker
from .mcp_client import (
    get_git_branch, get_pr_diff, get_pr_files, get_pr_info,  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è git –≤–µ—Ç–∫–∏ –∏ PR –¥–∞–Ω–Ω—ã—Ö
    user_get, user_register, user_block, user_unblock, user_delete,  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏
    reg_create, reg_find_by_user, reg_reschedule, reg_cancel,  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∑–∞–ø–∏—Å—è–º–∏
    task_create, task_list, task_delete,  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏
    deploy_check_docker, deploy_upload_image, deploy_load_image, deploy_create_compose, deploy_create_env, deploy_start_bot, deploy_check_container, deploy_stop_bot,  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –¥–µ–ø–ª–æ—è
)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ PR –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞
import sys
from pathlib import Path
REVIEW_SCRIPT_PATH = Path(__file__).resolve().parent.parent / "scripts" / "review_pr.py"
if REVIEW_SCRIPT_PATH.exists():
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    if str(PROJECT_ROOT) not in sys.path:
        sys.path.insert(0, str(PROJECT_ROOT))
    try:
        from scripts.review_pr import (
            extract_keywords_from_text,
            get_rag_context as get_rag_context_for_pr,
            format_pr_files,
            create_review_prompt,
        )
        PR_REVIEW_AVAILABLE = True
    except ImportError as e:
        PR_REVIEW_AVAILABLE = False
        logger.warning(f"PR review functions not available: {e}")
else:
    PR_REVIEW_AVAILABLE = False
from .weather_subscription import start_weather_subscription, stop_weather_subscription  # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É
from .embeddings import process_readme_file, process_docs_folder, search_relevant_chunks, has_embeddings, list_indexed_documents, EMBEDDING_MODEL  # –ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏


logger = logging.getLogger(__name__)


def utc_now_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")


def _short_model_name(m: str) -> str:
    m = (m or "").strip()
    if not m:
        return "default"
    return m.split("/")[-1]


def _get_usage_tokens(data: dict) -> tuple[int | None, int | None, int | None]:
    usage = data.get("usage") or {}
    pt = usage.get("prompt_tokens")
    ct = usage.get("completion_tokens")
    tt = usage.get("total_tokens")

    try:
        pt = int(pt) if pt is not None else None
    except Exception:
        pt = None
    try:
        ct = int(ct) if ct is not None else None
    except Exception:
        ct = None
    try:
        tt = int(tt) if tt is not None else None
    except Exception:
        tt = None

    return pt, ct, tt


def _get_content_from_raw(data: dict) -> str:
    try:
        return (((data.get("choices") or [{}])[0].get("message") or {}).get("content") or "").strip()
    except Exception:
        return ""


def _city_prepositional_case(city: str) -> str:
    """
    –°–∫–ª–æ–Ω—è–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –≤ –ø—Ä–µ–¥–ª–æ–∂–Ω—ã–π –ø–∞–¥–µ–∂ (–≥–¥–µ? –≤ —á—ë–º?).
    –ü—Ä–∏–º–µ—Ä—ã: –ú–æ—Å–∫–≤–∞ -> –ú–æ—Å–∫–≤–µ, –°–∞–º–∞—Ä–∞ -> –°–∞–º–∞—Ä–µ, –°–∞—Ä–∞—Ç–æ–≤ -> –°–∞—Ä–∞—Ç–æ–≤–µ, –¢–æ–º—Å–∫ -> –¢–æ–º—Å–∫–µ.
    """
    city = (city or "").strip()
    if not city:
        return city
    
    # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Å–∫–ª–æ–Ω–µ–Ω–∏—è —Ä—É—Å—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –≥–æ—Ä–æ–¥–æ–≤
    city_lower = city.lower()
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "–∞" (–ú–æ—Å–∫–≤–∞, –°–∞–º–∞—Ä–∞, –¢—É–ª–∞) -> "–µ" (–≤ –ú–æ—Å–∫–≤–µ, –≤ –°–∞–º–∞—Ä–µ, –≤ –¢—É–ª–µ)
    if city_lower.endswith("–∞"):
        return city[:-1] + "–µ"
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "–æ" (–¢—É–ª–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    if city_lower.endswith("–æ"):
        return city[:-1] + "–µ"
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "—å" (–¢–≤–µ—Ä—å, –†—è–∑–∞–Ω—å) -> "–∏" (–≤ –¢–≤–µ—Ä–∏, –≤ –†—è–∑–∞–Ω–∏)
    if city_lower.endswith("—å"):
        return city[:-1] + "–∏"
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —Å–æ–≥–ª–∞—Å–Ω—É—é (–°–∞—Ä–∞—Ç–æ–≤, –¢–æ–º—Å–∫, –ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫) -> "–µ" (–≤ –°–∞—Ä–∞—Ç–æ–≤–µ, –≤ –¢–æ–º—Å–∫–µ, –≤ –ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–µ)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –±—É–∫–≤—É
    last_char = city_lower[-1]
    if last_char not in "–∞–µ—ë–∏–æ—É—ã—ç—é—è—å":
        return city + "–µ"
    
    # –ï—Å–ª–∏ –Ω–µ –ø–æ–¥–æ—à–ª–æ –Ω–∏ –æ–¥–Ω–æ –ø—Ä–∞–≤–∏–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    return city


# -------------------- USER PROFILE FUNCTIONS --------------------

def load_user_profile() -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ JSON —Ñ–∞–π–ª–∞. –°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –ø—Ä–æ—Ñ–∏–ª—å, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    try:
        if not USER_PROFILE_PATH.exists():
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ—Ñ–∏–ª—å
            default_profile = {
                "name": "",
                "interests": [],
                "communication_style": "",
                "habits": [],
                "preferences": {}
            }
            save_user_profile(default_profile)
            return default_profile
        
        with open(USER_PROFILE_PATH, "r", encoding="utf-8") as f:
            profile = json.load(f)
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            default_profile = {
                "name": "",
                "interests": [],
                "communication_style": "",
                "habits": [],
                "preferences": {}
            }
            for key in default_profile:
                if key not in profile:
                    profile[key] = default_profile[key]
            return profile
    except json.JSONDecodeError as e:
        logger.error(f"Error parsing user profile JSON: {e}")
        raise ValueError("–ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ñ–∞–π–ª.")
    except Exception as e:
        logger.error(f"Error loading user profile: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–æ—Ñ–∏–ª—è: {e}")


def save_user_profile(profile: dict) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ JSON —Ñ–∞–π–ª."""
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        USER_PROFILE_PATH.parent.mkdir(parents=True, exist_ok=True)
        
        with open(USER_PROFILE_PATH, "w", encoding="utf-8") as f:
            json.dump(profile, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error saving user profile: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è: {e}")


def build_me_system_prompt(profile: dict) -> str:
    """–°–æ–∑–¥–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    profile_text = json.dumps(profile, ensure_ascii=False, indent=2)
    return f"""–¢—ã ‚Äî –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –í–æ—Ç —á—Ç–æ —Ç—ã –æ –Ω–µ–º –∑–Ω–∞–µ—à—å:

{profile_text}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –µ–º—É, –∏—Å—Ö–æ–¥—è –∏–∑ –µ–≥–æ –ø—Ä–∏–≤—ã—á–µ–∫ –∏ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤. –û—Ç–≤–µ—á–∞–π –≤ –µ–≥–æ –ª—é–±–∏–º–æ–º —Å—Ç–∏–ª–µ –æ–±—â–µ–Ω–∏—è."""


def update_profile_from_text(text: str) -> dict:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏–∑–≤–ª–µ–∫–∞—è –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Gemini."""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å
        current_profile = load_user_profile()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Gemini
        profile_structure = json.dumps({
            "name": "",
            "interests": [],
            "communication_style": "",
            "habits": [],
            "preferences": {}
        }, ensure_ascii=False, indent=2)
        
        update_prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –∏–∑ —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏ –≤–µ—Ä–Ω–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π JSON-–ø—Ä–æ—Ñ–∏–ª—å.

–¢–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å:
{json.dumps(current_profile, ensure_ascii=False, indent=2)}

–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{text}

–í–ê–ñ–ù–û:
1. –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è
2. –î–æ–±–∞–≤—å –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
3. –û–±–Ω–æ–≤–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è, –µ—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –µ—Å—Ç—å –±–æ–ª–µ–µ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
4. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
5. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —ç—Ç–æ–π —Å—Ö–µ–º–µ:
{profile_structure}

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON –æ–±—ä–µ–∫—Ç."""
        
        messages = [
            {"role": "user", "content": update_prompt}
        ]
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Gemini —á–µ—Ä–µ–∑ OpenRouter
        response = chat_completion(messages, temperature=0.3, model=ME_MODEL)
        
        if not response:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è")
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–µ—Ä–Ω—É—Ç –≤ markdown –∫–æ–¥ –±–ª–æ–∫–∏)
        response_clean = response.strip()
        
        # –£–¥–∞–ª—è–µ–º markdown –∫–æ–¥ –±–ª–æ–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        if response_clean.startswith("```json"):
            response_clean = response_clean[7:]
        elif response_clean.startswith("```"):
            response_clean = response_clean[3:]
        
        if response_clean.endswith("```"):
            response_clean = response_clean[:-3]
        
        response_clean = response_clean.strip()
        
        # –ü–∞—Ä—Å–∏–º JSON
        try:
            updated_profile = json.loads(response_clean)
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            required_keys = {"name", "interests", "communication_style", "habits", "preferences"}
            if not all(key in updated_profile for key in required_keys):
                raise ValueError("–ü—Ä–æ—Ñ–∏–ª—å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è")
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ interests –∏ habits - —ç—Ç–æ —Å–ø–∏—Å–∫–∏
            if not isinstance(updated_profile.get("interests"), list):
                updated_profile["interests"] = []
            if not isinstance(updated_profile.get("habits"), list):
                updated_profile["habits"] = []
            if not isinstance(updated_profile.get("preferences"), dict):
                updated_profile["preferences"] = {}
            
            return updated_profile
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing JSON from Gemini response: {e}")
            logger.error(f"Response was: {response_clean[:500]}")
            raise ValueError("–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç–µ –ø—Ä–æ—Ñ–∏–ª—å –≤—Ä—É—á–Ω—É—é.")
    except ValueError:
        raise
    except Exception as e:
        logger.error(f"Error updating profile from text: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è: {e}")


# -------------------- TEMPERATURE --------------------

DEFAULT_TEMPERATURE = 0.7
TEMPERATURE_MIN = 0.0
TEMPERATURE_MAX = 2.0

# -------------------- MEMORY SWITCH --------------------

DEFAULT_MEMORY_ENABLED = True  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–∞–º—è—Ç—å –≤–∫–ª—é—á–µ–Ω–∞

# -------------------- MODELS FROM ENV --------------------
# –î–æ–±–∞–≤—å –≤ .env:
# OPENROUTER_MODEL_GLM=z-ai/glm-4.7-flash
# OPENROUTER_MODEL_GEMMA=google/gemma-3-12b-it

MODEL_GLM = (os.getenv("OPENROUTER_MODEL_GLM") or "").strip()
MODEL_GEMMA = (os.getenv("OPENROUTER_MODEL_GEMMA") or "").strip()


# -------------------- SQLITE MEMORY + SETTINGS --------------------

# –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
DB_PATH = Path(os.getenv("DB_PATH", str(Path(__file__).resolve().parent / "bot_memory.sqlite3")))
MEMORY_LIMIT_MESSAGES = 30  # —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è LLM
MEMORY_CHAT_MODES = ("text", "thinking", "experts", "rag")  # –æ–±—â–∞—è –ø–∞–º—è—Ç—å –º–µ–∂–¥—É —ç—Ç–∏–º–∏ —Ä–µ–∂–∏–º–∞–º–∏


def open_db() -> sqlite3.Connection:
    DB_PATH.parent.mkdir(parents=True, exist_ok=True)
    conn = sqlite3.connect(DB_PATH, timeout=30)
    conn.execute("PRAGMA journal_mode=WAL;")
    conn.execute("PRAGMA synchronous=NORMAL;")
    conn.execute("PRAGMA busy_timeout=5000;")
    return conn


def _ensure_column(conn: sqlite3.Connection, table: str, column: str, ddl: str) -> None:
    """
    ddl –ø—Ä–∏–º–µ—Ä: 'ALTER TABLE chat_settings ADD COLUMN memory_enabled INTEGER NOT NULL DEFAULT 1'
    """
    cur = conn.execute(f"PRAGMA table_info({table})")
    cols = [r[1] for r in cur.fetchall()]  # (cid, name, type, notnull, dflt_value, pk)
    if column not in cols:
        conn.execute(ddl)


def init_db() -> None:
    with open_db() as conn:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS messages (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              chat_id INTEGER NOT NULL,
              mode TEXT NOT NULL,
              role TEXT NOT NULL,
              content TEXT NOT NULL,
              created_at TEXT NOT NULL
            )
            """
        )
        conn.execute("CREATE INDEX IF NOT EXISTS idx_messages_chat_id_id ON messages(chat_id, id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_messages_chat_id_mode_id ON messages(chat_id, mode, id)")

        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS chat_settings (
              chat_id INTEGER PRIMARY KEY,
              temperature REAL NOT NULL,
              updated_at TEXT NOT NULL
            )
            """
        )

        # –º–∏–≥—Ä–∞—Ü–∏–∏: –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∞ —Ä–∞–Ω—å—à–µ
        _ensure_column(
            conn,
            table="chat_settings",
            column="memory_enabled",
            ddl="ALTER TABLE chat_settings ADD COLUMN memory_enabled INTEGER NOT NULL DEFAULT 1",
        )
        _ensure_column(
            conn,
            table="chat_settings",
            column="model",
            ddl="ALTER TABLE chat_settings ADD COLUMN model TEXT",
        )

        conn.commit()


def db_get_chat_settings(chat_id: int) -> tuple[float | None, bool | None, str | None]:
    try:
        with open_db() as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.execute(
                "SELECT temperature, memory_enabled, model FROM chat_settings WHERE chat_id = ?",
                (int(chat_id),),
            )
            row = cur.fetchone()
            if not row:
                return None, None, None

            temp = None
            mem = None
            model = None

            try:
                temp = float(row["temperature"])
            except Exception:
                temp = None

            try:
                mem = bool(int(row["memory_enabled"]))
            except Exception:
                mem = None

            try:
                m = row["model"]
                model = str(m).strip() if m else None
            except Exception:
                model = None

            return temp, mem, model
    except Exception as e:
        logger.exception("DB get settings failed: %s", e)
        return None, None, None


def db_set_temperature(chat_id: int, temperature: float) -> None:
    try:
        old_temp, old_mem, old_model = db_get_chat_settings(chat_id)
        mem_val = int(old_mem) if isinstance(old_mem, bool) else int(DEFAULT_MEMORY_ENABLED)
        model_val = (old_model or "").strip() or None

        with open_db() as conn:
            conn.execute(
                """
                INSERT INTO chat_settings(chat_id, temperature, memory_enabled, model, updated_at)
                VALUES(?, ?, ?, ?, ?)
                ON CONFLICT(chat_id) DO UPDATE SET
                  temperature=excluded.temperature,
                  updated_at=excluded.updated_at
                """,
                (int(chat_id), float(temperature), int(mem_val), model_val, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB set temperature failed: %s", e)


def db_set_memory_enabled(chat_id: int, enabled: bool) -> None:
    try:
        old_temp, old_mem, old_model = db_get_chat_settings(chat_id)
        temp_val = float(old_temp) if isinstance(old_temp, (int, float)) else float(DEFAULT_TEMPERATURE)
        model_val = (old_model or "").strip() or None

        with open_db() as conn:
            conn.execute(
                """
                INSERT INTO chat_settings(chat_id, temperature, memory_enabled, model, updated_at)
                VALUES(?, ?, ?, ?, ?)
                ON CONFLICT(chat_id) DO UPDATE SET
                  memory_enabled=excluded.memory_enabled,
                  updated_at=excluded.updated_at
                """,
                (int(chat_id), float(temp_val), int(bool(enabled)), model_val, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB set memory_enabled failed: %s", e)


def db_set_model(chat_id: int, model: str) -> None:
    try:
        old_temp, old_mem, old_model = db_get_chat_settings(chat_id)
        temp_val = float(old_temp) if isinstance(old_temp, (int, float)) else float(DEFAULT_TEMPERATURE)
        mem_val = int(old_mem) if isinstance(old_mem, bool) else int(DEFAULT_MEMORY_ENABLED)
        model_val = (model or "").strip() or None

        with open_db() as conn:
            conn.execute(
                """
                INSERT INTO chat_settings(chat_id, temperature, memory_enabled, model, updated_at)
                VALUES(?, ?, ?, ?, ?)
                ON CONFLICT(chat_id) DO UPDATE SET
                  model=excluded.model,
                  updated_at=excluded.updated_at
                """,
                (int(chat_id), float(temp_val), int(mem_val), model_val, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB set model failed: %s", e)


def db_get_temperature(chat_id: int) -> float | None:
    t, _, _ = db_get_chat_settings(chat_id)
    return t


def db_get_memory_enabled(chat_id: int) -> bool | None:
    _, m, _ = db_get_chat_settings(chat_id)
    return m


def db_get_model(chat_id: int) -> str | None:
    _, _, m = db_get_chat_settings(chat_id)
    return m


def get_temperature(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> float:
    t = context.user_data.get("temperature", None)
    if isinstance(t, (int, float)):
        return float(t)

    db_t = db_get_temperature(chat_id)
    if isinstance(db_t, (int, float)):
        context.user_data["temperature"] = float(db_t)
        return float(db_t)

    context.user_data["temperature"] = float(DEFAULT_TEMPERATURE)
    return float(DEFAULT_TEMPERATURE)


def get_memory_enabled(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> bool:
    v = context.user_data.get("memory_enabled", None)
    if isinstance(v, bool):
        return v

    db_v = db_get_memory_enabled(chat_id)
    if isinstance(db_v, bool):
        context.user_data["memory_enabled"] = bool(db_v)
        return bool(db_v)

    context.user_data["memory_enabled"] = bool(DEFAULT_MEMORY_ENABLED)
    return bool(DEFAULT_MEMORY_ENABLED)


def get_model(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> str:
    v = context.user_data.get("model", None)
    if isinstance(v, str) and v.strip():
        return v.strip()

    db_v = db_get_model(chat_id)
    if isinstance(db_v, str) and db_v.strip():
        context.user_data["model"] = db_v.strip()
        return db_v.strip()

    # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ => openrouter.py –≤–æ–∑—å–º—ë—Ç OPENROUTER_MODEL –∏–∑ config
    return ""


def get_effective_model(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> str:
    selected = get_model(context, chat_id)
    return selected if selected else OPENROUTER_MODEL


def clamp_temperature(value: float) -> float:
    if value < TEMPERATURE_MIN:
        return TEMPERATURE_MIN
    if value > TEMPERATURE_MAX:
        return TEMPERATURE_MAX
    return value


def db_add_message(chat_id: int, mode: str, role: str, content: str) -> None:
    content = (content or "").strip()
    if not content:
        return
    try:
        with open_db() as conn:
            conn.execute(
                "INSERT INTO messages(chat_id, mode, role, content, created_at) VALUES(?,?,?,?,?)",
                (int(chat_id), str(mode), str(role), content, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB add failed: %s", e)


def db_clear_history(chat_id: int) -> None:
    try:
        with open_db() as conn:
            conn.execute("DELETE FROM messages WHERE chat_id = ?", (int(chat_id),))
            conn.commit()
    except Exception as e:
        logger.exception("DB clear history failed: %s", e)


def db_get_history(chat_id: int, modes: tuple[str, ...], limit: int) -> list[dict]:
    placeholders = ",".join(["?"] * len(modes))
    sql = f"""
        SELECT role, content
        FROM messages
        WHERE chat_id = ? AND mode IN ({placeholders})
        ORDER BY id DESC
        LIMIT ?
    """
    try:
        with open_db() as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.execute(sql, (int(chat_id), *modes, int(limit)))
            rows = cur.fetchall()
    except Exception as e:
        logger.exception("DB read failed: %s", e)
        return []

    rows = list(reversed(rows))
    out: list[dict] = []
    for r in rows:
        role = (r["role"] or "").strip()
        content = (r["content"] or "").strip()
        if role in ("user", "assistant") and content:
            out.append({"role": role, "content": content})
    return out


def build_messages_with_db_memory(system_prompt: str, chat_id: int) -> list[dict]:
    history = db_get_history(chat_id=chat_id, modes=MEMORY_CHAT_MODES, limit=MEMORY_LIMIT_MESSAGES)
    return [{"role": "system", "content": system_prompt}] + history


# -------------------- PROMPTS --------------------

SYSTEM_PROMPT_JSON = """
–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–∏–º –≤–∞–ª–∏–¥–Ω—ã–º JSON-–æ–±—ä–µ–∫—Ç–æ–º. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤–Ω–µ JSON. –ù–∏–∫–∞–∫–æ–≥–æ markdown.

–°—Ö–µ–º–∞ (–≤—Å–µ–≥–¥–∞ –≤—Å–µ –ø–æ–ª—è, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö):
{
  "title": "",
  "time": "",
  "tag": "",
  "answer": "",
  "steps": [],
  "warnings": [],
  "need_clarification": false,
  "clarifying_question": ""
}

–ü—Ä–∞–≤–∏–ª–∞:
- time –≤—Å–µ–≥–¥–∞ –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—ã–º "" (–µ–≥–æ –∑–∞–ø–æ–ª–Ω–∏—Ç –±–æ—Ç).
- steps –∏ warnings –≤—Å–µ–≥–¥–∞ –º–∞—Å—Å–∏–≤—ã —Å—Ç—Ä–æ–∫.
- need_clarification=true -> clarifying_question —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å, –∏–Ω–∞—á–µ "".
- –ù–∏–∫–∞–∫–∏—Ö –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π. –ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤. –¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON.
"""

SYSTEM_PROMPT_TEXT = """
–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤ Telegram. –û—Ç–≤–µ—á–∞–π –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –∑–∞–¥–∞–π –æ–¥–∏–Ω —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å.
"""

SYSTEM_PROMPT_TZ = """
–¢—ã ‚Äî AI-–∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–±–∏—Ä–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –¢–ó –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–π—Ç–∞.

–†–ï–ñ–ò–ú –†–ê–ë–û–¢–´:
1) –ü–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –∏ –∑–∞–¥–∞–π –†–û–í–ù–û –û–î–ò–ù —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å.
2) –ö–æ–≥–¥–∞ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –æ–¥–∏–Ω –≤–∞–ª–∏–¥–Ω—ã–π JSON –ø–æ —Å—Ö–µ–º–µ –Ω–∏–∂–µ (–±–µ–∑ –ª—é–±–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ/–ø–æ—Å–ª–µ).
3) –í–æ–ø—Ä–æ—Å–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∞–ª–æ: —Å—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –≤ 3‚Äì4 –≤–æ–ø—Ä–æ—Å–∞. –ö–∞–∫ —Ç–æ–ª—å–∫–æ –ø–æ–Ω—è—Ç–Ω–æ ‚Äî —Å—Ä–∞–∑—É —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–π JSON.

–°–•–ï–ú–ê JSON (–≤—Å–µ–≥–¥–∞ –≤—Å–µ –ø–æ–ª—è, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö):
{
  "title": "–¢–ó –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–π—Ç–∞",
  "time": "",
  "tag": "tz_site",
  "answer": "",
  "steps": [],
  "warnings": [],
  "need_clarification": false,
  "clarifying_question": ""
}

–ü–†–ê–í–ò–õ–ê:
- –ü–æ–∫–∞ —Ç—ã –∑–∞–¥–∞—ë—à—å –≤–æ–ø—Ä–æ—Å—ã ‚Äî –ù–ï –ü–ò–®–ò JSON.
- –ö–æ–≥–¥–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å ‚Äî –ø–∏—à–∏ –¢–û–õ–¨–ö–û JSON.
- time –≤ JSON –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—ã–º "" (–µ–≥–æ –∑–∞–ø–æ–ª–Ω–∏—Ç –±–æ—Ç).
- steps/warnings –≤—Å–µ–≥–¥–∞ –º–∞—Å—Å–∏–≤—ã —Å—Ç—Ä–æ–∫.
- –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π.
"""

SYSTEM_PROMPT_FOREST = """
–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç, –∫—Ç–æ –∫–æ–º—É —Å–∫–æ–ª—å–∫–æ –¥–æ–ª–∂–µ–Ω –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –∑–∞ –æ–±—â–∏–µ —Ä–∞—Å—Ö–æ–¥—ã (–ø–æ—Ö–æ–¥/–ª–µ—Å/–∫–∞—Ñ–µ).

–í–ê–ñ–ù–û: –≤–µ—Å—å –¥–∏–∞–ª–æ–≥ (–≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã) ‚Äî –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º.
–ö–æ–≥–¥–∞ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Ç—ã –¥–æ–ª–∂–µ–Ω –°–ê–ú –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –∏ –≤—ã–¥–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

–†–ï–ñ–ò–ú –†–ê–ë–û–¢–´:
1) –ü–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –∑–∞–¥–∞–π –†–û–í–ù–û –û–î–ò–ù –≤–æ–ø—Ä–æ—Å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ.
2) –°—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –≤ 3‚Äì4 –≤–æ–ø—Ä–æ—Å–∞. –ù–µ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–π.
3) –ö–∞–∫ —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –≤—ã–¥–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∏ –±–æ–ª—å—à–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –∑–∞–¥–∞–≤–∞–π.

–ß–¢–û –ù–£–ñ–ù–û –°–û–ë–†–ê–¢–¨:
- –°–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ (–∏–º–µ–Ω–∞).
- –°–∫–æ–ª—å–∫–æ –∑–∞–ø–ª–∞—Ç–∏–ª –∫–∞–∂–¥—ã–π (–≤ —Ä—É–±–ª—è—Ö).
- –ö–∞–∫ –¥–µ–ª–∏–º —Ä–∞—Å—Ö–æ–¥—ã: "–ø–æ—Ä–æ–≤–Ω—É" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∏–ª–∏ "–ø–æ –¥–æ–ª—è–º" (–µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ —Å–∫–∞–∂–µ—Ç, —Ç–æ–≥–¥–∞ —Å–ø—Ä–æ—Å–∏ –¥–æ–ª–∏).

–ü–†–ï–î–ü–û–ß–¢–ò–¢–ï–õ–¨–ù–´–ô –§–û–†–ú–ê–¢ –°–ë–û–†–ê (—á—Ç–æ–±—ã –≤–æ–ø—Ä–æ—Å–æ–≤ –±—ã–ª–æ –º–∞–ª–æ):
- 1-–π –≤–æ–ø—Ä–æ—Å: "–ö—Ç–æ —É—á–∞—Å—Ç–Ω–∏–∫–∏? (–ø–µ—Ä–µ—á–∏—Å–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)"
- 2-–π –≤–æ–ø—Ä–æ—Å: "–ù–∞–ø–∏—à–∏, –∫—Ç–æ —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–ª–∞—Ç–∏–ª –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: –ò–º—è —Å—É–º–º–∞, –ò–º—è —Å—É–º–º–∞, ..."
- 3-–π –≤–æ–ø—Ä–æ—Å (–µ—Å–ª–∏ –Ω–µ —Å–∫–∞–∑–∞–Ω–æ): "–î–µ–ª–∏–º –ø–æ—Ä–æ–≤–Ω—É? (–¥–∞/–Ω–µ—Ç). –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –∫–∞–∫ –¥–µ–ª–∏–º?"

–ê–õ–ì–û–†–ò–¢–ú (–¥–µ–ª–∞–π —Å–∞–º, –±–µ–∑ Python):
- Total = —Å—É–º–º–∞ –≤—Å–µ—Ö –æ–ø–ª–∞—Ç.
- –ï—Å–ª–∏ –¥–µ–ª–∏–º –ø–æ—Ä–æ–≤–Ω—É: Share = Total / N.
- –ë–∞–ª–∞–Ω—Å —É—á–∞—Å—Ç–Ω–∏–∫–∞ = paid - share.
  - balance > 0: –¥–æ–ª–∂–µ–Ω –ø–æ–ª—É—á–∏—Ç—å
  - balance < 0: –¥–æ–ª–∂–µ–Ω –∑–∞–ø–ª–∞—Ç–∏—Ç—å
- –°–æ—Å—Ç–∞–≤—å –ø–µ—Ä–µ–≤–æ–¥—ã –æ—Ç –¥–æ–ª–∂–Ω–∏–∫–æ–≤ –∫ –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º —Ç–∞–∫, —á—Ç–æ–±—ã –∑–∞–∫—Ä—ã—Ç—å –±–∞–ª–∞–Ω—Å—ã.
- –í—Å–µ–≥–¥–∞ —Å–¥–µ–ª–∞–π –ø—Ä–æ–≤–µ—Ä–∫—É: —Å—É–º–º–∞ –±–∞–ª–∞–Ω—Å–æ–≤ = 0 (–∏–ª–∏ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∏–∑-–∑–∞ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è).

–û–ö–†–£–ì–õ–ï–ù–ò–ï:
- –ï—Å–ª–∏ —Å—É–º–º—ã —Ü–µ–ª—ã–µ ‚Äî —Ä–∞–±–æ—Ç–∞–π –≤ —Ü–µ–ª—ã—Ö.
- –ï—Å–ª–∏ –ø–æ—è–≤–ª—è—é—Ç—Å—è –∫–æ–ø–µ–π–∫–∏ ‚Äî –æ–∫—Ä—É–≥–ª—è–π –¥–æ 2 –∑–Ω–∞–∫–æ–≤ –∏ –≤ –∫–æ–Ω—Ü–µ –ø—Ä–æ–≤–µ—Ä—å, —á—Ç–æ–±—ã –ø–µ—Ä–µ–≤–æ–¥—ã —Å–æ—à–ª–∏—Å—å.

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê –§–ò–ù–ê–õ–ê (–û–î–ò–ù –†–ê–ó, –≤ –∫–æ–Ω—Ü–µ):
1) –ö–æ—Ä–æ—Ç–∫–æ: Total, N, Share (–∏–ª–∏ –ø—Ä–∞–≤–∏–ª–æ –¥–µ–ª–µ–Ω–∏—è)
2) –¢–∞–±–ª–∏—Ü–∞ —Å—Ç—Ä–æ–∫–∞–º–∏:
   –ò–º—è: paid=..., share=..., balance=... (–ø–æ–ª—É—á–∏—Ç—å/–∑–∞–ø–ª–∞—Ç–∏—Ç—å ...)
3) "–§–∏–Ω–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã:" —Å–ø–∏—Å–∫–æ–º "–ò–º—è -> –ò–º—è: —Å—É–º–º–∞"
4) –°—Ç—Ä–æ–∫–∞ "–ü—Ä–æ–≤–µ—Ä–∫–∞: —Å—É–º–º–∞ –±–∞–ª–∞–Ω—Å–æ–≤ = ..."

–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ü–†–ê–í–ò–õ–û:
- –°–ª–æ–≤–æ "FINAL" –ø–∏—à–∏ –¢–û–õ–¨–ö–û –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑.
- –î–æ —Ñ–∏–Ω–∞–ª–∞ "FINAL" –Ω–µ –ø–∏—Å–∞—Ç—å.
"""

SYSTEM_PROMPT_THINKING = """
–¢—ã —Ä–µ—à–∞–µ—à—å –∑–∞–¥–∞—á–∏ –≤ —Ä–µ–∂–∏–º–µ "–ø–æ—à–∞–≥–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ".
–ü—Ä–∞–≤–∏–ª–∞:
- –†–µ—à–∞–π –∑–∞–¥–∞—á—É –ø–æ—à–∞–≥–æ–≤–æ.
- –í –∫–æ–Ω—Ü–µ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: "–ò–¢–û–ì: ...".
- –ü–∏—à–∏ –ø–æ–Ω—è—Ç–Ω–æ –∏ –±–µ–∑ –≤–æ–¥—ã.
"""

SYSTEM_PROMPT_EXPERTS = """
–¢—ã —Ä–µ—à–∞–µ—à—å –∑–∞–¥–∞—á—É –∫–∞–∫ "–≥—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤" –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.

–≠–∫—Å–ø–µ—Ä—Ç—ã:
1) –õ–æ–≥–∏–∫ ‚Äî —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π, –ø–æ–∏—Å–∫ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π.
2) –ú–∞—Ç–µ–º–∞—Ç–∏–∫ ‚Äî –≤—ã—á–∏—Å–ª–µ–Ω–∏—è/—Ñ–æ—Ä–º—É–ª—ã/–∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞).
3) –†–µ–≤–∏–∑–æ—Ä ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ—à–µ–Ω–∏—è –õ–æ–≥–∏–∫–∞ –∏ –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –∏—â–µ—Ç –æ—à–∏–±–∫–∏, –¥–∞—ë—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å–≤–µ—Ä–∫—É.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ —Å—Ç—Ä–æ–≥–æ —Ç–∞–∫–æ–π:
–õ–û–ì–ò–ö:
...

–ú–ê–¢–ï–ú–ê–¢–ò–ö:
...

–†–ï–í–ò–ó–û–†:
...

–ò–¢–û–ì:
(–æ–¥–Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞)

–ü—Ä–∞–≤–∏–ª–∞:
- –í—Å–µ —Ç—Ä–∏ —á–∞—Å—Ç–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å.
- –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –Ω–æ —Ç–∞–∫, —á—Ç–æ–±—ã –±—ã–ª–æ —è—Å–Ω–æ, –ø–æ—á–µ–º—É –∏—Ç–æ–≥ –≤–µ—Ä–Ω—ã–π.
"""


# -------------------- HELPERS --------------------

TELEGRAM_MESSAGE_LIMIT = 3900  # –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ 4096


def split_telegram_text(text: str, limit: int = TELEGRAM_MESSAGE_LIMIT) -> list[str]:
    t = (text or "").strip()
    if not t:
        return [""]

    if len(t) <= limit:
        return [t]

    parts: list[str] = []
    cur = t
    while len(cur) > limit:
        cut = cur.rfind("\n", 0, limit)
        if cut < 200:
            cut = limit
        parts.append(cur[:cut].rstrip())
        cur = cur[cut:].lstrip()
    if cur:
        parts.append(cur)
    return parts


async def safe_reply_text(update: Update, text: str, parse_mode: str | None = None) -> None:
    if not update.message:
        return

    chunks = split_telegram_text(text)
    for ch in chunks:
        try:
            await update.message.reply_text(ch, parse_mode=parse_mode)
        except TimedOut:
            return
        except BadRequest as e:
            msg = str(e).lower()
            if "message is too long" in msg and len(ch) > 500:
                for sub in split_telegram_text(ch, limit=2000):
                    try:
                        await update.message.reply_text(sub, parse_mode=parse_mode)
                    except Exception:
                        return
                continue
            return
        except Exception:
            return


def extract_json_object(text: str) -> str:
    text = (text or "").strip()
    text = re.sub(r"^```(?:json)?\s*|\s*```$", "", text, flags=re.IGNORECASE)
    m = re.search(r"\{.*\}", text, flags=re.DOTALL)
    if not m:
        raise ValueError("JSON object not found in model output")
    return m.group(0)


def normalize_payload(data: dict) -> dict:
    normalized = {
        "title": str(data.get("title", "")).strip() or "–û—Ç–≤–µ—Ç",
        "time": utc_now_iso(),
        "tag": str(data.get("tag", "")).strip() or "general",
        "answer": str(data.get("answer", "")).strip(),
        "steps": data.get("steps", []),
        "warnings": data.get("warnings", []),
        "need_clarification": bool(data.get("need_clarification", False)),
        "clarifying_question": str(data.get("clarifying_question", "")).strip(),
    }

    if not isinstance(normalized["steps"], list):
        normalized["steps"] = []
    if not isinstance(normalized["warnings"], list):
        normalized["warnings"] = []

    normalized["steps"] = [str(x).strip() for x in normalized["steps"] if str(x).strip()]
    normalized["warnings"] = [str(x).strip() for x in normalized["warnings"] if str(x).strip()]

    if normalized["need_clarification"]:
        if not normalized["clarifying_question"]:
            normalized["clarifying_question"] = "–£—Ç–æ—á–Ω–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞: —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã –∏–º–µ–µ—à—å –≤ –≤–∏–¥—É?"
        if not normalized["answer"]:
            normalized["answer"] = normalized["clarifying_question"]
    else:
        normalized["clarifying_question"] = ""

    if not normalized["answer"]:
        normalized["answer"] = "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

    return normalized


def repair_json_with_model(system_prompt: str, raw: str, temperature: float, model: str | None) -> str:
    repair_prompt = (
        system_prompt
        + "\n\n–ò—Å–ø—Ä–∞–≤—å —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç–≤–µ—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω —Å—Ç–∞–ª –≤–∞–ª–∏–¥–Ω—ã–º JSON —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON."
    )
    fixed = chat_completion(
        [
            {"role": "system", "content": repair_prompt},
            {"role": "user", "content": raw or ""},
        ],
        temperature=temperature,
        model=model,
    )
    return fixed


def get_mode(context: ContextTypes.DEFAULT_TYPE) -> str:
    return context.user_data.get("mode", "text")  # text | json | tz | forest | thinking | experts | summary


def looks_like_json(text: str) -> bool:
    t = (text or "").lstrip()
    return (t.startswith("{") and t.endswith("}")) or t.startswith("{")


def is_forest_final(text: str) -> bool:
    t = (text or "").lstrip()
    return t.upper().startswith("FINAL")


def strip_forest_final_marker(text: str) -> str:
    lines = (text or "").splitlines()
    if not lines:
        return ""
    if lines[0].strip().upper() == "FINAL":
        return "\n".join(lines[1:]).strip()
    return (text or "").strip()


def user_asked_to_show_result(user_text: str) -> bool:
    t = (user_text or "").strip().lower()
    keywords = ["–ø–æ–∫–∞–∂–∏", "–≤—ã–≤–µ–¥–∏", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç", "—Ä–∞—Å—á", "–∏—Ç–æ–≥", "—Ñ–∏–Ω–∞–ª", "–ø–µ—Ä–µ–≤–æ–¥—ã", "–∫—Ç–æ –∫–æ–º—É"]
    return any(k in t for k in keywords)


def reset_tz(context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data.pop("tz_history", None)
    context.user_data.pop("tz_questions", None)
    context.user_data.pop("tz_done", None)


def reset_forest(context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data.pop("forest_history", None)
    context.user_data.pop("forest_questions", None)
    context.user_data.pop("forest_done", None)
    context.user_data.pop("forest_result", None)


# -------------------- COMMANDS --------------------

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    mode = get_mode(context)
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    t = get_temperature(context, chat_id)
    mem = get_memory_enabled(context, chat_id)
    current_model = get_effective_model(context, chat_id)

    lines = [
        "–ü—Ä–∏–≤–µ—Ç! üëã",
        "",
        "üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:",
        "",
        "üîß –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∂–∏–º—ã:",
        f"/mode_text ‚Äî —Ä–µ–∂–∏–º text + {_short_model_name(OPENROUTER_MODEL)}",
        "/mode_json ‚Äî JSON –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        f"/mode_summary ‚Äî —Ä–µ–∂–∏–º summary + {_short_model_name(OPENROUTER_MODEL)} (—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏)",
        "/summary_debug ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ summary (—Ä–µ–∂–∏–º summary)",
    ]

    if MODEL_GLM:
        lines.append(f"/model_glm ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GLM)}")
    if MODEL_GEMMA:
        lines.append(f"/model_gemma ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GEMMA)}")
    
    lines.extend([
        "",
        "ü§ñ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã:",
        "/tz_creation_site ‚Äî —Å–æ–±—Ä–∞—Ç—å –¢–ó –Ω–∞ —Å–∞–π—Ç (–∏—Ç–æ–≥ JSON)",
        "/forest_split ‚Äî –∫—Ç–æ –∫–æ–º—É –¥–æ–ª–∂–µ–Ω (–∏—Ç–æ–≥ —Ç–µ–∫—Å—Ç)",
        "/thinking_model ‚Äî —Ä–µ—à–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ",
        "/expert_group_model ‚Äî –≥—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤",
        "",
        "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:",
        "/ch_temperature ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: /ch_temperature 0.7)",
        "/ch_memory ‚Äî –ø–∞–º—è—Ç—å –í–ö–õ/–í–´–ö–õ (–ø—Ä–∏–º–µ—Ä: /ch_memory off)",
        "/clear_memory ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞",
        "/clear_embeddings ‚Äî —É–¥–∞–ª–∏—Ç—å –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏",
        "",
        "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:",
        "/tokens_test ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤ (–≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º)",
        "/tokens_next ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø",
        "/tokens_stop ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–≤–æ–¥–∫–∞ –∏ –≤—ã—Ö–æ–¥",
        "",
        "üìö RAG –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏:",
        "/embed_create ‚Äî —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ .md —Ñ–∞–π–ª–∞ (—Å–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª)",
        "/embed_docs ‚Äî —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ docs/",
        "/rag_model ‚Äî —Ä–µ–∂–∏–º RAG",
        "",
        "üí¨ –°–ª–æ–≤–µ—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã (–≤ —Ä–µ–∂–∏–º–µ RAG):",
        "‚Ä¢ \"RAG+—Ñ–∏–ª—å—Ç—Ä\" –∏–ª–∏ \"RAG+—Ñ–∏–ª—å—Ç—Ä <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –ø–æ–∏—Å–∫ —Å –ø–æ—Ä–æ–≥–æ–º –ø–æ—Ö–æ–∂–µ—Å—Ç–∏",
        "‚Ä¢ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞\" –∏–ª–∏ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –ø–æ–∏—Å–∫ –±–µ–∑ –ø–æ—Ä–æ–≥–∞",
        "‚Ä¢ \"–ë–µ–∑ RAG\" –∏–ª–∏ \"–ë–µ–∑ RAG <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ø–æ–∏—Å–∫–∞",
        "",
        "üå§Ô∏è –ü–æ–≥–æ–¥–∞:",
        "/weather_sub ‚Äî –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É (–ø—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30)",
        "/weather_sub_stop ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É (–ø—Ä–∏–º–µ—Ä: /weather_sub_stop –ú–æ—Å–∫–≤–∞)",
        "/digest ‚Äî —É—Ç—Ä–µ–Ω–Ω—è—è —Å–≤–æ–¥–∫–∞: –ø–æ–≥–æ–¥–∞ + –Ω–æ–≤–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)",
        "",
        "üë§ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –∑–∞–ø–∏—Å–∏:",
        "/register ‚Äî —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è (–ø—Ä–∏–º–µ—Ä: /register –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á +79991234567)",
        "/unregister ‚Äî —É–¥–∞–ª–∏—Ç—å —Å–≤–æ—é —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é",
        "/train_signup ‚Äî –∑–∞–ø–∏—Å—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É (–ø—Ä–∏–º–µ—Ä: /train_signup 15-02-2026 18:00 [–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ])",
        "/train_move ‚Äî –ø–µ—Ä–µ–Ω–æ—Å –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_move 1 16-02-2026 19:00)",
        "/train_cancel ‚Äî –æ—Ç–º–µ–Ω–∞ –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_cancel 1)",
        "/support ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å RAG (–ø—Ä–∏–º–µ—Ä: /support –º–æ–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∑–∞–ø–∏—Å—å?)",
        "/task_list ‚Äî —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏ (—Å–ª–æ–≤–µ—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è, –ø—Ä–æ—Å–º–æ—Ç—Ä–∞, —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–¥–∞—á)",
        "",
        "ü§ñ –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏:",
        "/local_model ‚Äî —Ä–µ–∂–∏–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Ollama (–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞, –∑–∞—Ç–µ–º –ø—Ä–æ—Å—Ç–æ –ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è)",
        "/analyze ‚Äî –∞–Ω–∞–ª–∏–∑ JSON —Ñ–∞–π–ª–æ–≤ —Å –ª–æ–≥–∞–º–∏ —á–µ—Ä–µ–∑ Ollama (–æ—Ç–ø—Ä–∞–≤—å—Ç–µ JSON —Ñ–∞–π–ª, –∑–∞—Ç–µ–º –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å)",
        "/me ‚Äî –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ–º–∞–Ω–¥—ã: '–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å', '–ö—Ç–æ —è?')",
        "",
        "üöÄ –î–µ–ø–ª–æ–π:",
        "/deploy_bot ‚Äî –¥–µ–ø–ª–æ–π –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä (—Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)",
    ])
    
    if PR_REVIEW_AVAILABLE:
        lines.append("/review_pr ‚Äî –∞–Ω–∞–ª–∏–∑ Pull Request (–ø—Ä–∏–º–µ—Ä: /review_pr 123)")
    
    lines.extend([
        "",
        "üìñ –°–ø—Ä–∞–≤–∫–∞:",
        "/help ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–µ–∫—Ç–µ",
    ])

    lines.extend([
        "",
        f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {mode}",
        f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {t}",
        f"–ü–∞–º—è—Ç—å: {'–í–ö–õ' if mem else '–í–´–ö–õ'}",
        f"–ú–æ–¥–µ–ª—å: {current_model}",
    ])

    await safe_reply_text(update, "\n".join(lines))


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ /help: –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥ –∏–ª–∏ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É—è RAG.
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    - /help - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥
    - /help <–≤–æ–ø—Ä–æ—Å> - –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É—è RAG
    """
    if not update.message:
        return
    
    # –ï—Å–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥
    if not context.args:
        lines = [
            "üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:",
            "",
            "üîß –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∂–∏–º—ã:",
        f"/mode_text ‚Äî —Ä–µ–∂–∏–º text + {_short_model_name(OPENROUTER_MODEL)}",
        "/mode_json ‚Äî JSON –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        f"/mode_summary ‚Äî —Ä–µ–∂–∏–º summary + {_short_model_name(OPENROUTER_MODEL)} (—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏)",
            "/summary_debug ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ summary (—Ä–µ–∂–∏–º summary)",
            "",
            "ü§ñ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã:",
            "/tz_creation_site ‚Äî —Å–æ–±—Ä–∞—Ç—å –¢–ó –Ω–∞ —Å–∞–π—Ç (–∏—Ç–æ–≥ JSON)",
            "/forest_split ‚Äî –∫—Ç–æ –∫–æ–º—É –¥–æ–ª–∂–µ–Ω (–∏—Ç–æ–≥ —Ç–µ–∫—Å—Ç)",
        "/thinking_model ‚Äî —Ä–µ—à–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ",
            "/expert_group_model ‚Äî –≥—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤",
            "",
            "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:",
            "/ch_temperature ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: /ch_temperature 0.7)",
            "/ch_memory ‚Äî –ø–∞–º—è—Ç—å –í–ö–õ/–í–´–ö–õ (–ø—Ä–∏–º–µ—Ä: /ch_memory off)",
            "/clear_memory ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞",
            "/clear_embeddings ‚Äî —É–¥–∞–ª–∏—Ç—å –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏",
            "",
            "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:",
            "/tokens_test ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤ (–≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º)",
            "/tokens_next ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø",
            "/tokens_stop ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–≤–æ–¥–∫–∞ –∏ –≤—ã—Ö–æ–¥",
            "",
            "üìö RAG –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏:",
            "/embed_create ‚Äî —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ .md —Ñ–∞–π–ª–∞ (—Å–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª)",
            "/embed_docs ‚Äî —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ docs/",
            "/rag_model ‚Äî —Ä–µ–∂–∏–º RAG",
            "",
            "üí¨ –°–ª–æ–≤–µ—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã (–≤ —Ä–µ–∂–∏–º–µ RAG):",
            "‚Ä¢ \"RAG+—Ñ–∏–ª—å—Ç—Ä\" –∏–ª–∏ \"RAG+—Ñ–∏–ª—å—Ç—Ä <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –ø–æ–∏—Å–∫ —Å –ø–æ—Ä–æ–≥–æ–º –ø–æ—Ö–æ–∂–µ—Å—Ç–∏",
            "‚Ä¢ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞\" –∏–ª–∏ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –ø–æ–∏—Å–∫ –±–µ–∑ –ø–æ—Ä–æ–≥–∞",
            "‚Ä¢ \"–ë–µ–∑ RAG\" –∏–ª–∏ \"–ë–µ–∑ RAG <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ø–æ–∏—Å–∫–∞",
            "",
            "üå§Ô∏è –ü–æ–≥–æ–¥–∞:",
            "/weather_sub ‚Äî –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É (–ø—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30)",
            "/weather_sub_stop ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É (–ø—Ä–∏–º–µ—Ä: /weather_sub_stop –ú–æ—Å–∫–≤–∞)",
            "/digest ‚Äî —É—Ç—Ä–µ–Ω–Ω—è—è —Å–≤–æ–¥–∫–∞: –ø–æ–≥–æ–¥–∞ + –Ω–æ–≤–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)",
            "",
            "üë§ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –∑–∞–ø–∏—Å–∏:",
            "/register ‚Äî —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è (–ø—Ä–∏–º–µ—Ä: /register –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á +79991234567)",
            "/unregister ‚Äî —É–¥–∞–ª–∏—Ç—å —Å–≤–æ—é —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é",
            "/train_signup ‚Äî –∑–∞–ø–∏—Å—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É (–ø—Ä–∏–º–µ—Ä: /train_signup 15-02-2026 18:00 [–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ])",
            "/train_move ‚Äî –ø–µ—Ä–µ–Ω–æ—Å –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_move 1 16-02-2026 19:00)",
            "/train_cancel ‚Äî –æ—Ç–º–µ–Ω–∞ –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_cancel 1)",
            "/support ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å RAG (–ø—Ä–∏–º–µ—Ä: /support –º–æ–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∑–∞–ø–∏—Å—å?)",
            "/task_list ‚Äî —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏ (—Å–ª–æ–≤–µ—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è, –ø—Ä–æ—Å–º–æ—Ç—Ä–∞, —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–¥–∞—á)",
            "/local_model ‚Äî —Ä–µ–∂–∏–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Ollama (–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞, –∑–∞—Ç–µ–º –ø—Ä–æ—Å—Ç–æ –ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è)",
            "/analyze ‚Äî –∞–Ω–∞–ª–∏–∑ JSON —Ñ–∞–π–ª–æ–≤ —Å –ª–æ–≥–∞–º–∏ —á–µ—Ä–µ–∑ Ollama (–æ—Ç–ø—Ä–∞–≤—å—Ç–µ JSON —Ñ–∞–π–ª, –∑–∞—Ç–µ–º –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å)",
            "/me ‚Äî –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ–º–∞–Ω–¥—ã: '–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å', '–ö—Ç–æ —è?')",
            "",
            "üöÄ –î–µ–ø–ª–æ–π:",
            "/deploy_bot ‚Äî –¥–µ–ø–ª–æ–π –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä (—Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)",
            "/stop_bot ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ (–æ–ø—Ü–∏–∏: -v —É–¥–∞–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ, -i —É–¥–∞–ª–∏—Ç—å –æ–±—Ä–∞–∑—ã)",
            "",
            "üìñ –°–ø—Ä–∞–≤–∫–∞:",
            "/help <–≤–æ–ø—Ä–æ—Å> ‚Äî –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É—è RAG",
    ]

        if PR_REVIEW_AVAILABLE:
            lines.insert(-2, "/review_pr ‚Äî –∞–Ω–∞–ª–∏–∑ Pull Request (–ø—Ä–∏–º–µ—Ä: /review_pr 123)")

        if MODEL_GLM:
            lines.insert(4, f"/model_glm ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GLM)}")
        if MODEL_GEMMA:
            lines.insert(5 if MODEL_GLM else 4, f"/model_gemma ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GEMMA)}")

        await safe_reply_text(update, "\n".join(lines))
        return
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º RAG –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å
    question_text = " ".join(context.args).strip()
    if not question_text:
        await safe_reply_text(update, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–µ–∫—Ç–µ. –ü—Ä–∏–º–µ—Ä: /help –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç RAG —Å–∏—Å—Ç–µ–º–∞?")
        return
    
    await update.message.chat.send_action("typing")
    
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    temperature = get_temperature(context, chat_id)
    memory_enabled = get_memory_enabled(context, chat_id)
    model = get_model(context, chat_id) or None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    if not has_embeddings(EMBEDDING_MODEL):
        await safe_reply_text(
            update,
            "‚ö†Ô∏è –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.\n"
            "–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /embed_create.\n"
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ README.md –∏ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ docs/ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ git –≤–µ—Ç–∫—É
    question_lower = question_text.lower()
    is_git_branch_question = any(keyword in question_lower for keyword in [
        "–≤–µ—Ç–∫–∞", "–≤–µ—Ç–∫—É", "–≤–µ—Ç–∫–∏", "branch", "git branch", "—Ç–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞",
        "–∫–∞–∫–∞—è –≤–µ—Ç–∫–∞", "–∫–∞–∫—É—é –≤–µ—Ç–∫—É", "–∫–∞–∫–∏–µ –≤–µ—Ç–∫–∏"
    ])
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –≤–µ—Ç–∫—É git —á–µ—Ä–µ–∑ MCP (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    git_branch_info = None
    git_branch_name = None
    try:
        git_branch_name = await get_git_branch()
        if git_branch_name:
            git_branch_info = f"–¢–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞ git: {git_branch_name}"
    except Exception as e:
        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å git –≤–µ—Ç–∫—É —á–µ—Ä–µ–∑ MCP: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ git
    
    # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ git –≤–µ—Ç–∫—É –∏ –º—ã –ø–æ–ª—É—á–∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é - –æ—Ç–≤–µ—á–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é
    if is_git_branch_question and git_branch_name:
        await safe_reply_text(update, f"üåø –¢–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞ git: `{git_branch_name}`")
        return
    elif is_git_branch_question and not git_branch_name:
        await safe_reply_text(
            update,
            "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ç–∫—É git.\n"
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:\n"
            "- MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω (http://127.0.0.1:8000/mcp)\n"
            "- –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è MCP —Å–µ—Ä–≤–µ—Ä–∞ —è–≤–ª—è–µ—Ç—Å—è git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º"
        )
        return
    
    # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ (—Å–Ω–∞—á–∞–ª–∞ —Å –ø–æ—Ä–æ–≥–æ–º)
    filtered_chunks = []
    try:
        relevant_chunks = search_relevant_chunks(
            question_text,
            model=EMBEDDING_MODEL,
            top_k=RAG_TOP_K,
            min_similarity=RAG_SIM_THRESHOLD,
            apply_threshold=True
        )
        # –§–∏–ª—å—Ç—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ –ø–æ—Ä–æ–≥—É
        filtered_chunks = [chunk for chunk in relevant_chunks if chunk["similarity"] >= RAG_SIM_THRESHOLD]
        
        # –ï—Å–ª–∏ —Å –ø–æ—Ä–æ–≥–æ–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø–æ—Ä–æ–≥–∞ (–¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)
        if not filtered_chunks:
            logger.debug(f"No chunks found with threshold {RAG_SIM_THRESHOLD}, trying without threshold")
            relevant_chunks_no_threshold = search_relevant_chunks(
                question_text,
                model=EMBEDDING_MODEL,
                top_k=RAG_TOP_K * 2,  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ —á–∞–Ω–∫–æ–≤
                min_similarity=0.0,
                apply_threshold=False
            )
            # –ë–µ—Ä–µ–º —Ç–æ–ø —á–∞–Ω–∫–∏ –¥–∞–∂–µ —Å –Ω–∏–∑–∫–æ–π –ø–æ—Ö–æ–∂–µ—Å—Ç—å—é (–Ω–æ –Ω–µ –Ω—É–ª–µ–≤–æ–π)
            filtered_chunks = [chunk for chunk in relevant_chunks_no_threshold if chunk["similarity"] > 0.3]
            
    except Exception as e:
        logger.exception(f"Error searching relevant chunks: {e}")
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {e}")
        return
    
    if not filtered_chunks:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        indexed_docs = list_indexed_documents(EMBEDDING_MODEL)
        
        error_msg = "‚ö†Ô∏è –ù–µ –Ω–∞—à–ª–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å."
        
        if indexed_docs:
            error_msg += f"\n\n–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: {', '.join(indexed_docs[:5])}"
            if len(indexed_docs) > 5:
                error_msg += f" –∏ –µ—â–µ {len(indexed_docs) - 5}"
        else:
            error_msg += "\n\n–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
            error_msg += "- `/embed_create` –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ README.md\n"
            error_msg += "- `/embed_docs` –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–∞–ø–∫–∏ docs/"
        
        error_msg += "\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é."
        
        await safe_reply_text(update, error_msg)
        return
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
    context_parts = ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞:\n"]
    for i, chunk in enumerate(filtered_chunks, 1):
        context_parts.append(f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} (doc_name={chunk['doc_name']}, chunk_index={chunk['chunk_index']}, score={chunk['similarity']:.4f})]:")
        context_parts.append(chunk["text"])
        context_parts.append("")
    
    context_parts.append(f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –ø—Ä–æ–µ–∫—Ç–µ: {question_text}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ git –≤–µ—Ç–∫–µ, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
    if git_branch_info:
        context_parts.append(f"\n{git_branch_info}")
    
    context_parts.append("\n–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤—ã—à–µ.")
    context_parts.append("–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞, —É–∫–∞–∂–∏ —ç—Ç–æ –≤ –æ—Ç–≤–µ—Ç–µ.")
    
    user_content = "\n".join(context_parts)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è LLM
    system_prompt = SYSTEM_PROMPT_TEXT
    if memory_enabled:
        messages = build_messages_with_db_memory(system_prompt, chat_id=chat_id)
    else:
        messages = [{"role": "system", "content": system_prompt}]
    
    messages.append({"role": "user", "content": user_content})
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
    try:
        answer = chat_completion(messages, temperature=temperature, model=model)
        answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."
    except Exception as e:
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
        return
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    mode = "text"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∂–∏–º text –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
    db_add_message(chat_id, mode, "user", f"/help {question_text}")
    db_add_message(chat_id, mode, "assistant", answer)
    
    await safe_reply_text(update, answer)


async def ch_temperature_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args:
        t = get_temperature(context, chat_id)
        await safe_reply_text(
            update,
            f"–¢–µ–∫—É—â–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {t}\n"
            f"–ò–∑–º–µ–Ω–∏—Ç—å: /ch_temperature <—á–∏—Å–ª–æ –æ—Ç {TEMPERATURE_MIN} –¥–æ {TEMPERATURE_MAX}>\n"
            "–ü—Ä–∏–º–µ—Ä—ã: /ch_temperature 0, /ch_temperature 0.7, /ch_temperature 1.2"
        )
        return

    raw = (context.args[0] or "").replace(",", ".").strip()
    try:
        val = float(raw)
    except Exception:
        await safe_reply_text(update, "–ù–µ –ø–æ–Ω—è–ª —á–∏—Å–ª–æ. –ü—Ä–∏–º–µ—Ä: /ch_temperature 0.7")
        return

    val = clamp_temperature(val)

    context.user_data["temperature"] = val
    db_set_temperature(chat_id, val)

    await safe_reply_text(update, f"–û–∫. –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {val}")


async def ch_memory_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    /ch_memory
    /ch_memory on|off
    """
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args:
        mem = get_memory_enabled(context, chat_id)
        await safe_reply_text(
            update,
            f"–ü–∞–º—è—Ç—å —Å–µ–π—á–∞—Å: {'–í–ö–õ' if mem else '–í–´–ö–õ'}\n"
            "–ò–∑–º–µ–Ω–∏—Ç—å: /ch_memory on –∏–ª–∏ /ch_memory off\n"
            "–ü—Ä–∏–º–µ—Ä: /ch_memory off (–¥–ª—è —á–µ—Å—Ç–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã)"
        )
        return

    v = (context.args[0] or "").strip().lower()
    truthy = {"on", "1", "true", "yes", "y", "–¥–∞", "–≤–∫–ª"}
    falsy = {"off", "0", "false", "no", "n", "–Ω–µ—Ç", "–≤—ã–∫–ª"}

    if v in truthy:
        enabled = True
    elif v in falsy:
        enabled = False
    else:
        await safe_reply_text(update, "–ù–µ –ø–æ–Ω—è–ª. –ò—Å–ø–æ–ª—å–∑—É–π: /ch_memory on –∏–ª–∏ /ch_memory off")
        return

    context.user_data["memory_enabled"] = enabled
    db_set_memory_enabled(chat_id, enabled)

    await safe_reply_text(update, f"–û–∫. –ü–∞–º—è—Ç—å: {'–í–ö–õ' if enabled else '–í–´–ö–õ'}")


async def clear_memory_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    db_clear_history(chat_id)

    # NEW: —á–∏—Å—Ç–∏–º summary-—Ç–∞–±–ª–∏—Ü—É —Ç–æ–∂–µ
    try:
        clear_summary(chat_id, mode=MODE_SUMMARY)
    except Exception:
        pass

    await safe_reply_text(update, "–û–∫. –ü–∞–º—è—Ç—å —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞.")


async def clear_embeddings_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    try:
        from .embeddings import clear_all_embeddings
        deleted_count = clear_all_embeddings()
        if deleted_count > 0:
            logger.info(f"Cleared {deleted_count} embedding chunks from database")
            await safe_reply_text(update, f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted_count} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.")
        else:
            await safe_reply_text(update, "‚ÑπÔ∏è –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
    except Exception as e:
        logger.exception(f"Error clearing embeddings: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")


async def model_glm_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not MODEL_GLM:
        await safe_reply_text(update, "–ú–æ–¥–µ–ª—å OPENROUTER_MODEL_GLM –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ .env")
        return
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    context.user_data["model"] = MODEL_GLM
    db_set_model(chat_id, MODEL_GLM)
    await safe_reply_text(update, f"–û–∫. –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {MODEL_GLM}")


async def model_gemma_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not MODEL_GEMMA:
        await safe_reply_text(update, "–ú–æ–¥–µ–ª—å OPENROUTER_MODEL_GEMMA –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ .env")
        return
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    context.user_data["model"] = MODEL_GEMMA
    db_set_model(chat_id, MODEL_GEMMA)
    await safe_reply_text(update, f"–û–∫. –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {MODEL_GEMMA}")


async def mode_text_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    context.user_data["mode"] = "text"
    reset_tz(context)
    reset_forest(context)

    # –°–±—Ä–æ—Å –Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ .env (OPENROUTER_MODEL)
    context.user_data.pop("model", None)
    db_set_model(chat_id, "")

    await safe_reply_text(update, f"–û–∫. –†–µ–∂–∏–º: text. –ú–æ–¥–µ–ª—å: {OPENROUTER_MODEL}")


async def mode_json_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "json"
    reset_tz(context)
    reset_forest(context)

    payload = {
        "title": "–†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω",
        "time": utc_now_iso(),
        "tag": "system",
        "answer": "–û–∫. –†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: json",
        "steps": [],
        "warnings": [],
        "need_clarification": False,
        "clarifying_question": "",
    }
    context.user_data["last_payload"] = payload
    await safe_reply_text(update, json.dumps(payload, ensure_ascii=False, indent=2))


# NEW: summary mode command
async def mode_summary_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    context.user_data["mode"] = MODE_SUMMARY
    reset_tz(context)
    reset_forest(context)

    # –í summary-—Ä–µ–∂–∏–º–µ –ø–∞–º—è—Ç—å –Ω—É–∂–Ω–∞ –≤—Å–µ–≥–¥–∞
    context.user_data["memory_enabled"] = True
    db_set_memory_enabled(chat_id, True)

    await safe_reply_text(update, "–û–∫. –†–µ–∂–∏–º: summary (—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏: summary –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏).")


async def thinking_model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "thinking"
    reset_tz(context)
    reset_forest(context)
    await safe_reply_text(update, "–û–∫. –†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: thinking_model (–ø–æ—à–∞–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ).")


async def expert_group_model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "experts"
    reset_tz(context)
    reset_forest(context)
    await safe_reply_text(update, "–û–∫. –†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: expert_group_model (–õ–æ–≥–∏–∫/–ú–∞—Ç–µ–º–∞—Ç–∏–∫/–†–µ–≤–∏–∑–æ—Ä).")


async def tz_creation_site_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "tz"
    context.user_data["tz_history"] = []
    context.user_data["tz_questions"] = 0
    context.user_data["tz_done"] = False
    reset_forest(context)

    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    temperature = get_temperature(context, chat_id)
    model = get_model(context, chat_id) or None

    first = (chat_completion(
        [
            {"role": "system", "content": SYSTEM_PROMPT_TZ},
            {"role": "user", "content": "–ù–∞—á–Ω–∏. –ó–∞–¥–∞–π –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å, —á—Ç–æ–±—ã —Å–æ–±—Ä–∞—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –¢–ó –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–π—Ç–∞."},
        ],
        temperature=temperature,
        model=model,
    ) or "").strip()

    if looks_like_json(first):
        await send_final_tz_json(update, context, first, temperature=temperature, model=model)
        return

    context.user_data["tz_questions"] = 1
    context.user_data["tz_history"].append({"role": "assistant", "content": first})
    await safe_reply_text(update, first)


async def forest_split_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "forest"
    context.user_data["forest_history"] = []
    context.user_data["forest_questions"] = 0
    context.user_data["forest_done"] = False
    context.user_data.pop("forest_result", None)
    reset_tz(context)

    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    temperature = get_temperature(context, chat_id)
    model = get_model(context, chat_id) or None

    first = (chat_completion(
        [
            {"role": "system", "content": SYSTEM_PROMPT_FOREST},
            {"role": "user", "content": "–ù–∞—á–Ω–∏. –ó–∞–¥–∞–π –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –∫—Ç–æ –∫–æ–º—É —Å–∫–æ–ª—å–∫–æ –¥–æ–ª–∂–µ–Ω."},
        ],
        temperature=temperature,
        model=model,
    ) or "").strip()

    context.user_data["forest_questions"] = 1
    context.user_data["forest_history"].append({"role": "assistant", "content": first})
    await safe_reply_text(update, first)


# -------------------- WEATHER SUBSCRIPTION --------------------
async def weather_sub_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ –ø–æ–≥–æ–¥—É —Å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–º —Å–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö.
    –§–æ—Ä–º–∞—Ç: /weather_sub <–ì–æ—Ä–æ–¥> <–≤—Ä–µ–º—è_–≤_—Å–µ–∫—É–Ω–¥–∞—Ö>
    –ü—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30
    """
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args or len(context.args) < 2:
        await safe_reply_text(
            update,
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /weather_sub <–ì–æ—Ä–æ–¥> <–≤—Ä–µ–º—è_–≤_—Å–µ–∫—É–Ω–¥–∞—Ö>\n"
            "–ü—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30\n"
            "–ü–æ–¥–ø–∏—Å–∫–∞ –±—É–¥–µ—Ç —Å–æ–±–∏—Ä–∞—Ç—å –ø–æ–≥–æ–¥—É –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å summary –∫–∞–∂–¥—ã–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Å–µ–∫—É–Ω–¥—ã.",
        )
        return

    city = context.args[0].strip()
    try:
        summary_interval = int(context.args[1])
        if summary_interval < 10:
            await safe_reply_text(update, "–ò–Ω—Ç–µ—Ä–≤–∞–ª summary –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –º–µ–Ω–µ–µ 10 —Å–µ–∫—É–Ω–¥.")
            return
    except ValueError:
        await safe_reply_text(update, "–í—Ä–µ–º—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö).")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–¥–ø–∏—Å–∫—É
    try:
        start_weather_subscription(
            chat_id=chat_id,
            city=city,
            summary_interval=summary_interval,
            bot=context.bot,
            context=context,
            db_add_message=db_add_message,
        )
    except Exception as e:
        logger.exception(f"Failed to start weather subscription: {e}")
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–æ–¥–ø–∏—Å–∫–∏: {e}")


async def weather_sub_stop_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ –ø–æ–≥–æ–¥—É.
    –§–æ—Ä–º–∞—Ç: /weather_sub_stop <–ì–æ—Ä–æ–¥>
    """
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args or len(context.args) < 1:
        await safe_reply_text(update, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /weather_sub_stop <–ì–æ—Ä–æ–¥>\n–ü—Ä–∏–º–µ—Ä: /weather_sub_stop –ú–æ—Å–∫–≤–∞")
        return

    city = context.args[0].strip()
    stopped = stop_weather_subscription(chat_id=chat_id, city=city, context=context)

    if stopped:
        await safe_reply_text(update, f"‚úÖ –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É –¥–ª—è {city} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    else:
        await safe_reply_text(update, f"‚ùå –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É –¥–ª—è {city} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")


# -------------------- EMBEDDINGS COMMAND --------------------

async def embed_create_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ .md —Ñ–∞–π–ª–∞.
    –§–æ—Ä–º–∞—Ç: /embed_create
    –ü–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ –∫–æ–º–∞–Ω–¥—ã –Ω—É–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ª—é–±–æ–π .md —Ñ–∞–π–ª –≤ —á–∞—Ç (–∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç).
    """
    if not update.message:
        return
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –æ–∂–∏–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    context.user_data["waiting_for_readme"] = True
    
    await safe_reply_text(
        update,
        "‚úÖ –û–∂–∏–¥–∞—é .md —Ñ–∞–π–ª.\n"
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±–æ–π .md —Ñ–∞–π–ª –≤ —á–∞—Ç (–∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç)."
    )


async def embed_docs_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –≤—Å–µ—Ö .md —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ docs/.
    –§–æ—Ä–º–∞—Ç: /embed_docs
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≤—Å–µ .md —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ docs/ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ.
    """
    if not update.message:
        return
    
    await update.message.chat.send_action("typing")
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–ø–∫—É docs/
        result = process_docs_folder(replace_existing=True)
        
        if not result["success"]:
            error_msg = result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
            await safe_reply_text(
                update,
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–∞–ø–∫–∏ docs/: {error_msg}\n"
                f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result.get('files_processed', 0)}/{result.get('total_files', 0)}"
            )
            return
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats = []
        stats.append(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã –¥–ª—è –ø–∞–ø–∫–∏ docs/!")
        stats.append(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result['files_processed']}/{result['total_files']}")
        stats.append(f"üì¶ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {result['total_chunks']}")
        stats.append("")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–º —Ñ–∞–π–ª–µ
        if result.get("results"):
            stats.append("üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
            for file_result in result["results"]:
                if file_result.get("status") == "success":
                    stats.append(f"  ‚úÖ {file_result['file']} ({file_result['chunks']} —á–∞–Ω–∫–æ–≤)")
                else:
                    stats.append(f"  ‚ùå {file_result['file']}: {file_result.get('error', '–û—à–∏–±–∫–∞')}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        if result.get("errors"):
            stats.append("")
            stats.append("‚ö†Ô∏è –û—à–∏–±–∫–∏:")
            for error in result["errors"][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                stats.append(f"  - {error}")
            if len(result["errors"]) > 5:
                stats.append(f"  ... –∏ –µ—â–µ {len(result['errors']) - 5} –æ—à–∏–±–æ–∫")
        
        response_text = "\n".join(stats)
        await safe_reply_text(update, response_text)
        
    except Exception as e:
        logger.exception(f"Error in embed_docs_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–∞–ø–∫–∏ docs/: {e}")


async def rag_model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–µ–∂–∏–º–∞ RAG.
    –í —ç—Ç–æ–º —Ä–µ–∂–∏–º–µ –¥–æ—Å—Ç—É–ø–Ω—ã 3 –ø–æ–¥—Ä–µ–∂–∏–º–∞: RAG+—Ñ–∏–ª—å—Ç—Ä, RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞, –ë–µ–∑ RAG.
    """
    if not update.message:
        return
    
    context.user_data["mode"] = "rag"
    context.user_data["rag_submode"] = "rag_filter"  # –†–µ–∂–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    reset_tz(context)
    reset_forest(context)
    
    await safe_reply_text(
        update,
        "‚úÖ –†–µ–∂–∏–º RAG –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω. –î–æ—Å—Ç—É–ø–Ω—ã 3 —Ä–µ–∂–∏–º–∞:\n"
        "- \"RAG+—Ñ–∏–ª—å—Ç—Ä\" –∏–ª–∏ \"RAG+—Ñ–∏–ª—å—Ç—Ä <–≤–æ–ø—Ä–æ—Å>\" - –ø–æ–∏—Å–∫ —Å –ø–æ—Ä–æ–≥–æ–º –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)\n"
        "- \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞\" –∏–ª–∏ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ <–≤–æ–ø—Ä–æ—Å>\" - –ø–æ–∏—Å–∫ –±–µ–∑ –ø–æ—Ä–æ–≥–∞\n"
        "- \"–ë–µ–∑ RAG\" –∏–ª–∏ \"–ë–µ–∑ RAG <–≤–æ–ø—Ä–æ—Å>\" - –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ø–æ–∏—Å–∫–∞\n\n"
        "–ü–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ä–µ–∂–∏–º–∞ –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã - —Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è."
    )


async def on_document(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç .md —Ñ–∞–π–ª—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ JSON —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
    """
    if not update.message or not update.message.document:
        return
    
    document = update.message.document
    file_name = document.file_name or ""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º analyze –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É JSON —Ñ–∞–π–ª–æ–≤
    mode = context.user_data.get("mode")
    if mode == "analyze" and file_name.lower().endswith(".json"):
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            file = await context.bot.get_file(document.file_id)
            
            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            file_content_bytes = await file.download_as_bytearray()
            file_content = file_content_bytes.decode("utf-8", errors="replace")
            
            # –ü–∞—Ä—Å–∏–º JSON –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            try:
                json.loads(file_content)
            except json.JSONDecodeError as e:
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON. {str(e)}")
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ JSON
            context.user_data["analyze_json_content"] = file_content
            
            await safe_reply_text(
                update,
                "–§–∞–π–ª –ø–æ–ª—É—á–µ–Ω! –ß—Ç–æ —Ö–æ—á–µ—à—å —É–∑–Ω–∞—Ç—å? –ù–∞–ø—Ä–∏–º–µ—Ä: –∫–∞–∫–∞—è –æ—à–∏–±–∫–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—â–µ –≤—Å–µ–≥–æ?"
            )
        except Exception as e:
            logger.exception(f"Error processing JSON file {file_name}: {e}")
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_name}: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ .md —Ñ–∞–π–ª
    if not file_name.lower().endswith(".md"):
        return  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –Ω–µ .md —Ñ–æ—Ä–º–∞—Ç–∞
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ–∂–∏–¥–∞–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –¥–ª—è embed_create
    waiting_for_readme = context.user_data.get("waiting_for_readme", False)
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file = await context.bot.get_file(document.file_id)
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        file_content_bytes = await file.download_as_bytearray()
        file_content = file_content_bytes.decode("utf-8", errors="replace")
        
        # –ï—Å–ª–∏ –æ–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª –¥–ª—è embed_create, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ–≥–æ —Å—Ä–∞–∑—É
        if waiting_for_readme:
            # –£–±–∏—Ä–∞–µ–º —Ñ–ª–∞–≥ –æ–∂–∏–¥–∞–Ω–∏—è
            context.user_data.pop("waiting_for_readme", None)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            await update.message.chat.send_action("typing")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
            result = process_readme_file(
                file_content=file_content,
                doc_name=file_name,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
                replace_existing=True,  # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ
            )
            
            if not result["success"]:
                error_msg = result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {error_msg}")
                return
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
            stats = []
            stats.append(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã!")
            stats.append(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç: {result['doc_name']}")
            stats.append(f"üìä –°–∏–º–≤–æ–ª–æ–≤: {result['text_length']}")
            stats.append(f"üì¶ –ß–∞–Ω–∫–æ–≤: {result['chunks_count']}")
            stats.append(f"üî¢ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {result['embedding_dim']}")
            stats.append(f"ü§ñ –ú–æ–¥–µ–ª—å: {result['model']}")
            stats.append("")
            stats.append("üìù –ü—Ä–µ–≤—å—é –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞:")
            stats.append(result['first_chunk_preview'])
            stats.append("")
            stats.append("üî¢ –ü–µ—Ä–≤—ã–µ 10 —á–∏—Å–µ–ª –ø–µ—Ä–≤–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞:")
            first_vec_preview = ", ".join([f"{x:.6f}" for x in result['first_embedding_preview']])
            stats.append(first_vec_preview)
            
            response_text = "\n".join(stats)
            await safe_reply_text(update, response_text)
        else:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ user_data –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–º
            context.user_data["last_readme_file"] = {
                "file_name": file_name,
                "content": file_content,
                "file_id": document.file_id,
            }
            
            # –£–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            await safe_reply_text(
                update,
                f"‚úÖ –§–∞–π–ª {file_name} –ø–æ–ª—É—á–µ–Ω ({len(file_content)} —Å–∏–º–≤–æ–ª–æ–≤).\n"
                f"–í—ã–∑–æ–≤–∏—Ç–µ /embed_create, –∑–∞—Ç–µ–º –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —ç—Ç–æ—Ç —Ñ–∞–π–ª –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."
            )
    except Exception as e:
        logger.exception(f"Error processing document {file_name}: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_name}: {e}")


# -------------------- PR REVIEW COMMAND --------------------

async def review_pr_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Pull Request —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG –∏ MCP.
    –§–æ—Ä–º–∞—Ç: /review_pr <–Ω–æ–º–µ—Ä_pr>
    –ü—Ä–∏–º–µ—Ä: /review_pr 123
    """
    if not PR_REVIEW_AVAILABLE:
        await safe_reply_text(
            update,
            "‚ùå –§—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ PR –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–∫—Ä–∏–ø—Ç review_pr.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."
        )
        return
    
    if not update.message:
        return
    
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    if not context.args or len(context.args) != 1:
        await safe_reply_text(
            update,
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /review_pr <–Ω–æ–º–µ—Ä_pr>\n"
            "–ü—Ä–∏–º–µ—Ä: /review_pr 123\n\n"
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:\n"
            "1. MCP —Å–µ—Ä–≤–µ—Ä python-sdk –∑–∞–ø—É—â–µ–Ω (http://127.0.0.1:8000/mcp)\n"
            "2. –í –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω GB_TOKEN (–∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –≤ .env)"
        )
        return
    
    try:
        pr_number = int(context.args[0])
    except ValueError:
        await safe_reply_text(update, f"‚ùå –ù–æ–º–µ—Ä PR –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º, –ø–æ–ª—É—á–µ–Ω–æ: {context.args[0]}")
        return
    
    await update.message.chat.send_action("typing")
    
    # –ü–æ–ª—É—á–∞–µ–º GitHub token –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (–ø—Ä–æ–±—É–µ–º GB_TOKEN, –∑–∞—Ç–µ–º GITHUB_TOKEN)
    github_token = os.getenv("GB_TOKEN", "").strip() or os.getenv("GITHUB_TOKEN", "").strip()
    if not github_token:
        await safe_reply_text(
            update,
            "‚ùå GitHub token –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.\n"
            "–î–æ–±–∞–≤—å—Ç–µ GB_TOKEN –∏–ª–∏ GITHUB_TOKEN –≤ .env —Ñ–∞–π–ª –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–∞–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è."
        )
        return
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (nikita_ai)
    owner = "RomAn-8"
    repo = "nikita_ai"
    
    try:
        # 1. –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ PR —á–µ—Ä–µ–∑ MCP
        await safe_reply_text(update, f"üì• –ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ PR #{pr_number}...")
        try:
            pr_info = await get_pr_info(owner, repo, pr_number, github_token)
        except ValueError as e:
            error_msg = str(e)
            if "404" in error_msg or "–Ω–µ –Ω–∞–π–¥–µ–Ω" in error_msg.lower():
                await safe_reply_text(update, f"‚ùå PR #{pr_number} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {owner}/{repo}.\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–æ–º–µ—Ä PR.")
            elif "401" in error_msg or "Unauthorized" in error_msg:
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ GitHub.\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å GB_TOKEN –≤ .env —Ñ–∞–π–ª–µ.")
            else:
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ PR:\n{error_msg}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n1. MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω (http://127.0.0.1:8000/mcp)\n2. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å GB_TOKEN")
            return
        
        try:
            pr_files = await get_pr_files(owner, repo, pr_number, github_token)
        except ValueError as e:
            error_msg = str(e)
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤ PR:\n{error_msg}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n1. MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω\n2. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å GB_TOKEN\n3. –î–æ—Å—Ç—É–ø –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é")
            return
        
        try:
            pr_diff = await get_pr_diff(owner, repo, pr_number, github_token)
        except ValueError as e:
            error_msg = str(e)
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ diff PR:\n{error_msg}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n1. MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω\n2. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å GB_TOKEN")
            return
        
        pr_title = pr_info.get("title", "N/A")
        await safe_reply_text(update, f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ PR: {pr_title}\nüìÅ –§–∞–π–ª–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–æ: {len(pr_files)}\nüîç –ò—â—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é...")
        
        # 2. –ü–æ–ª—É—á–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
        rag_context = await get_rag_context_for_pr(pr_info, pr_files, pr_diff)
        if rag_context:
            await safe_reply_text(update, "‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è\nü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ä–µ–≤—å—é...")
        else:
            await safe_reply_text(update, "‚ö†Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\nü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ä–µ–≤—å—é...")
        
        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–≤—å—é —á–µ—Ä–µ–∑ LLM
        messages = create_review_prompt(pr_info, pr_files, pr_diff, rag_context)
        review_text = chat_completion(messages, temperature=0.3, model=OPENROUTER_MODEL)
        
        if not review_text or not review_text.strip():
            await safe_reply_text(update, "‚ùå LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–µ —Ä–µ–≤—å—é.")
            return
        
        # 4. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π)
        max_length = 4000  # Telegram limit
        if len(review_text) <= max_length:
            await safe_reply_text(update, f"üìù **–†–µ–≤—å—é PR #{pr_number}:**\n\n{review_text}", parse_mode="Markdown")
        else:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å
            await safe_reply_text(update, f"üìù **–†–µ–≤—å—é PR #{pr_number}:**\n\n{review_text[:max_length]}...", parse_mode="Markdown")
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫
            remaining = review_text[max_length:]
            while remaining:
                chunk = remaining[:max_length]
                remaining = remaining[max_length:]
                await safe_reply_text(update, chunk, parse_mode="Markdown")
        
        await safe_reply_text(update, "‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        logger.exception(f"Error reviewing PR #{pr_number}: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ PR: {e}")


# -------------------- DIGEST COMMAND --------------------

async def digest_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É—Ç—Ä–µ–Ω–Ω–µ–π —Å–≤–æ–¥–∫–∏: –ø–æ–≥–æ–¥–∞ + –Ω–æ–≤–æ—Å—Ç–∏.
    –§–æ—Ä–º–∞—Ç: /digest <–≥–æ—Ä–æ–¥ –ø–æ–≥–æ–¥—ã>, <—Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π>
    –ü—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
    """
    if not update.message:
        return
    
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã: –≥–æ—Ä–æ–¥ –∏ —Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    if not context.args:
        await safe_reply_text(
            update,
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /digest <–≥–æ—Ä–æ–¥ –ø–æ–≥–æ–¥—ã>, <—Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π>\n"
            "–ü—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\n"
            "–ü—Ä–∏–º–µ—Ä: /digest –°–∞–º–∞—Ä–∞, —Å–ø–æ—Ä—Ç"
        )
        return

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç–æ–π
    full_text = " ".join(context.args)
    parts = [p.strip() for p in full_text.split(",", 1)]
    
    if len(parts) < 2:
        await safe_reply_text(
            update,
            "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /digest <–≥–æ—Ä–æ–¥>, <—Ç–µ–º–∞>\n"
            "–ü—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"
        )
        return

    city = parts[0]
    news_topic = parts[1]
    
    if not city or not news_topic:
        await safe_reply_text(update, "–ì–æ—Ä–æ–¥ –∏ —Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–∫–∞–∑–∞–Ω—ã.")
        return
    
    await update.message.chat.send_action("typing")
    
    # –°–∫–ª–æ–Ω—è–µ–º –≥–æ—Ä–æ–¥ –≤ –ø—Ä–µ–¥–ª–æ–∂–Ω—ã–π –ø–∞–¥–µ–∂ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ
    city_prep = _city_prepositional_case(city)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–≥–æ–¥—É —á–µ—Ä–µ–∑ MCP
    weather_text = await get_weather_via_mcp(city)
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ MCP (5 –Ω–æ–≤–æ—Å—Ç–µ–π)
    news_text = await get_news_via_mcp(news_topic, count=5)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º Markdown —Ñ–∞–π–ª
    from datetime import datetime, timedelta, timezone
    
    # –°–∞–º–∞—Ä—Å–∫–æ–µ –≤—Ä–µ–º—è (UTC+4)
    SAMARA_OFFSET = timedelta(hours=4)
    SAMARA_TIMEZONE = timezone(SAMARA_OFFSET)
    now = datetime.now(SAMARA_TIMEZONE)
    date_str = now.strftime("%d.%m.%Y %H:%M")
    
    markdown_content = f"""# –°–≤–æ–¥–∫–∞ –ø–æ–≥–æ–¥—ã –≤ {city_prep} –∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–µ {news_topic}
**–î–∞—Ç–∞:** {date_str}

## –ü–æ–≥–æ–¥–∞: {city}

{weather_text}

## –ù–æ–≤–æ—Å—Ç–∏: {news_topic}

{news_text}

---
*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏*
"""
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º Markdown —Ñ–∞–π–ª
    digest_dir = Path(__file__).resolve().parent / "digests"
    digest_dir.mkdir(exist_ok=True)
    filename = f"digest_{chat_id}_{now.strftime('%Y%m%d_%H%M%S')}.md"
    filepath = digest_dir / filename
    
    try:
        filepath.write_text(markdown_content, encoding="utf-8")
    except Exception as e:
        logger.exception(f"Failed to save digest file: {e}")
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ò–ò
    mode = MODE_SUMMARY
    temperature = get_temperature(context, chat_id)
    model = get_model(context, chat_id) or None
    
    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò
    system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å–≤–æ–¥–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–≥–æ–¥–µ –∏ –Ω–æ–≤–æ—Å—Ç—è—Ö.
–°–¥–µ–ª–∞–π —Å–≤–æ–¥–∫—É –∫—Ä–∞—Ç–∫–æ–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –∏ –ø—Ä–∏—è—Ç–Ω–æ–π –¥–ª—è —á—Ç–µ–Ω–∏—è.
–ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≥–æ–¥–µ –∏ –Ω–æ–≤–æ—Å—Ç—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã."""
    
    user_prompt = f"""–°–æ–∑–¥–∞–π —Å–≤–æ–¥–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö:

–ü–û–ì–û–î–ê:
{weather_text}

–ù–û–í–û–°–¢–ò:
{news_text}

–í–ê–ñ–ù–û: –ù–∞—á–Ω–∏ —Å–≤–æ–¥–∫—É —Å —Ñ—Ä–∞–∑—ã "–°–≤–æ–¥–∫–∞ –ø–æ–≥–æ–¥—ã –≤ {city_prep} –∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–µ {news_topic}!" (–±–µ–∑ –∫–∞–≤—ã—á–µ–∫).
–ó–∞—Ç–µ–º —Å—Ñ–æ—Ä–º–∏—Ä—É–π –∫—Ä–∞—Ç–∫—É—é –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—É—é —Å–≤–æ–¥–∫—É, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–≥–æ–¥—É –∏ –Ω–æ–≤–æ—Å—Ç–∏."""
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò —á–µ—Ä–µ–∑ mode_summary
    try:
        messages = build_messages_with_summary(system_prompt, chat_id=chat_id, mode=mode)
        messages.append({"role": "user", "content": user_prompt})
        
        data = chat_completion_raw(messages, temperature=temperature, model=model)
        ai_response = _get_content_from_raw(data)
        
        if not ai_response:
            ai_response = f"–ü–æ–≥–æ–¥–∞: {weather_text}\n\n–ù–æ–≤–æ—Å—Ç–∏: {news_text}"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        db_add_message(chat_id, mode, "user", f"/digest {city}, {news_topic}")
        db_add_message(chat_id, mode, "assistant", ai_response)
        
        # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        try:
            maybe_compress_history(chat_id, temperature=0.0, mode=mode)
        except Exception:
            pass
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò
        await safe_reply_text(update, ai_response)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º Markdown —Ñ–∞–π–ª
        try:
            with open(filepath, "rb") as f:
                await update.message.reply_document(
                    document=f,
                    filename=filename,
                    caption=f"üìÑ Markdown —Ñ–∞–π–ª —Å–æ —Å–≤–æ–¥–∫–æ–π: {city}, {news_topic}"
                )
        except Exception as e:
            logger.exception(f"Failed to send digest file: {e}")
            await safe_reply_text(update, f"‚ö†Ô∏è –°–≤–æ–¥–∫–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª: {e}")
    
    except Exception as e:
        logger.exception(f"Failed to generate digest: {e}")
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–≤–æ–¥–∫–∏: {e}")


# -------------------- TZ FLOW --------------------

async def send_final_tz_json(update: Update, context: ContextTypes.DEFAULT_TYPE, raw: str, temperature: float, model: str | None) -> None:
    try:
        json_str = extract_json_object(raw)
        data = json.loads(json_str)
        payload = normalize_payload(data)
    except Exception:
        try:
            fixed_raw = repair_json_with_model(SYSTEM_PROMPT_TZ, raw, temperature=temperature, model=model)
            json_str = extract_json_object(fixed_raw)
            data = json.loads(json_str)
            payload = normalize_payload(data)
        except Exception as e2:
            err_payload = {
                "title": "–û—à–∏–±–∫–∞",
                "time": utc_now_iso(),
                "tag": "error",
                "answer": "–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–ø–∞—Ä—Å–∏—Ä—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¢–ó.",
                "steps": [],
                "warnings": [str(e2)],
                "need_clarification": False,
                "clarifying_question": "",
            }
            await safe_reply_text(update, json.dumps(err_payload, ensure_ascii=False, indent=2))
            return

    context.user_data["tz_done"] = True
    context.user_data["last_payload"] = payload
    await safe_reply_text(update, json.dumps(payload, ensure_ascii=False, indent=2))


async def handle_tz_message(update: Update, context: ContextTypes.DEFAULT_TYPE, user_text: str, temperature: float, model: str | None) -> None:
    if context.user_data.get("tz_done"):
        await safe_reply_text(update, "–¢–ó —É–∂–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –∑–∞–Ω–æ–≤–æ ‚Äî –≤—ã–∑–æ–≤–∏ /tz_creation_site.")
        return

    history = context.user_data.get("tz_history", [])
    questions_asked = int(context.user_data.get("tz_questions", 0))

    history.append({"role": "user", "content": user_text})

    force_finalize = questions_asked >= 4

    messages = [{"role": "system", "content": SYSTEM_PROMPT_TZ}]
    messages.extend(history)
    if force_finalize:
        messages.append({"role": "user", "content": "–°—Ñ–æ—Ä–º–∏—Ä—É–π —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –¢–ó –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON –ø–æ —Å—Ö–µ–º–µ."})

    try:
        raw = (chat_completion(messages, temperature=temperature, model=model) or "").strip()
    except Exception as e:
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
        return

    if looks_like_json(raw):
        await send_final_tz_json(update, context, raw, temperature=temperature, model=model)
        return

    history.append({"role": "assistant", "content": raw})
    context.user_data["tz_history"] = history
    context.user_data["tz_questions"] = questions_asked + 1
    await safe_reply_text(update, raw)


# -------------------- FOREST FLOW --------------------

async def handle_forest_message(update: Update, context: ContextTypes.DEFAULT_TYPE, user_text: str, temperature: float, model: str | None) -> None:
    if context.user_data.get("forest_done"):
        if user_asked_to_show_result(user_text):
            res = (context.user_data.get("forest_result") or "").strip()
            if res:
                await safe_reply_text(update, res)
            else:
                await safe_reply_text(update, "–†–∞—Å—á—ë—Ç –≥–æ—Ç–æ–≤, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω. –ó–∞–ø—É—Å—Ç–∏ /forest_split –∑–∞–Ω–æ–≤–æ.")
            return
        await safe_reply_text(update, "–†–∞—Å—á—ë—Ç —É–∂–µ –≥–æ—Ç–æ–≤. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –∑–∞–Ω–æ–≤–æ ‚Äî –≤—ã–∑–æ–≤–∏ /forest_split.")
        return

    history = context.user_data.get("forest_history", [])
    questions_asked = int(context.user_data.get("forest_questions", 0))

    history.append({"role": "user", "content": user_text})

    force_finalize = questions_asked >= 6

    messages = [{"role": "system", "content": SYSTEM_PROMPT_FOREST}]
    messages.extend(history)
    if force_finalize:
        messages.append({
            "role": "user",
            "content": "–•–≤–∞—Ç–∏—Ç –≤–æ–ø—Ä–æ—Å–æ–≤. –°—Ñ–æ—Ä–º–∏—Ä—É–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å. –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ FINAL, –¥–∞–ª–µ–µ –æ—Ç—á—ë—Ç —Ç–µ–∫—Å—Ç–æ–º."
        })

    try:
        raw = (chat_completion(messages, temperature=temperature, model=model) or "").strip()
    except Exception as e:
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
        return

    if not raw:
        await safe_reply_text(update, "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏.")
        return

    if is_forest_final(raw):
        report = strip_forest_final_marker(raw)
        if not report:
            await safe_reply_text(update, "–û—à–∏–±–∫–∞: —Ñ–∏–Ω–∞–ª –±–µ–∑ –æ—Ç—á—ë—Ç–∞. –ó–∞–ø—É—Å—Ç–∏ /forest_split –∑–∞–Ω–æ–≤–æ.")
            return

        context.user_data["forest_done"] = True
        context.user_data["forest_result"] = report
        history.append({"role": "assistant", "content": raw})
        context.user_data["forest_history"] = history
        await safe_reply_text(update, report)
        return

    history.append({"role": "assistant", "content": raw})
    context.user_data["forest_history"] = history
    context.user_data["forest_questions"] = questions_asked + 1
    await safe_reply_text(update, raw)


# -------------------- MAIN TEXT HANDLER --------------------

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not update.message:
        return

    text = (update.message.text or "").strip()
    if not text:
        return

    # –ø–µ—Ä–µ—Ö–≤–∞—Ç —Ä–µ–∂–∏–º–∞ —Ç–µ—Å—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
    if await tokens_test_intercept(update, context, text):
        return

    await update.message.chat.send_action("typing")

    mode = get_mode(context)
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    temperature = get_temperature(context, chat_id)
    memory_enabled = get_memory_enabled(context, chat_id)
    model = get_model(context, chat_id) or None

    if mode == "tz":
        await handle_tz_message(update, context, text, temperature=temperature, model=model)
        return

    if mode == "forest":
        await handle_forest_message(update, context, text, temperature=temperature, model=model)
        return

    # ---- TASK LIST MODE ----
    if mode == "task_list":
        await handle_task_list_message(update, context, text, temperature=temperature, model=model)
        return

    # ---- LOCAL MODEL MODE (OLLAMA) ----
    if mode == "local_model":
        text_lower = text.lower().strip()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–æ–≤–µ—Å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
        # –ò–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
        temp_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É\s+([\d.]+)', text_lower)
        if temp_match:
            try:
                new_temp = float(temp_match.group(1))
                if 0.0 <= new_temp <= 2.0:
                    context.user_data["ollama_temperature"] = new_temp
                    await safe_reply_text(update, f"‚úÖ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {new_temp}")
                else:
                    await safe_reply_text(update, "‚ùå –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0.0 –¥–æ 2.0")
                return
            except ValueError:
                await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã")
                return
        
        # –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ
        ctx_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ\s+–æ–∫–Ω–æ\s+(\d+)', text_lower)
        if ctx_match:
            try:
                new_ctx = int(ctx_match.group(1))
                if new_ctx > 0:
                    context.user_data["ollama_num_ctx"] = new_ctx
                    await safe_reply_text(update, f"‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ {new_ctx}")
                else:
                    await safe_reply_text(update, "‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
                return
            except ValueError:
                await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞")
                return
        
        # –ò–∑–º–µ–Ω–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
        predict_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+–º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é\s+–¥–ª–∏–Ω—É\s+–æ—Ç–≤–µ—Ç–∞\s+(\d+)', text_lower)
        if predict_match:
            try:
                new_predict = int(predict_match.group(1))
                if new_predict > 0:
                    context.user_data["ollama_num_predict"] = new_predict
                    await safe_reply_text(update, f"‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {new_predict}")
                else:
                    await safe_reply_text(update, "‚ùå –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
                return
            except ValueError:
                await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞")
                return
        
        # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if "–ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏" in text_lower or "–ø–æ–∫–∞–∑–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" in text_lower:
            settings_text = _get_ollama_settings_display(context.user_data)
            await safe_reply_text(update, settings_text)
            return
        
        # –°–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if "—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏" in text_lower or "—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" in text_lower:
            # –£–¥–∞–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            context.user_data.pop("ollama_temperature", None)
            context.user_data.pop("ollama_num_ctx", None)
            context.user_data.pop("ollama_num_predict", None)
            context.user_data.pop("ollama_system_prompt", None)
            settings_text = _get_ollama_settings_display(context.user_data)
            await safe_reply_text(update, f"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–±—Ä–æ—à–µ–Ω—ã –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:\n\n{settings_text}")
            return
        
        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –∫–æ–º–∞–Ω–¥–∞ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ –º–æ–¥–µ–ª—å
        try:
            answer = await send_to_ollama(text, context.user_data)
            await safe_reply_text(update, answer)
        except ValueError as e:
            # –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–ª–∏ –æ—Ç –º–æ–¥–µ–ª–∏
            await safe_reply_text(update, f"‚ùå {str(e)}\n\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–∞–Ω–¥–æ–π: —Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
        except ConnectionError as e:
            await safe_reply_text(update, f"‚ùå {str(e)}")
        except Exception as e:
            logger.exception("Error in local_model mode")
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return

    # ---- ANALYZE MODE ----
    if mode == "analyze":
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö
        json_content = context.user_data.get("analyze_json_content")
        if not json_content:
            await safe_reply_text(update, "‚ùå JSON —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –û—Ç–ø—Ä–∞–≤—å JSON —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            return
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Ollama –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        try:
            answer = await send_to_ollama_analyze(json_content, text)
            await safe_reply_text(update, answer)
        except ConnectionError as e:
            await safe_reply_text(update, f"‚ùå {str(e)}")
        except ValueError as e:
            await safe_reply_text(update, f"‚ùå {str(e)}")
        except Exception as e:
            logger.exception("Error in analyze mode")
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return

    # ---- ME MODE (PERSONAL ASSISTANT) ----
    if mode == "me":
        text_lower = text.lower().strip()
        
        # –ö–æ–º–∞–Ω–¥–∞ "–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å [—Ç–µ–∫—Å—Ç]"
        update_profile_match = re.match(r'^–æ–±–Ω–æ–≤–∏—Ç—å\s+–ø—Ä–æ—Ñ–∏–ª—å\s+(.+)$', text, re.IGNORECASE)
        if update_profile_match:
            update_text = update_profile_match.group(1).strip()
            if not update_text:
                await safe_reply_text(update, "‚ùå –£–∫–∞–∂–∏—Ç–µ —Ç–µ–∫—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–µ–±–µ –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã '–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å'")
                return
            
            try:
                await safe_reply_text(update, "‚è≥ –û–±–Ω–æ–≤–ª—è—é –ø—Ä–æ—Ñ–∏–ª—å...")
                updated_profile = update_profile_from_text(update_text)
                save_user_profile(updated_profile)
                await safe_reply_text(update, "‚úÖ –ü—Ä–æ—Ñ–∏–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω!")
            except ValueError as e:
                await safe_reply_text(update, f"‚ùå {str(e)}")
            except Exception as e:
                logger.exception("Error updating profile")
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è: {str(e)}")
            return
        
        # –ö–æ–º–∞–Ω–¥–∞ "–ö—Ç–æ —è?"
        if text_lower == "–∫—Ç–æ —è?" or text_lower == "–∫—Ç–æ —è":
            try:
                profile = load_user_profile()
                
                profile_text = "üë§ **–í–∞—à –ø—Ä–æ—Ñ–∏–ª—å:**\n\n"
                
                if profile.get("name"):
                    profile_text += f"**–ò–º—è:** {profile['name']}\n"
                
                if profile.get("interests"):
                    interests_str = ", ".join(profile["interests"]) if isinstance(profile["interests"], list) else str(profile["interests"])
                    profile_text += f"**–ò–Ω—Ç–µ—Ä–µ—Å—ã:** {interests_str}\n"
                
                if profile.get("communication_style"):
                    profile_text += f"**–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:** {profile['communication_style']}\n"
                
                if profile.get("habits"):
                    habits_str = ", ".join(profile["habits"]) if isinstance(profile["habits"], list) else str(profile["habits"])
                    profile_text += f"**–ü—Ä–∏–≤—ã—á–∫–∏:** {habits_str}\n"
                
                if profile.get("preferences") and isinstance(profile["preferences"], dict) and profile["preferences"]:
                    prefs_str = ", ".join([f"{k}: {v}" for k, v in profile["preferences"].items()])
                    profile_text += f"**–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è:** {prefs_str}\n"
                
                # –ï—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –ø—É—Å—Ç–æ–π
                if not any([profile.get("name"), profile.get("interests"), profile.get("communication_style"), 
                           profile.get("habits"), (profile.get("preferences") and profile["preferences"])]):
                    profile_text += "–ü—Ä–æ—Ñ–∏–ª—å –ø–æ–∫–∞ –ø—É—Å—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É '–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å [—Ç–µ–∫—Å—Ç]' –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–µ–±–µ."
                
                await safe_reply_text(update, profile_text)
            except Exception as e:
                logger.exception("Error loading profile for display")
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–æ—Ñ–∏–ª—è: {str(e)}")
            return
        
        # –û–±—ã—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenRouter —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å
            profile = load_user_profile()
            
            # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_prompt = build_me_system_prompt(profile)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ]
            
            logger.debug(f"ME mode: sending request to model {ME_MODEL}, messages count: {len(messages)}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ OpenRouter
            answer = chat_completion(messages, temperature=temperature, model=ME_MODEL)
            
            if not answer:
                await safe_reply_text(update, "‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                return
            
            await safe_reply_text(update, answer)
        except requests.exceptions.HTTPError as e:
            error_msg = str(e)
            if "400" in error_msg or "Bad Request" in error_msg:
                await safe_reply_text(
                    update,
                    f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ {ME_MODEL}.\n"
                    f"–í–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –Ω–µ–≤–µ—Ä–Ω–æ.\n"
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É ME_MODEL –≤ .env —Ñ–∞–π–ª–µ.\n\n"
                    f"–î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            else:
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ API: {error_msg}")
            logger.exception("HTTPError in me mode")
        except ValueError as e:
            await safe_reply_text(update, f"‚ùå {str(e)}")
        except Exception as e:
            logger.exception("Error in me mode")
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return

    # ---- RAG MODE ----
    if mode == "rag":
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø–æ–¥—Ä–µ–∂–∏–º –∏–ª–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        rag_submode = context.user_data.get("rag_submode", "rag_filter")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–∞–Ω–¥—ã –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞
        question_text = None
        new_submode = None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º "RAG+—Ñ–∏–ª—å—Ç—Ä" –∏–ª–∏ "RAG —Ñ–∏–ª—å—Ç—Ä"
        rag_filter_match = re.match(r"^rag\+?—Ñ–∏–ª—å—Ç—Ä(?:\s+(.+))?$", text, re.IGNORECASE)
        if rag_filter_match:
            new_submode = "rag_filter"
            question_text = rag_filter_match.group(1).strip() if rag_filter_match.group(1) else None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º "RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞"
        if not new_submode:
            rag_no_filter_match = re.match(r"^rag\s+–±–µ–∑\s+—Ñ–∏–ª—å—Ç—Ä–∞(?:\s+(.+))?$", text, re.IGNORECASE)
            if rag_no_filter_match:
                new_submode = "rag_no_filter"
                question_text = rag_no_filter_match.group(1).strip() if rag_no_filter_match.group(1) else None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º "–ë–µ–∑ RAG"
        if not new_submode:
            no_rag_match = re.match(r"^–±–µ–∑\s+rag(?:\s+(.+))?$", text, re.IGNORECASE)
            if no_rag_match:
                new_submode = "no_rag"
                question_text = no_rag_match.group(1).strip() if no_rag_match.group(1) else None
        
        # –ï—Å–ª–∏ —Ä–µ–∂–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω, –æ–±–Ω–æ–≤–ª—è–µ–º –∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º
        if new_submode:
            rag_submode = new_submode
            context.user_data["rag_submode"] = rag_submode
            mode_names = {
                "rag_filter": "RAG+—Ñ–∏–ª—å—Ç—Ä",
                "rag_no_filter": "RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞",
                "no_rag": "–ë–µ–∑ RAG"
            }
            if question_text:
                # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —É–∫–∞–∑–∞–Ω —Å—Ä–∞–∑—É, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                pass
            else:
                # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º
                await safe_reply_text(update, f"‚úÖ –†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {mode_names[rag_submode]}. –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å.")
                return
        
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –±—ã–ª –∏–∑–≤–ª–µ—á–µ–Ω –∏–∑ –∫–æ–º–∞–Ω–¥—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –≤–æ–ø—Ä–æ—Å
        if question_text is None:
            question_text = text.strip()
        
        if not question_text:
            await safe_reply_text(
                update,
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—ã:\n"
                "- \"RAG+—Ñ–∏–ª—å—Ç—Ä\" –∏–ª–∏ \"RAG+—Ñ–∏–ª—å—Ç—Ä <–≤–æ–ø—Ä–æ—Å>\"\n"
                "- \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞\" –∏–ª–∏ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ <–≤–æ–ø—Ä–æ—Å>\"\n"
                "- \"–ë–µ–∑ RAG\" –∏–ª–∏ \"–ë–µ–∑ RAG <–≤–æ–ø—Ä–æ—Å>\""
            )
            return
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–¥—Ä–µ–∂–∏–º–∞
        if rag_submode == "rag_filter":
            # –†–µ–∂–∏–º RAG+—Ñ–∏–ª—å—Ç—Ä
            if not has_embeddings(EMBEDDING_MODEL):
                await safe_reply_text(
                    update,
                    "‚ö†Ô∏è –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.\n"
                    "–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /embed_create."
                )
                return
            
            try:
                relevant_chunks = search_relevant_chunks(
                    question_text,
                    model=EMBEDDING_MODEL,
                    top_k=RAG_TOP_K,
                    min_similarity=RAG_SIM_THRESHOLD,
                    apply_threshold=True
                )
            except Exception as e:
                logger.exception(f"Error searching relevant chunks: {e}")
                await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {e}")
                return
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ –ø–æ—Ä–æ–≥—É (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
            filtered_chunks = [chunk for chunk in relevant_chunks if chunk["similarity"] >= RAG_SIM_THRESHOLD]
            
            if not filtered_chunks:
                await safe_reply_text(update, "‚ö†Ô∏è –ù–µ –Ω–∞—à–ª–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")
                return
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            context_parts = ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n"]
            for i, chunk in enumerate(filtered_chunks, 1):
                context_parts.append(f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} (doc_name={chunk['doc_name']}, chunk_index={chunk['chunk_index']}, score={chunk['similarity']:.4f})]:")
                context_parts.append(chunk["text"])
                context_parts.append("")
            context_parts.append(f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question_text}")
            context_parts.append("\n–í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏ —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:")
            context_parts.append("[–§—Ä–∞–≥–º–µ–Ω—Ç N: doc_name=..., chunk_index=..., score=...]")
            context_parts.append('–¶–∏—Ç–∞—Ç–∞: "—Ç–æ—á–Ω–∞—è –¥–æ—Å–ª–æ–≤–Ω–∞—è –≤—ã–¥–µ—Ä–∂–∫–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"')
            context_parts.append("\n–í–∞–∂–Ω–æ:")
            context_parts.append("- –¶–∏—Ç–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–æ—á–Ω–æ–π –¥–æ—Å–ª–æ–≤–Ω–æ–π –≤—ã–¥–µ—Ä–∂–∫–æ–π –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (–Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ)")
            context_parts.append("- –¶–∏—Ç–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–π (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)")
            context_parts.append("- –¶–∏—Ç–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π —á–∞—Å—Ç—å—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å")
            context_parts.append("- –ö–∞–∂–¥—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Å–≤–æ—é —Ü–∏—Ç–∞—Ç—É")
            user_content = "\n".join(context_parts)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è LLM
            system_prompt = SYSTEM_PROMPT_TEXT
            if memory_enabled:
                messages = build_messages_with_db_memory(system_prompt, chat_id=chat_id)
            else:
                messages = [{"role": "system", "content": system_prompt}]
            
            messages.append({"role": "user", "content": user_content})
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            try:
                answer = chat_completion(messages, temperature=temperature, model=model)
                answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."
            except Exception as e:
                await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            db_add_message(chat_id, mode, "user", text)
            db_add_message(chat_id, mode, "assistant", answer)
            
            await safe_reply_text(update, answer)
            return
        
        elif rag_submode == "rag_no_filter":
            # –†–µ–∂–∏–º RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞
            if not has_embeddings(EMBEDDING_MODEL):
                await safe_reply_text(
                    update,
                    "‚ö†Ô∏è –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.\n"
                    "–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /embed_create."
                )
                return
            
            try:
                relevant_chunks = search_relevant_chunks(
                    question_text,
                    model=EMBEDDING_MODEL,
                    top_k=RAG_TOP_K,
                    min_similarity=0.0,
                    apply_threshold=False
                )
            except Exception as e:
                logger.exception(f"Error searching relevant chunks: {e}")
                await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {e}")
                return
            
            if not relevant_chunks:
                await safe_reply_text(update, "‚ö†Ô∏è –ù–µ –Ω–∞—à–ª–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")
                return
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            context_parts = ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n"]
            for i, chunk in enumerate(relevant_chunks, 1):
                context_parts.append(f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} (doc_name={chunk['doc_name']}, chunk_index={chunk['chunk_index']}, score={chunk['similarity']:.4f})]:")
                context_parts.append(chunk["text"])
                context_parts.append("")
            context_parts.append(f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question_text}")
            context_parts.append("\n–í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏ —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:")
            context_parts.append("[–§—Ä–∞–≥–º–µ–Ω—Ç N: doc_name=..., chunk_index=..., score=...]")
            context_parts.append('–¶–∏—Ç–∞—Ç–∞: "—Ç–æ—á–Ω–∞—è –¥–æ—Å–ª–æ–≤–Ω–∞—è –≤—ã–¥–µ—Ä–∂–∫–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"')
            context_parts.append("\n–í–∞–∂–Ω–æ:")
            context_parts.append("- –¶–∏—Ç–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–æ—á–Ω–æ–π –¥–æ—Å–ª–æ–≤–Ω–æ–π –≤—ã–¥–µ—Ä–∂–∫–æ–π –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (–Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ)")
            context_parts.append("- –¶–∏—Ç–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–π (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)")
            context_parts.append("- –¶–∏—Ç–∞—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π —á–∞—Å—Ç—å—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å")
            context_parts.append("- –ö–∞–∂–¥—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Å–≤–æ—é —Ü–∏—Ç–∞—Ç—É")
            user_content = "\n".join(context_parts)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è LLM
            system_prompt = SYSTEM_PROMPT_TEXT
            if memory_enabled:
                messages = build_messages_with_db_memory(system_prompt, chat_id=chat_id)
            else:
                messages = [{"role": "system", "content": system_prompt}]
            
            messages.append({"role": "user", "content": user_content})
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            try:
                answer = chat_completion(messages, temperature=temperature, model=model)
                answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."
            except Exception as e:
                await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            db_add_message(chat_id, mode, "user", text)
            db_add_message(chat_id, mode, "assistant", answer)
            
            await safe_reply_text(update, answer)
            return
        
        elif rag_submode == "no_rag":
            # –†–µ–∂–∏–º –ë–µ–∑ RAG - –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ø–æ–∏—Å–∫–∞
            system_prompt = SYSTEM_PROMPT_TEXT
            if memory_enabled:
                messages = build_messages_with_db_memory(system_prompt, chat_id=chat_id)
            else:
                messages = [{"role": "system", "content": system_prompt}]
            
            messages.append({"role": "user", "content": question_text})
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            try:
                answer = chat_completion(messages, temperature=temperature, model=model)
                answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."
            except Exception as e:
                await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            db_add_message(chat_id, mode, "user", text)
            db_add_message(chat_id, mode, "assistant", answer)
            
            await safe_reply_text(update, answer)
        return

    # ---- CHAT MODES (text/thinking/experts/summary) ----
    if mode in ("text", "thinking", "experts", MODE_SUMMARY):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∞–π—Ç–æ–º –≤ —Ä–µ–∂–∏–º–µ summary
        if mode == MODE_SUMMARY:
            # –ö–æ–º–∞–Ω–¥–∞ "–ü–æ–¥–Ω–∏–º–∏ —Å–∞–π—Ç"
            if re.match(r"^(?:–ø–æ–¥–Ω–∏–º–∏|–ø–æ–¥–Ω—è—Ç—å|–∑–∞–ø—É—Å—Ç–∏|–∑–∞–ø—É—Å—Ç–∏—Ç—å)\s+—Å–∞–π—Ç$", text, re.IGNORECASE):
                await update.message.chat.send_action("typing")
                result = await site_up_via_mcp()
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –≤ –ë–î
                db_add_message(chat_id, mode, "user", text)
                db_add_message(chat_id, mode, "assistant", result)
                # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
                try:
                    maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                except Exception:
                    pass
                await safe_reply_text(update, result)
                return
            
            # –ö–æ–º–∞–Ω–¥–∞ "–°–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω" –∏–ª–∏ "–°–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç"
            if re.match(r"^(?:—Å–¥–µ–ª–∞–π|—Å–æ–∑–¥–∞–π|—Å–Ω—è—Ç—å)\s+—Å–∫—Ä–∏–Ω(?:—à–æ—Ç)?$", text, re.IGNORECASE):
                await update.message.chat.send_action("typing")
                screenshot_path = await site_screenshot_via_mcp()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ –ë–î
                db_add_message(chat_id, mode, "user", text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ø–æ–ª—É—á–µ–Ω
                if screenshot_path and Path(screenshot_path).exists():
                    try:
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º PNG —Ñ–∞–π–ª –≤ Telegram
                        with open(screenshot_path, "rb") as f:
                            await update.message.reply_document(
                                document=f,
                                filename="site.png",
                                caption="üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–∞–π—Ç–∞"
                            )
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ë–î
                        db_add_message(chat_id, mode, "assistant", f"–°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ–∑–¥–∞–Ω: {screenshot_path}")
                    except Exception as e:
                        logger.exception(f"Failed to send screenshot: {e}")
                        await safe_reply_text(update, f"–°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ–∑–¥–∞–Ω, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å: {e}")
                else:
                    # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                    db_add_message(chat_id, mode, "assistant", screenshot_path)
                    await safe_reply_text(update, screenshot_path)
                
                # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
                try:
                    maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                except Exception:
                    pass
                return
            
            # –ö–æ–º–∞–Ω–¥–∞ "–û—Å—Ç–∞–Ω–æ–≤–∏ —Å–∞–π—Ç"
            if re.match(r"^(?:–æ—Å—Ç–∞–Ω–æ–≤–∏|–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å|–≤—ã–∫–ª—é—á–∏|–≤—ã–∫–ª—é—á–∏—Ç—å)\s+—Å–∞–π—Ç$", text, re.IGNORECASE):
                await update.message.chat.send_action("typing")
                result = await site_down_via_mcp()
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –≤ –ë–î
                db_add_message(chat_id, mode, "user", text)
                db_add_message(chat_id, mode, "assistant", result)
                # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
                try:
                    maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                except Exception:
                    pass
                await safe_reply_text(update, result)
                return
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–≥–æ–¥—ã –≤ —Ä–µ–∂–∏–º–µ summary (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ü–æ–≥–æ–¥–∞ –ú–æ—Å–∫–≤–∞" –∏–ª–∏ "–ü–æ–≥–æ–¥–∞ –°–∞–º–∞—Ä–∞")
        weather_request_handled = False
        if mode == MODE_SUMMARY:
            # –ü–∞—Ç—Ç–µ—Ä–Ω: "–ü–æ–≥–æ–¥–∞" + –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
            weather_match = re.match(r"^(?:–ø–æ–≥–æ–¥–∞|weather)\s+(.+)$", text, re.IGNORECASE)
            if weather_match:
                city = weather_match.group(1).strip()
                if city:
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–≥–æ–¥—É —á–µ—Ä–µ–∑ MCP –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    weather_text = await get_weather_via_mcp(city)
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –≤ –ë–î –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
                    db_add_message(chat_id, mode, "user", text)
                    db_add_message(chat_id, mode, "assistant", weather_text)
                    
                    # –í—ã–∑—ã–≤–∞–µ–º —Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ (–∫–∞–∫ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π)
                    try:
                        maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                    except Exception:
                        pass
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–≥–æ–¥–æ–π
                    await safe_reply_text(update, weather_text)
                    weather_request_handled = True
                    return

        if mode == "thinking":
            system_prompt = SYSTEM_PROMPT_THINKING
        elif mode == "experts":
            system_prompt = SYSTEM_PROMPT_EXPERTS
        else:
            system_prompt = SYSTEM_PROMPT_TEXT

        if memory_enabled:
            # NEW: summary-context builder
            if mode == MODE_SUMMARY:
                messages = build_messages_with_summary(system_prompt, chat_id=chat_id, mode=MODE_SUMMARY)
            else:
                messages = build_messages_with_db_memory(system_prompt, chat_id=chat_id)
        else:
            messages = [{"role": "system", "content": system_prompt}]  # –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏

        messages.append({"role": "user", "content": text})

        # SUMMARY: –Ω—É–∂–µ–Ω raw, —á—Ç–æ–±—ã –≤–∑—è—Ç—å usage
        if mode == MODE_SUMMARY:
            try:
                data = chat_completion_raw(messages, temperature=temperature, model=model)
                answer = _get_content_from_raw(data)
                pt, ct, tt = _get_usage_tokens(data)
                req_id = str(data.get("id") or "").strip()
            except Exception as e:
                await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
                return

            answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

            # –ø–∏—à–µ–º –≤ –ë–î (summary –≤—Å–µ–≥–¥–∞ —Å –ø–∞–º—è—Ç—å—é)
            db_add_message(chat_id, mode, "user", text)
            db_add_message(chat_id, mode, "assistant", answer)

            try:
                maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
            except Exception:
                pass

            # 1) –æ—Ç–≤–µ—Ç
            def fmt(x: int | None) -> str:
                return str(x) if isinstance(x, int) else "n/a"

            rid = f", id={req_id}" if req_id else ""
            combined = f"{answer}\n\n–¢–æ–∫–µ–Ω—ã: –∑–∞–ø—Ä–æ—Å={fmt(pt)}, –æ—Ç–≤–µ—Ç={fmt(ct)}, –≤—Å–µ–≥–æ={fmt(tt)}{rid}"
            await safe_reply_text(update, combined)
            return


        # –ù–ï summary ‚Äî –∫–∞–∫ –±—ã–ª–æ
        try:
            answer = (chat_completion(messages, temperature=temperature, model=model) or "").strip()
        except Exception as e:
            await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
            return

        answer = answer or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

        # –ø–∏—à–µ–º –≤ –ë–î —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–∞–º—è—Ç—å –≤–∫–ª—é—á–µ–Ω–∞
        if memory_enabled:
            db_add_message(chat_id, mode, "user", text)
            db_add_message(chat_id, mode, "assistant", answer)

        await safe_reply_text(update, answer)
        return

    # ---- JSON MODE (–±–µ–∑ –ø–∞–º—è—Ç–∏) ----
    raw = ""
    try:
        raw = chat_completion(
            [
                {"role": "system", "content": SYSTEM_PROMPT_JSON},
                {"role": "user", "content": text},
            ],
            temperature=temperature,
            model=model,
        ) or ""

        json_str = extract_json_object(raw)
        data = json.loads(json_str)
        payload = normalize_payload(data)

    except Exception:
        try:
            fixed_raw = repair_json_with_model(SYSTEM_PROMPT_JSON, raw or text, temperature=temperature, model=model)
            json_str = extract_json_object(fixed_raw)
            data = json.loads(json_str)
            payload = normalize_payload(data)
        except Exception as e2:
            err_payload = {
                "title": "–û—à–∏–±–∫–∞",
                "time": utc_now_iso(),
                "tag": "error",
                "answer": "–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–ø–∞—Ä—Å–∏—Ä—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç.",
                "steps": [],
                "warnings": [str(e2)],
                "need_clarification": False,
                "clarifying_question": "",
            }
            await safe_reply_text(update, json.dumps(err_payload, ensure_ascii=False, indent=2))
            return

    context.user_data["last_payload"] = payload
    await safe_reply_text(update, json.dumps(payload, ensure_ascii=False, indent=2))


# -------------------- GOOGLE SHEETS COMMANDS --------------------

async def register_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /register <–§–ò–û> <—Ç–µ–ª–µ—Ñ–æ–Ω>"""
    if not update.message:
        return
    
    if not context.args or len(context.args) < 2:
        await safe_reply_text(update, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /register <–§–ò–û> <—Ç–µ–ª–µ—Ñ–æ–Ω>\n–ü—Ä–∏–º–µ—Ä: /register –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á +79991234567")
        return
    
    username = update.effective_user.username
    if not username:
        await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞: —É –≤–∞—Å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω username –≤ Telegram. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ username –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Telegram –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        return
    
    fio = context.args[0]
    phone = context.args[1]
    
    # –ï—Å–ª–∏ –§–ò–û —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–≤, –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Ö
    if len(context.args) > 2:
        fio = " ".join(context.args[:-1])
        phone = context.args[-1]
    
    try:
        result = await user_register(username, fio, phone)
        if result and result.get("status") == "registered":
            await safe_reply_text(update, "‚úÖ –í—ã –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã")
        elif result and result.get("status") == "updated":
            await safe_reply_text(update, "‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
        else:
            await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏")
    except ValueError as e:
        await safe_reply_text(update, f"‚ùå {e}")
    except Exception as e:
        logger.exception(f"Error in register_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


async def unregister_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /unregister - —É–¥–∞–ª–∏—Ç—å —Å–≤–æ—é —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é"""
    if not update.message:
        return
    
    username = update.effective_user.username
    if not username:
        await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞: —É –≤–∞—Å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω username –≤ Telegram. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ username –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Telegram.")
        return
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        active_regs = []
        try:
            active_regs = await reg_find_by_user(username) or []
        except ValueError:
            pass
        
        if active_regs:
            await safe_reply_text(
                update,
                f"‚ö†Ô∏è –£ –≤–∞—Å –µ—Å—Ç—å {len(active_regs)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π. –°–Ω–∞—á–∞–ª–∞ –æ—Ç–º–µ–Ω–∏—Ç–µ –∏—Ö –∫–æ–º–∞–Ω–¥–æ–π /train_cancel <reg_id>"
            )
            return
        
        # –£–¥–∞–ª—è–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é
        result = await user_delete(username)
        if result:
            await safe_reply_text(update, "‚úÖ –í–∞—à–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —É–¥–∞–ª–µ–Ω–∞")
        else:
            await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏")
    except ValueError as e:
        await safe_reply_text(update, f"‚ùå {e}")
    except Exception as e:
        logger.exception(f"Error in unregister_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


async def train_signup_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /train_signup <–¥–∞—Ç–∞ DD-MM-YYYY> <–≤—Ä–µ–º—è HH:MM> [–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ]"""
    if not update.message:
        return
    
    if not context.args or len(context.args) < 2:
        await safe_reply_text(update, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /train_signup <–¥–∞—Ç–∞ DD-MM-YYYY> <–≤—Ä–µ–º—è HH:MM> [–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ]\n–ü—Ä–∏–º–µ—Ä: /train_signup 15-02-2026 18:00\n–ü—Ä–∏–º–µ—Ä —Å –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ–º: /train_signup 15-02-2026 10:00 –£–ª–∏—á–Ω–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∫—Ä–æ—Å—Å—Ñ–∏—Ç –≥–∏—Ä—è 16 –∫–≥")
        return
    
    username = update.effective_user.username
    if not username:
        await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞: —É –≤–∞—Å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω username –≤ Telegram. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ username –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Telegram.")
        return
    
    date = context.args[0]
    time = context.args[1]
    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –ø–æ—Å–ª–µ –≤—Ä–µ–º–µ–Ω–∏ - —ç—Ç–æ –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ
    note = " ".join(context.args[2:]) if len(context.args) > 2 else ""
    
    try:
        result = await reg_create(username, date, time, note)
        if result:
            reg_id = result.get("reg_id")
            row_url = result.get("row_url", "")
            response_text = f"‚úÖ –í—ã –∑–∞–ø–∏—Å–∞–Ω—ã –Ω–∞ {date} –≤ {time}\nID –∑–∞–ø–∏—Å–∏: {reg_id}"
            if note:
                response_text += f"\n–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: {note}"
            response_text += f"\n–°—Å—ã–ª–∫–∞: {row_url}"
            await safe_reply_text(update, response_text)
        else:
            await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–ø–∏—Å–∏")
    except ValueError as e:
        await safe_reply_text(update, f"‚ùå {e}")
    except Exception as e:
        logger.exception(f"Error in train_signup_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


async def train_move_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /train_move <reg_id> <–¥–∞—Ç–∞ DD-MM-YYYY> <–≤—Ä–µ–º—è HH:MM>"""
    if not update.message:
        return
    
    if not context.args or len(context.args) < 3:
        await safe_reply_text(update, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /train_move <reg_id> <–¥–∞—Ç–∞ DD-MM-YYYY> <–≤—Ä–µ–º—è HH:MM>\n–ü—Ä–∏–º–µ—Ä: /train_move 1 16-02-2026 19:00")
        return
    
    try:
        reg_id = int(context.args[0])
        new_date = context.args[1]
        new_time = context.args[2]
        
        result = await reg_reschedule(reg_id, new_date, new_time)
        if result:
            row_url = result.get("row_url", "")
            await safe_reply_text(
                update,
                f"‚úÖ –ó–∞–ø–∏—Å—å {reg_id} –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –Ω–∞ {new_date} {new_time}\n–°—Å—ã–ª–∫–∞: {row_url}"
            )
        else:
            await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–Ω–æ—Å–µ –∑–∞–ø–∏—Å–∏")
    except ValueError as e:
        await safe_reply_text(update, f"‚ùå {e}")
    except Exception as e:
        logger.exception(f"Error in train_move_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


async def train_cancel_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /train_cancel <reg_id>"""
    if not update.message:
        return
    
    if not context.args or len(context.args) < 1:
        await safe_reply_text(update, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /train_cancel <reg_id>\n–ü—Ä–∏–º–µ—Ä: /train_cancel 1")
        return
    
    try:
        reg_id = int(context.args[0])
        result = await reg_cancel(reg_id)
        if result:
            await safe_reply_text(update, f"‚úÖ –ó–∞–ø–∏—Å—å {reg_id} –æ—Ç–º–µ–Ω–µ–Ω–∞ –∏ —É–¥–∞–ª–µ–Ω–∞ –∏–∑ —Å–∏—Å—Ç–µ–º—ã")
        else:
            await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–º–µ–Ω–µ –∑–∞–ø–∏—Å–∏")
    except ValueError as e:
        await safe_reply_text(update, f"‚ùå {e}")
    except Exception as e:
        logger.exception(f"Error in train_cancel_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


async def support_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /support <–≤–æ–ø—Ä–æ—Å> - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å RAG + MCP"""
    if not update.message:
        return
    
    if not context.args:
        await safe_reply_text(update, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /support <–≤–æ–ø—Ä–æ—Å>\n–ü—Ä–∏–º–µ—Ä: /support –º–æ–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∑–∞–ø–∏—Å—å?")
        return
    
    question = " ".join(context.args)
    username = update.effective_user.username
    if not username:
        await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞: —É –≤–∞—Å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω username –≤ Telegram. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ username –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Telegram.")
        return
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ MCP
        user_data = None
        try:
            user_data = await user_get(username)
        except ValueError as e:
            logger.warning(f"Could not get user data: {e}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —á–µ—Ä–µ–∑ MCP
        active_regs = []
        try:
            active_regs = await reg_find_by_user(username) or []
            if active_regs:
                logger.info(f"Found {len(active_regs)} active registrations for user {username}: {active_regs}")
            else:
                logger.info(f"No active registrations found for user {username}")
        except ValueError as e:
            logger.warning(f"Could not get user registrations: {e}")
        
        # RAG –ø–æ–∏—Å–∫
        rag_chunks = []
        if has_embeddings(EMBEDDING_MODEL):
            try:
                rag_chunks = search_relevant_chunks(
                    question,
                    model=EMBEDDING_MODEL,
                    top_k=RAG_TOP_K,
                    min_similarity=RAG_SIM_THRESHOLD,
                    apply_threshold=True
                )
            except Exception as e:
                logger.exception(f"Error in RAG search: {e}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
        context_parts = []
        
        # –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_data:
            context_parts.append("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:")
            context_parts.append(f"- –§–ò–û: {user_data.get('fio', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ')}")
            context_parts.append(f"- –°—Ç–∞—Ç—É—Å: {user_data.get('status', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            context_parts.append(f"- –î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏: {user_data.get('date_reg', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ')}")
            context_parts.append("")
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        if active_regs:
            context_parts.append("–ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø–∏—Å–∏:")
            for reg in active_regs:
                context_parts.append(f"- –ó–∞–ø–∏—Å—å #{reg.get('reg_id')}: {reg.get('date')} {reg.get('time')}, —Å—Ç–∞—Ç—É—Å: {reg.get('status')}")
            context_parts.append("")
        
        # RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if rag_chunks:
            context_parts.append("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:")
            for i, chunk in enumerate(rag_chunks, 1):
                context_parts.append(f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} (doc_name={chunk['doc_name']}, chunk_index={chunk['chunk_index']}, score={chunk['similarity']:.4f})]:")
                context_parts.append(chunk["text"])
                context_parts.append("")
        
        context_parts.append(f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}")
        context_parts.append("")
        context_parts.append("–í–ê–ñ–ù–û: –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è:")
        context_parts.append("1. –ö–æ–º–∞–Ω–¥—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –æ –¥–µ–π—Å—Ç–≤–∏—è—Ö - —É–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∫–æ–º–∞–Ω–¥—É)")
        context_parts.append("2. –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã—à–µ (–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –µ—Å—Ç—å)")
        context_parts.append("3. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
        context_parts.append("")
        context_parts.append("–û–°–û–ë–û–ï –í–ù–ò–ú–ê–ù–ò–ï:")
        context_parts.append("- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –æ –≤—Ä–µ–º–µ–Ω–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∏–ª–∏ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ø—Ä–∏–π—Ç–∏, –í–°–ï–ì–î–ê —É–∫–∞–∑—ã–≤–∞–π, —á—Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∑–∞ 15 –º–∏–Ω—É—Ç –¥–æ –Ω–∞—á–∞–ª–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏.")
        context_parts.append("  –ù–∞–ø—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –≤ 10:00, –Ω—É–∂–Ω–æ –ø—Ä–∏–π—Ç–∏ –∫ 09:45.")
        context_parts.append("")
        context_parts.append("–í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ –ù–ï —É–∫–∞–∑—ã–≤–∞–π:")
        context_parts.append("- –î–∞–Ω–Ω—ã–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ (–æ–Ω–∏ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
        context_parts.append("- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–æ–Ω–∏ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
        context_parts.append("–ü—Ä–æ—Å—Ç–æ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã—à–µ.")
        
        user_content = "\n".join(context_parts)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è LLM
        system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –∑–∞–ø–∏—Å–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏. 

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
2. –ï—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –µ—Å—Ç—å –∫–æ–º–∞–Ω–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, /train_move, /train_cancel, /train_signup), –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É–∫–∞–∂–∏ –µ—ë –≤ –æ—Ç–≤–µ—Ç–µ
3. –ù–ï –≥–æ–≤–æ—Ä–∏ "–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É", –µ—Å–ª–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –µ—Å—Ç—å —Å–ø–æ—Å–æ–± —Ä–µ—à–∏—Ç—å –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞
4. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ–≥–æ –∑–∞–ø–∏—Å–∏, reg_id, –¥–∞—Ç—ã, –≤—Ä–µ–º—è)
5. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –¥–∞–≤–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
6. –í–ê–ñ–ù–û: –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –≤—Ä–µ–º–µ–Ω–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∏–ª–∏ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ø—Ä–∏–π—Ç–∏, –í–°–ï–ì–î–ê —É–∫–∞–∑—ã–≤–∞–π, —á—Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∑–∞ 15 –º–∏–Ω—É—Ç –¥–æ –Ω–∞—á–∞–ª–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –≤ 10:00, –Ω—É–∂–Ω–æ –ø—Ä–∏–π—Ç–∏ –∫ 09:45.

–û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∫–æ–º–∞–Ω–¥—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
        messages = [{"role": "system", "content": system_prompt}]
        messages.append({"role": "user", "content": user_content})
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
        try:
            answer = chat_completion(messages, temperature=0.7, model=OPENROUTER_MODEL)
            answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."
        except Exception as e:
            await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
            return
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –∏ –¥–∞–Ω–Ω—ã–º–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        response_parts = [answer]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        if rag_chunks:
            response_parts.append("")
            response_parts.append("üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
            for chunk in rag_chunks:
                # –ë–µ—Ä–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Ü–∏—Ç–∞—Ç—É (–¥–æ 120 —Å–∏–º–≤–æ–ª–æ–≤, –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
                chunk_text = chunk["text"]
                # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                chunk_text = " ".join(chunk_text.split())
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–ª–∏ –ø–µ—Ä–≤—ã–µ 120 —Å–∏–º–≤–æ–ª–æ–≤
                sentences = chunk_text.split(". ")
                if sentences:
                    quote = sentences[0]
                    if len(quote) > 120:
                        quote = quote[:120] + "..."
                    elif len(sentences) > 1 and len(quote) < 80:
                        # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–æ–µ, –¥–æ–±–∞–≤–ª—è–µ–º –≤—Ç–æ—Ä–æ–µ
                        quote = ". ".join(sentences[:2])
                        if len(quote) > 120:
                            quote = quote[:120] + "..."
                    if not quote.endswith(".") and not quote.endswith("..."):
                        quote += "."
                else:
                    quote = chunk_text[:120] + "..." if len(chunk_text) > 120 else chunk_text
                
                # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: (doc_name, chunk_index, score, —Ü–∏—Ç–∞—Ç–∞)
                response_parts.append(f"({chunk['doc_name']}, chunk_index={chunk['chunk_index']}, score={chunk['similarity']:.4f}, —Ü–∏—Ç–∞—Ç–∞=\"{quote}\")")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        if active_regs:
            response_parts.append("")
            response_parts.append("üìÖ –î–∞–Ω–Ω—ã–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏:")
            for reg in active_regs:
                reg_id = reg.get('reg_id') or '–Ω–µ —É–∫–∞–∑–∞–Ω'
                date = reg.get('date') or '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'
                time = reg.get('time') or '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'
                status = reg.get('status') or '–Ω–µ —É–∫–∞–∑–∞–Ω'
                response_parts.append(f"- –ó–∞–ø–∏—Å—å #{reg_id}: {date} {time}, —Å—Ç–∞—Ç—É—Å: {status}")
        elif user_data:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å, –Ω–æ –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π
            response_parts.append("")
            response_parts.append("üìÖ –î–∞–Ω–Ω—ã–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏:")
            response_parts.append("- –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /train_signup –¥–ª—è –∑–∞–ø–∏—Å–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É.")
        
        final_response = "\n".join(response_parts)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç (—Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π)
        await safe_reply_text(update, final_response)
        
    except Exception as e:
        logger.exception(f"Error in support_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏: {e}")


async def task_list_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /task_list - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏"""
    if not update.message:
        return
    
    context.user_data["mode"] = "task_list"
    reset_tz(context)
    reset_forest(context)
    
    welcome_text = """‚úÖ –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!

–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–ª–æ–≤–µ—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏:

üìù –ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥:
‚Ä¢ "–°–æ–∑–¥–∞–π –∑–∞–¥–∞—á—É –Ω–∞ 15-02-2026 –≤ 10:00 —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º high: –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é"
‚Ä¢ "–ü–æ–∫–∞–∂–∏ –∑–∞–¥–∞—á–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º high"
‚Ä¢ "–ü–æ–∫–∞–∂–∏ –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏"
‚Ä¢ "–£–¥–∞–ª–∏ –∑–∞–¥–∞—á—É –≤ —Å—Ç—Ä–æ–∫–µ 5"
‚Ä¢ "–ü–æ–∫–∞–∂–∏ –∑–∞–¥–∞—á–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º high –∏ –ø—Ä–µ–¥–ª–æ–∂–∏, —á—Ç–æ –¥–µ–ª–∞—Ç—å –ø–µ—Ä–≤—ã–º"

–î–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /cancel –∏–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç–µ—Å—å –Ω–∞ –¥—Ä—É–≥–æ–π —Ä–µ–∂–∏–º."""
    
    await safe_reply_text(update, welcome_text)


async def deploy_bot_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /deploy_bot - –¥–µ–ø–ª–æ–π –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä"""
    if not update.message:
        return
    
    try:
        # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –¥–µ–ø–ª–æ—è
        deploy_ssh_host = os.getenv("DEPLOY_SSH_HOST", "").strip()
        deploy_ssh_port = int(os.getenv("DEPLOY_SSH_PORT", "22"))
        deploy_ssh_username = os.getenv("DEPLOY_SSH_USERNAME", "").strip()
        deploy_ssh_password = os.getenv("DEPLOY_SSH_PASSWORD", "").strip()
        deploy_image_tar_path = os.getenv("DEPLOY_IMAGE_TAR_PATH", "").strip()
        deploy_remote_path = os.getenv("DEPLOY_REMOTE_PATH", "/opt/nikita_ai").strip()
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –±–æ—Ç–∞ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±–æ—Ç–∞)
        deploy_bot_token = os.getenv("DEPLOY_BOT_TOKEN", "").strip()
        
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑ config.py (—Ç–µ –∂–µ, —á—Ç–æ –∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±–æ—Ç–∞)
        deploy_openrouter_api_key = OPENROUTER_API_KEY
        deploy_openrouter_model = OPENROUTER_MODEL
        deploy_embedding_model = EMBEDDING_MODEL
        deploy_rag_sim_threshold = str(RAG_SIM_THRESHOLD)
        deploy_rag_top_k = str(RAG_TOP_K)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞
        deploy_ollama_base_url = "http://127.0.0.1:11434"  # –õ–æ–∫–∞–ª—å–Ω—ã–π –∞–¥—Ä–µ—Å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
        deploy_ollama_model = OLLAMA_MODEL  # –ò–∑ config.py (–º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º .env)
        deploy_ollama_timeout = str(OLLAMA_TIMEOUT)  # –ò–∑ config.py
        deploy_ollama_temperature = str(OLLAMA_TEMPERATURE)  # –ò–∑ config.py
        deploy_ollama_num_ctx = str(OLLAMA_NUM_CTX)  # –ò–∑ config.py
        deploy_ollama_num_predict = str(OLLAMA_NUM_PREDICT)  # –ò–∑ config.py
        deploy_ollama_system_prompt = OLLAMA_SYSTEM_PROMPT  # –ò–∑ config.py
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        missing_vars = []
        if not deploy_ssh_host:
            missing_vars.append("DEPLOY_SSH_HOST")
        if not deploy_ssh_username:
            missing_vars.append("DEPLOY_SSH_USERNAME")
        if not deploy_ssh_password:
            missing_vars.append("DEPLOY_SSH_PASSWORD")
        if not deploy_image_tar_path:
            missing_vars.append("DEPLOY_IMAGE_TAR_PATH")
        if not deploy_bot_token:
            missing_vars.append("DEPLOY_BOT_TOKEN")
        
        if missing_vars:
            await safe_reply_text(
                update,
                f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:\n" + "\n".join(f"‚Ä¢ {var}" for var in missing_vars)
            )
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –æ–±—Ä–∞–∑–∞
        image_path = Path(deploy_image_tar_path)
        if not image_path.exists():
            await safe_reply_text(update, f"‚ùå –§–∞–π–ª –æ–±—Ä–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {deploy_image_tar_path}")
            return
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è –æ–±—Ä–∞–∑–∞ (–¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –∏–º–µ–Ω–µ–º –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ .tar)
        image_name = "nikita_ai"  # –ò–º—è –æ–±—Ä–∞–∑–∞ —Å –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ–º (–∫–∞–∫ –≤ docker save)
        image_tag = "latest"
        
        await safe_reply_text(update, "üöÄ –ù–∞—á–∏–Ω–∞—é –¥–µ–ø–ª–æ–π –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä...")
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞/—É—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker
        await safe_reply_text(update, "üì¶ –ü—Ä–æ–≤–µ—Ä—è—é –Ω–∞–ª–∏—á–∏–µ Docker –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ...")
        docker_result = await deploy_check_docker(deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password)
        if not docker_result or docker_result.get("status") != "installed":
            error_msg = docker_result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if docker_result else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ Docker"
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ Docker: {error_msg}")
            return
        await safe_reply_text(update, f"‚úÖ {docker_result.get('message', 'Docker –≥–æ—Ç–æ–≤')}")
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–∑–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
        remote_image_path = f"{deploy_remote_path}/{image_path.name}"
        await safe_reply_text(update, f"üì§ –ó–∞–≥—Ä—É–∂–∞—é –æ–±—Ä–∞–∑ –Ω–∞ —Å–µ—Ä–≤–µ—Ä: {deploy_image_tar_path}...")
        upload_result = await deploy_upload_image(
            deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
            deploy_image_tar_path, remote_image_path
        )
        if not upload_result or upload_result.get("status") != "success":
            error_msg = upload_result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if upload_result else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–±—Ä–∞–∑–∞"
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–±—Ä–∞–∑–∞: {error_msg}")
            return
        await safe_reply_text(update, f"‚úÖ {upload_result.get('message', '–û–±—Ä–∞–∑ –∑–∞–≥—Ä—É–∂–µ–Ω')}")
        
        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–∑–∞ –≤ Docker
        await safe_reply_text(update, "üê≥ –ó–∞–≥—Ä—É–∂–∞—é –æ–±—Ä–∞–∑ –≤ Docker...")
        load_result = await deploy_load_image(
            deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
            remote_image_path
        )
        if not load_result or load_result.get("status") != "success":
            error_msg = load_result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if load_result else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–±—Ä–∞–∑–∞ –≤ Docker"
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–±—Ä–∞–∑–∞ –≤ Docker: {error_msg}")
            return
        await safe_reply_text(update, f"‚úÖ {load_result.get('message', '–û–±—Ä–∞–∑ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Docker')}")
        
        # 4. –°–æ–∑–¥–∞–Ω–∏–µ docker-compose.yml
        compose_path = f"{deploy_remote_path}/docker-compose.yml"
        compose_content = f"""services:
  bot:
    image: {image_name}:{image_tag}
    container_name: nikita_ai_bot
    restart: unless-stopped
    network_mode: host
    env_file:
      - .env
    environment:
      - DB_PATH=/app/data/bot_memory.sqlite3
    volumes:
      - ./data:/app/data
      - ./digests:/app/bot/digests
    user: "0:0"
"""
        await safe_reply_text(update, "üìù –°–æ–∑–¥–∞—é docker-compose.yml...")
        compose_result = await deploy_create_compose(
            deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
            compose_content, compose_path
        )
        if not compose_result or compose_result.get("status") != "success":
            error_msg = compose_result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if compose_result else "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ docker-compose.yml"
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ docker-compose.yml: {error_msg}")
            return
        compose_msg = compose_result.get('message', 'docker-compose.yml —Å–æ–∑–¥–∞–Ω')
        if compose_result.get('skipped'):
            await safe_reply_text(update, f"‚è≠Ô∏è {compose_msg}")
        else:
            await safe_reply_text(update, f"‚úÖ {compose_msg}")
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ .env —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –±–æ—Ç–∞
        env_path = f"{deploy_remote_path}/.env"
        env_content = f"""TELEGRAM_BOT_TOKEN={deploy_bot_token}
OPENROUTER_API_KEY={deploy_openrouter_api_key}
OPENROUTER_MODEL={deploy_openrouter_model}
EMBEDDING_MODEL={deploy_embedding_model}
RAG_SIM_THRESHOLD={deploy_rag_sim_threshold}
RAG_TOP_K={deploy_rag_top_k}
OLLAMA_BASE_URL={deploy_ollama_base_url}
OLLAMA_MODEL={deploy_ollama_model}
OLLAMA_TIMEOUT={deploy_ollama_timeout}
OLLAMA_TEMPERATURE={deploy_ollama_temperature}
OLLAMA_NUM_CTX={deploy_ollama_num_ctx}
OLLAMA_NUM_PREDICT={deploy_ollama_num_predict}
OLLAMA_SYSTEM_PROMPT={deploy_ollama_system_prompt}
"""
        await safe_reply_text(update, "üìù –ü—Ä–æ–≤–µ—Ä—è—é .env —Ñ–∞–π–ª...")
        env_result = await deploy_create_env(
            deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
            env_content, env_path
        )
        if not env_result or env_result.get("status") != "success":
            error_msg = env_result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if env_result else "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ .env —Ñ–∞–π–ª–∞"
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ .env —Ñ–∞–π–ª–∞: {error_msg}")
            return
        env_msg = env_result.get('message', '.env —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω')
        if env_result.get('skipped'):
            await safe_reply_text(update, f"‚è≠Ô∏è {env_msg}")
        else:
            await safe_reply_text(update, f"‚úÖ {env_msg}")
        
        # 6. –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
        await safe_reply_text(update, "üöÄ –ó–∞–ø—É—Å–∫–∞—é –±–æ—Ç–∞...")
        start_result = await deploy_start_bot(
            deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
            compose_path
        )
        if not start_result or start_result.get("status") != "success":
            error_msg = start_result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if start_result else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞"
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞: {error_msg}")
            return
        
        # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ, —á—Ç–æ–±—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —É—Å–ø–µ–ª –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è
        import asyncio
        await asyncio.sleep(3)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –∏ –ª–æ–≥–∏
        await safe_reply_text(update, "üîç –ü—Ä–æ–≤–µ—Ä—è—é —Å—Ç–∞—Ç—É—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞...")
        container_result = await deploy_check_container(
            deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password
        )
        
        if container_result:
            container_status = container_result.get("container_status", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            container_list = container_result.get("container_list", "")
            container_id = container_result.get("container_id", "")
            logs = container_result.get("logs", "")
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –ª–æ–≥–æ–≤, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
            logs_preview = logs[-1000:] if len(logs) > 1000 else logs
            
            status_msg = f"‚úÖ –î–µ–ø–ª–æ–π –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\n\n"
            status_msg += f"–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ {deploy_ssh_host}\n"
            status_msg += f"–ü—É—Ç—å: {deploy_remote_path}\n"
            status_msg += f"–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä: nikita_ai_bot\n"
            status_msg += f"–°—Ç–∞—Ç—É—Å: {container_status}\n"
            if container_id:
                status_msg += f"ID: {container_id}\n"
            if container_list:
                status_msg += f"\n–í—Å–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã:\n{container_list}\n"
            status_msg += f"\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏:\n```\n{logs_preview}\n```"
            
            await safe_reply_text(update, status_msg)
        else:
            await safe_reply_text(
                update,
                f"‚úÖ –î–µ–ø–ª–æ–π –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\n\n"
                f"–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ {deploy_ssh_host}\n"
                f"–ü—É—Ç—å: {deploy_remote_path}\n"
                f"–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä: nikita_ai_bot\n\n"
                f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ª–æ–≥–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ä—É—á–Ω—É—é: docker logs nikita_ai_bot"
            )
        
    except Exception as e:
        logger.exception(f"Error in deploy_bot_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–ø–ª–æ–µ: {e}")


async def stop_bot_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /stop_bot - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –±–æ—Ç–∞ —Å —Å–µ—Ä–≤–µ—Ä–∞."""
    if not update.message:
        return

    try:
        # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –¥–µ–ø–ª–æ—è
        deploy_ssh_host = os.getenv("DEPLOY_SSH_HOST", "").strip()
        deploy_ssh_port = int(os.getenv("DEPLOY_SSH_PORT", "22"))
        deploy_ssh_username = os.getenv("DEPLOY_SSH_USERNAME", "").strip()
        deploy_ssh_password = os.getenv("DEPLOY_SSH_PASSWORD", "").strip()
        deploy_remote_path = os.getenv("DEPLOY_REMOTE_PATH", "/opt/nikita_ai").strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        if not deploy_ssh_host or not deploy_ssh_username or not deploy_ssh_password:
            await safe_reply_text(
                update,
                "‚ùå –û—à–∏–±–∫–∞: –ù–µ –∑–∞–¥–∞–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –¥–µ–ø–ª–æ—è.\n\n"
                "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å:\n"
                "- DEPLOY_SSH_HOST\n"
                "- DEPLOY_SSH_USERNAME\n"
                "- DEPLOY_SSH_PASSWORD"
            )
            return
        
        compose_path = f"{deploy_remote_path}/docker-compose.yml"
        
        # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥—ã
        args = context.args or []
        remove_volumes = "--remove-volumes" in args or "-v" in args
        remove_images = "--remove-images" in args or "-i" in args
        
        await safe_reply_text(update, "üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ...")
        
        stop_result = await deploy_stop_bot(
            deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
            compose_path, remove_volumes, remove_images
        )
        
        if not stop_result or stop_result.get("status") != "success":
            error_msg = stop_result.get("message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if stop_result else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –±–æ—Ç–∞"
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –±–æ—Ç–∞: {error_msg}")
            return
        
        details = stop_result.get("details", [])
        details_text = "\n".join(f"‚Ä¢ {d}" for d in details) if details else ""
        
        await safe_reply_text(
            update,
            f"‚úÖ {stop_result.get('message', '–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω')}\n\n"
            f"{details_text}\n\n"
            f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
            f"/stop_bot - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä\n"
            f"/stop_bot -v - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ\n"
            f"/stop_bot -i - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å –æ–±—Ä–∞–∑—ã\n"
            f"/stop_bot -v -i - –ø–æ–ª–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ"
        )
        
    except Exception as e:
        logger.exception(f"Error in stop_bot_cmd: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –±–æ—Ç–∞: {e}")


async def handle_task_list_message(update: Update, context: ContextTypes.DEFAULT_TYPE, text: str, temperature: float, model: str) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–µ–∂–∏–º–µ task_list"""
    if not update.message:
        return
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞
    text_lower = text.lower().strip()
    if text_lower in ["–≤—ã—Ö–æ–¥", "–æ—Ç–º–µ–Ω–∞", "cancel", "/cancel"]:
        context.user_data["mode"] = "text"
        await safe_reply_text(update, "‚úÖ –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏ –æ—Ç–∫–ª—é—á–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –≤ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º.")
        return
    
    # Fallback: –ø–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ –∫–æ–º–∞–Ω–¥—ã –±–µ–∑ LLM
    # –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏: "—É–¥–∞–ª–∏ –∑–∞–¥–∞—á—É –≤ —Å—Ç—Ä–æ–∫–µ X" –∏–ª–∏ "—É–¥–∞–ª–∏ —Å—Ç—Ä–æ–∫—É X"
    delete_match = re.search(r'(?:—É–¥–∞–ª–∏|—É–¥–∞–ª–∏—Ç—å|delete).*?(?:–∑–∞–¥–∞—á—É|—Å—Ç—Ä–æ–∫—É|task).*?(?:–≤|–Ω–∞|–Ω–æ–º–µ—Ä|#)?\s*(\d+)', text_lower)
    if delete_match:
        try:
            row_num = int(delete_match.group(1))
            result = await task_delete(row_num)
            if result:
                status = result.get("status", "deleted")
                if status == "cleared":
                    await safe_reply_text(update, f"‚úÖ –ó–∞–¥–∞—á–∞ –≤ —Å—Ç—Ä–æ–∫–µ {row_num} –æ—á–∏—â–µ–Ω–∞ (–ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö)")
                else:
                    await safe_reply_text(update, f"‚úÖ –ó–∞–¥–∞—á–∞ –≤ —Å—Ç—Ä–æ–∫–µ {row_num} —É–¥–∞–ª–µ–Ω–∞")
            else:
                await safe_reply_text(update, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∑–∞–¥–∞—á—É –≤ —Å—Ç—Ä–æ–∫–µ {row_num}")
            return
        except Exception as e:
            logger.exception(f"Error in fallback delete: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ –æ–±—ã—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–µ—Ä–µ–∑ LLM
    
    # –ü—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö –∑–∞–¥–∞—á: "–ø–æ–∫–∞–∂–∏ –∑–∞–¥–∞—á–∏", "—Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á", "–∑–∞–¥–∞—á–∏"
    if text_lower in ["–ø–æ–∫–∞–∂–∏ –∑–∞–¥–∞—á–∏", "—Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á", "–∑–∞–¥–∞—á–∏", "–ø–æ–∫–∞–∑–∞—Ç—å –∑–∞–¥–∞—á–∏", "list tasks", "show tasks"]:
        try:
            tasks = await task_list() or []
            if not tasks:
                await safe_reply_text(update, "üìã –ó–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                return
            
            response_parts = ["üìã –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á:\n"]
            for task in tasks:
                status = "‚úÖ" if task.get("completed") else "‚è≥"
                priority_emoji = {"high": "üî¥", "middle": "üü°", "low": "üü¢"}.get(task.get("priority", "").lower(), "")
                response_parts.append(f"{status} –°—Ç—Ä–æ–∫–∞ {task.get('row_number')}: {task.get('date')} {task.get('time')} | {priority_emoji} {task.get('priority', '').upper()} | {task.get('task', '')}")
            
            await safe_reply_text(update, "\n".join(response_parts))
            return
        except Exception as e:
            logger.exception(f"Error in fallback list: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ –æ–±—ã—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–µ—Ä–µ–∑ LLM
    
    try:
        # RAG –ø–æ–∏—Å–∫
        rag_chunks = []
        if has_embeddings(EMBEDDING_MODEL):
            try:
                rag_chunks = search_relevant_chunks(
                    text,
                    model=EMBEDDING_MODEL,
                    top_k=RAG_TOP_K,
                    min_similarity=RAG_SIM_THRESHOLD,
                    apply_threshold=True
                )
            except Exception as e:
                logger.exception(f"Error in RAG search: {e}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        all_tasks = []
        try:
            all_tasks = await task_list() or []
        except Exception as e:
            logger.warning(f"Could not get tasks: {e}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
        context_parts = []
        
        # RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if rag_chunks:
            context_parts.append("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:")
            for i, chunk in enumerate(rag_chunks, 1):
                context_parts.append(f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} (doc_name={chunk['doc_name']}, chunk_index={chunk['chunk_index']}, score={chunk['similarity']:.4f})]:")
                context_parts.append(chunk["text"])
                context_parts.append("")
        
        # –¢–µ–∫—É—â–∏–µ –∑–∞–¥–∞—á–∏
        if all_tasks:
            context_parts.append("–¢–µ–∫—É—â–∏–µ –∑–∞–¥–∞—á–∏ –≤ —Å–∏—Å—Ç–µ–º–µ:")
            for task in all_tasks:
                status = "‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–∞" if task.get("completed") else "‚è≥ –ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"
                priority_emoji = {"high": "üî¥", "middle": "üü°", "low": "üü¢"}.get(task.get("priority", "").lower(), "")
                context_parts.append(f"- –°—Ç—Ä–æ–∫–∞ {task.get('row_number')}: {status} | {task.get('date')} {task.get('time')} | {priority_emoji} {task.get('priority', '').upper()} | {task.get('task', '')}")
            context_parts.append("")
        
        context_parts.append(f"–ö–æ–º–∞–Ω–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {text}")
        context_parts.append("")
        context_parts.append("–í–ê–ñ–ù–û: –†–∞—Å–ø–æ–∑–Ω–∞–π –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤–µ—Ä–Ω–∏ JSON —Å –¥–µ–π—Å—Ç–≤–∏–µ–º:")
        context_parts.append("- –ï—Å–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏: {\"action\": \"create\", \"date\": \"DD-MM-YYYY\", \"time\": \"HH:MM\", \"task\": \"–æ–ø–∏—Å–∞–Ω–∏–µ\", \"priority\": \"high|middle|low\"}")
        context_parts.append("- –ï—Å–ª–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–¥–∞—á: {\"action\": \"list\", \"priority\": \"high|middle|low\" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ), \"completed\": true/false (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)}")
        context_parts.append("- –ï—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏: {\"action\": \"delete\", \"row_number\": —á–∏—Å–ª–æ}")
        context_parts.append("- –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {\"action\": \"recommend\", \"priority\": \"high|middle|low\" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)}")
        context_parts.append("")
        context_parts.append("–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –ø–æ–∫–∞–∑–∞—Ç—å –∑–∞–¥–∞—á–∏ –∏ –¥–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–π action: \"recommend\".")
        context_parts.append("–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∞–≤–∏–ª–∞ –∫–ª—É–±–∞ –æ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∏—Ö–æ–¥–∞).")
        
        user_content = "\n".join(context_parts)
        
        # System prompt –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –µ–≥–æ —Å–ª–æ–≤–µ—Å–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã –∏ –≤–µ—Ä–Ω—É—Ç—å JSON —Å –¥–µ–π—Å—Ç–≤–∏–µ–º –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:
1. create - —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ (—Ç—Ä–µ–±—É–µ—Ç: date, time, task, priority)
2. list - –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–¥–∞—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: priority, completed)
3. delete - —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ (—Ç—Ä–µ–±—É–µ—Ç: row_number)
4. recommend - —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞–¥–∞—á–∞–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: priority)

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        
        messages = [{"role": "system", "content": system_prompt}]
        messages.append({"role": "user", "content": user_content})
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        try:
            intent_response = chat_completion(messages, temperature=0.3, model=model)
            intent_response = (intent_response or "").strip()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_match = re.search(r'\{[^}]+\}', intent_response, re.DOTALL)
            if json_match:
                intent_json = json.loads(json_match.group(0))
            else:
                # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –≤–µ—Å—å –æ—Ç–≤–µ—Ç –∫–∞–∫ JSON
                intent_json = json.loads(intent_response)
        except requests.exceptions.HTTPError as e:
            # –û—à–∏–±–∫–∞ –æ—Ç API (–Ω–∞–ø—Ä–∏–º–µ—Ä, 500)
            logger.exception(f"Error from LLM API: {e}")
            error_msg = "‚ùå –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥."
            # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–∞—è –∫–æ–º–∞–Ω–¥–∞ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ, –ø–æ–ø—Ä–æ–±—É–µ–º fallback
            delete_match = re.search(r'(\d+)', text)
            if delete_match and any(word in text_lower for word in ["—É–¥–∞–ª–∏", "—É–¥–∞–ª–∏—Ç—å", "delete"]):
                try:
                    row_num = int(delete_match.group(1))
                    result = await task_delete(row_num)
                    if result:
                        status = result.get("status", "deleted")
                        if status == "cleared":
                            await safe_reply_text(update, f"‚úÖ –ó–∞–¥–∞—á–∞ –≤ —Å—Ç—Ä–æ–∫–µ {row_num} –æ—á–∏—â–µ–Ω–∞ (–ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö)")
                        else:
                            await safe_reply_text(update, f"‚úÖ –ó–∞–¥–∞—á–∞ –≤ —Å—Ç—Ä–æ–∫–µ {row_num} —É–¥–∞–ª–µ–Ω–∞")
                        return
                except Exception:
                    pass
            await safe_reply_text(update, error_msg)
            return
        except json.JSONDecodeError as e:
            logger.exception(f"Error parsing JSON from LLM: {e}")
            await safe_reply_text(update, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–æ–º–∞–Ω–¥—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–Ω–∞—á–µ.\n–û—Ç–≤–µ—Ç LLM: {intent_response[:100]}")
            return
        except Exception as e:
            logger.exception(f"Error parsing intent: {e}")
            await safe_reply_text(update, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–æ–º–∞–Ω–¥—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–Ω–∞—á–µ.\n–û—à–∏–±–∫–∞: {e}")
            return
        
        action = intent_json.get("action", "").lower()
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è
        if action == "create":
            date = intent_json.get("date", "")
            time = intent_json.get("time", "")
            task_desc = intent_json.get("task", "")
            priority = intent_json.get("priority", "middle").lower()
            
            if not date or not time or not task_desc:
                await safe_reply_text(update, "‚ùå –ù–µ —É–∫–∞–∑–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ (–¥–∞—Ç–∞, –≤—Ä–µ–º—è, –æ–ø–∏—Å–∞–Ω–∏–µ)")
                return
            
            try:
                result = await task_create(date, time, task_desc, priority)
                if result:
                    row_url = result.get("row_url", "")
                    response_text = f"‚úÖ –ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞!\nüìÖ –î–∞—Ç–∞: {date}\n‚è∞ –í—Ä–µ–º—è: {time}\nüìù –ó–∞–¥–∞—á–∞: {task_desc}\nüéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority.upper()}\n–°—Ç—Ä–æ–∫–∞: {result.get('row_number')}"
                    if row_url:
                        response_text += f"\nüîó –°—Å—ã–ª–∫–∞: {row_url}"
                    await safe_reply_text(update, response_text)
                else:
                    await safe_reply_text(update, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–¥–∞—á–∏")
            except ValueError as e:
                await safe_reply_text(update, f"‚ùå {e}")
            except Exception as e:
                logger.exception(f"Error creating task: {e}")
                await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        
        elif action == "list":
            priority_filter = intent_json.get("priority")
            completed_filter = intent_json.get("completed")
            
            try:
                tasks = await task_list(
                    priority=priority_filter,
                    completed=completed_filter
                ) or []
                
                if not tasks:
                    await safe_reply_text(update, "üìã –ó–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    return
                
                response_parts = ["üìã –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á:\n"]
                for task in tasks:
                    status = "‚úÖ" if task.get("completed") else "‚è≥"
                    priority_emoji = {"high": "üî¥", "middle": "üü°", "low": "üü¢"}.get(task.get("priority", "").lower(), "")
                    response_parts.append(f"{status} –°—Ç—Ä–æ–∫–∞ {task.get('row_number')}: {task.get('date')} {task.get('time')} | {priority_emoji} {task.get('priority', '').upper()} | {task.get('task', '')}")
                
                await safe_reply_text(update, "\n".join(response_parts))
            except Exception as e:
                logger.exception(f"Error listing tasks: {e}")
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á: {e}")
        
        elif action == "delete":
            row_number = intent_json.get("row_number")
            if not row_number:
                await safe_reply_text(update, "‚ùå –ù–µ —É–∫–∞–∑–∞–Ω –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
                return
            
            try:
                row_num = int(row_number)
                result = await task_delete(row_num)
                if result:
                    status = result.get("status", "deleted")
                    if status == "cleared":
                        await safe_reply_text(update, f"‚úÖ –ó–∞–¥–∞—á–∞ –≤ —Å—Ç—Ä–æ–∫–µ {row_num} –æ—á–∏—â–µ–Ω–∞ (–ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö)")
                    else:
                        await safe_reply_text(update, f"‚úÖ –ó–∞–¥–∞—á–∞ –≤ —Å—Ç—Ä–æ–∫–µ {row_num} —É–¥–∞–ª–µ–Ω–∞")
                else:
                    await safe_reply_text(update, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∑–∞–¥–∞—á—É –≤ —Å—Ç—Ä–æ–∫–µ {row_num}")
            except ValueError as e:
                await safe_reply_text(update, f"‚ùå {e}")
            except Exception as e:
                logger.exception(f"Error deleting task: {e}")
                await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        
        elif action == "recommend":
            priority_filter = intent_json.get("priority")
            
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                tasks = await task_list(priority=priority_filter, completed=False) or []
                
                if not tasks:
                    await safe_reply_text(update, "üìã –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
                    return
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                tasks_context = []
                for task in tasks:
                    tasks_context.append(f"- –°—Ç—Ä–æ–∫–∞ {task.get('row_number')}: {task.get('date')} {task.get('time')} | {task.get('priority', '').upper()} | {task.get('task', '')}")
                
                # RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                rag_context = ""
                if rag_chunks:
                    rag_context = "\n\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:\n"
                    for chunk in rag_chunks[:2]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 —á–∞–Ω–∫–∞
                        rag_context += f"- {chunk['text'][:200]}...\n"
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø—Ä–∞–≤–∏–ª –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–¥–∞—á–∏ —Å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è–º–∏
                exercise_rules_context = ""
                exercise_rules_chunks = []
                exercise_keywords = ["–ø—Ä–∏—Å–µ–¥", "–æ—Ç–∂–∞—Ç—å—Å—è", "–ø–æ–¥—Ç—è–Ω—É—Ç—å—Å—è", "–ø—Ä–µ—Å—Å", "—É–ø—Ä–∞–∂–Ω–µ–Ω–∏", "–Ω–æ–≥–∏", "—Å–ø–∏–Ω–∞", "–≥—Ä—É–¥—å"]
                has_exercises = any(
                    any(keyword in task.get("task", "").lower() for keyword in exercise_keywords)
                    for task in tasks
                )
                
                if has_exercises and has_embeddings(EMBEDDING_MODEL):
                    try:
                        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø—Ä–∞–≤–∏–ª –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π
                        exercise_rules_chunks = search_relevant_chunks(
                            "–ø—Ä–∞–≤–∏–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–æ–≥–∏ —Å–ø–∏–Ω–∞ –≥—Ä—É–¥—å –ø—Ä–µ—Å—Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç",
                            model=EMBEDDING_MODEL,
                            top_k=3,
                            min_similarity=0.5,
                            apply_threshold=True
                        )
                        if exercise_rules_chunks:
                            exercise_rules_context = "\n\n–ü—Ä–∞–≤–∏–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π:\n"
                            for chunk in exercise_rules_chunks:
                                exercise_rules_context += f"- {chunk['text'][:300]}...\n"
                    except Exception as e:
                        logger.warning(f"Error searching exercise rules: {e}")
                
                recommendation_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–¥–∞—á–∏ –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, —á—Ç–æ –¥–µ–ª–∞—Ç—å –ø–µ—Ä–≤—ã–º:

–ó–∞–¥–∞—á–∏:
{chr(10).join(tasks_context)}
{rag_context}
{exercise_rules_context}

–í–ê–ñ–ù–û: –ï—Å–ª–∏ —Å—Ä–µ–¥–∏ –∑–∞–¥–∞—á –µ—Å—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è (–ø—Ä–∏—Å–µ–¥–∞–Ω–∏—è, –æ—Ç–∂–∏–º–∞–Ω–∏—è, –ø–æ–¥—Ç—è–≥–∏–≤–∞–Ω–∏—è, –ø—Ä–µ—Å—Å –∏ —Ç.–¥.), –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∞–≤–∏–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏. –£—á–∏—Ç—ã–≤–∞–π:
1. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–¥–∞—á–∏ (HIGH > MIDDLE > LOW) - –≥–ª–∞–≤–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π
2. –ü—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ: —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –Ω–∞ –Ω–æ–≥–∏ ‚Üí —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –Ω–∞ –≤–µ—Ä—Ö —Ç–µ–ª–æ (—Å–ø–∏–Ω–∞/–≥—Ä—É–¥—å) ‚Üí —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ—Å—Å
3. –ü–æ–¥—Ç—è–≥–∏–≤–∞–Ω–∏—è –∏ –æ—Ç–∂–∏–º–∞–Ω–∏—è –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –≤ —Å—É–ø–µ—Ä—Å–µ—Ç–µ

–î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–µ—Ä–≤—ã–º–∏ –∏ –ø–æ—á–µ–º—É. –£—á–∏—Ç—ã–≤–∞–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã, –¥–∞—Ç—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
                
                rec_messages = [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –∑–∞–¥–∞—á. –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."},
                    {"role": "user", "content": recommendation_prompt}
                ]
                
                recommendation = chat_completion(rec_messages, temperature=0.7, model=model)
                recommendation = (recommendation or "").strip()
                
                response_parts = [recommendation]
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å RAG —á–∞–Ω–∫–∏
                all_rag_chunks = []
                if rag_chunks:
                    all_rag_chunks.extend(rag_chunks)
                if exercise_rules_chunks:
                    all_rag_chunks.extend(exercise_rules_chunks)
                
                # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ doc_name –∏ chunk_index
                seen = set()
                unique_chunks = []
                for chunk in all_rag_chunks:
                    key = (chunk.get("doc_name", ""), chunk.get("chunk_index", -1))
                    if key not in seen:
                        seen.add(key)
                        unique_chunks.append(chunk)
                
                if unique_chunks:
                    response_parts.append("")
                    response_parts.append("üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
                    for chunk in unique_chunks[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 3 –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                        # –ë–µ—Ä–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Ü–∏—Ç–∞—Ç—É (–¥–æ 120 —Å–∏–º–≤–æ–ª–æ–≤, –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
                        chunk_text = chunk["text"]
                        # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                        chunk_text = " ".join(chunk_text.split())
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–ª–∏ –ø–µ—Ä–≤—ã–µ 120 —Å–∏–º–≤–æ–ª–æ–≤
                        sentences = chunk_text.split(". ")
                        if sentences:
                            quote = sentences[0]
                            if len(quote) > 120:
                                quote = quote[:120] + "..."
                        else:
                            quote = chunk_text[:120] + ("..." if len(chunk_text) > 120 else "")
                        
                        doc_name = chunk.get("doc_name", "unknown")
                        # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å docs/ –µ—Å–ª–∏ –µ—Å—Ç—å
                        if doc_name.startswith("docs/"):
                            doc_name = doc_name[5:]
                        
                        response_parts.append(f"- {doc_name}, chunk_index={chunk.get('chunk_index', 0)}, score={chunk.get('similarity', 0):.4f}")
                        response_parts.append(f"  –¶–∏—Ç–∞—Ç–∞: {quote}")
                
                response_parts.append("")
                response_parts.append("üìã –ó–∞–¥–∞—á–∏ –¥–ª—è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è:")
                for task in tasks[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 10 –∑–∞–¥–∞—á
                    priority_emoji = {"high": "üî¥", "middle": "üü°", "low": "üü¢"}.get(task.get("priority", "").lower(), "")
                    response_parts.append(f"‚Ä¢ –°—Ç—Ä–æ–∫–∞ {task.get('row_number')}: {task.get('date')} {task.get('time')} | {priority_emoji} {task.get('priority', '').upper()} | {task.get('task', '')}")
                
                await safe_reply_text(update, "\n".join(response_parts))
            except Exception as e:
                logger.exception(f"Error getting recommendations: {e}")
                await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        
        else:
            await safe_reply_text(update, f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {action}")
    
    except Exception as e:
        logger.exception(f"Error in handle_task_list_message: {e}")
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–º–∞–Ω–¥—ã: {e}")


# -------------------- LOCAL MODEL (OLLAMA) --------------------

async def send_to_ollama(question: str, user_data: dict = None) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Ollama API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏."""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ user_data –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config
        temperature = float(user_data.get("ollama_temperature", OLLAMA_TEMPERATURE)) if user_data else OLLAMA_TEMPERATURE
        num_ctx = int(user_data.get("ollama_num_ctx", OLLAMA_NUM_CTX)) if user_data else OLLAMA_NUM_CTX
        num_predict = int(user_data.get("ollama_num_predict", OLLAMA_NUM_PREDICT)) if user_data else OLLAMA_NUM_PREDICT
        system_prompt = user_data.get("ollama_system_prompt", OLLAMA_SYSTEM_PROMPT) if user_data else OLLAMA_SYSTEM_PROMPT
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if not (0.0 <= temperature <= 2.0):
            raise ValueError(f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0.0 –¥–æ 2.0, –ø–æ–ª—É—á–µ–Ω–æ: {temperature}")
        if num_ctx <= 0 or num_ctx > 32768:
            raise ValueError(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 32768, –ø–æ–ª—É—á–µ–Ω–æ: {num_ctx}")
        if num_predict <= 0 or num_predict > 8192:
            raise ValueError(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç 1 –¥–æ 8192, –ø–æ–ª—É—á–µ–Ω–æ: {num_predict}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        api_url = f"{OLLAMA_BASE_URL}/api/chat"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        # –£–ª—É—á—à–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å, –¥–æ–±–∞–≤–ª—è—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        enhanced_question = question
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç "—á—Ç–æ —Ç–∞–∫–æ–µ" –∏–ª–∏ –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã, –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if any(phrase in question.lower() for phrase in ["—á—Ç–æ —Ç–∞–∫–æ–µ", "–æ–±—ä—è—Å–Ω–∏", "—Ä–∞—Å—Å–∫–∞–∂–∏", "–ø–∞—Ä–∞–¥–æ–∫—Å", "–≥–∏–ø–æ—Ç–µ–∑–∞"]):
            enhanced_question = f"{question}\n\n–í–∞–∂–Ω–æ: –æ—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ñ–∞–∫—Ç–∞—Ö. –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º."
        messages.append({"role": "user", "content": enhanced_question})
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º payload –¥–ª—è Ollama API
        payload = {
            "model": OLLAMA_MODEL,
            "messages": messages,
            "stream": False,
            "options": {
                "temperature": temperature,
                "num_ctx": num_ctx,
                "num_predict": num_predict
            }
        }
        
        logger.info(f"Sending request to Ollama: {api_url}, model: {OLLAMA_MODEL}, temperature: {temperature}, num_ctx: {num_ctx}, num_predict: {num_predict}")
        logger.debug(f"Ollama payload: {payload}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º POST –∑–∞–ø—Ä–æ—Å
        response = requests.post(
            api_url,
            json=payload,
            timeout=OLLAMA_TIMEOUT
        )
        
        logger.debug(f"Ollama response status: {response.status_code}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
        response.raise_for_status()
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        data = response.json()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ
        if "error" in data:
            error_msg = data.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
            logger.error(f"Ollama API error: {error_msg}, full response: {data}")
            raise ValueError(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {error_msg}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Ollama
        # –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {"message": {"content": "—Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞"}}
        if "message" in data and "content" in data["message"]:
            answer = data["message"]["content"].strip()
            if answer:
                logger.info(f"Ollama response received, length: {len(answer)}")
                return answer
            else:
                logger.warning(f"Ollama returned empty content, full response: {data}")
                raise ValueError("–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
        else:
            logger.warning(f"Unexpected Ollama response structure: {data}")
            raise ValueError("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏")
            
    except requests.exceptions.Timeout:
        logger.exception("Ollama request timeout")
        raise ConnectionError("–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (—Ç–∞–π–º–∞—É—Ç)")
    except requests.exceptions.ConnectionError:
        logger.exception("Ollama connection error")
        raise ConnectionError("–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)")
    except requests.exceptions.HTTPError as e:
        status_code = e.response.status_code if hasattr(e, 'response') and e.response else 'unknown'
        error_body = ""
        if hasattr(e, 'response') and e.response:
            try:
                error_body = e.response.text
                logger.error(f"Ollama HTTP error {status_code}: {error_body}")
            except:
                pass
        logger.exception(f"Ollama HTTP error: {status_code}")
        raise ConnectionError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ (HTTP {status_code})")
    except ValueError as e:
        # –ü–µ—Ä–µ–¥–∞–µ–º ValueError –∫–∞–∫ –µ—Å—Ç—å (—ç—Ç–æ –æ—à–∏–±–∫–∏ –æ—Ç –º–æ–¥–µ–ª–∏)
        logger.error(f"Ollama model error: {str(e)}")
        raise
    except Exception as e:
        logger.exception(f"Unexpected error in send_to_ollama: {type(e).__name__}: {str(e)}")
        raise ConnectionError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {str(e)}")


async def send_to_ollama_analyze(json_content: str, question: str) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Ollama API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ JSON –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏."""
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        api_url = f"{OLLAMA_BASE_URL}/api/chat"
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤
        system_prompt = "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ –∏ –æ—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ, –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"JSON –¥–∞–Ω–Ω—ã–µ:\n{json_content}\n\n–í–æ–ø—Ä–æ—Å: {question}"}
        ]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º payload –¥–ª—è Ollama API
        payload = {
            "model": ANALYZE_MODEL,
            "messages": messages,
            "stream": False,
            "options": {
                "temperature": OLLAMA_TEMPERATURE,
                "num_ctx": OLLAMA_NUM_CTX,
                "num_predict": OLLAMA_NUM_PREDICT
            }
        }
        
        logger.info(f"Sending analyze request to Ollama: {api_url}, model: {ANALYZE_MODEL}")
        logger.debug(f"Ollama analyze payload: {payload}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º POST –∑–∞–ø—Ä–æ—Å
        response = requests.post(
            api_url,
            json=payload,
            timeout=OLLAMA_TIMEOUT
        )
        
        logger.debug(f"Ollama analyze response status: {response.status_code}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
        response.raise_for_status()
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        data = response.json()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ
        if "error" in data:
            error_msg = data.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
            logger.error(f"Ollama API error: {error_msg}, full response: {data}")
            raise ValueError(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {error_msg}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Ollama
        if "message" in data and "content" in data["message"]:
            answer = data["message"]["content"].strip()
            if answer:
                logger.info(f"Ollama analyze response received, length: {len(answer)}")
                return answer
            else:
                logger.warning(f"Ollama returned empty content, full response: {data}")
                raise ValueError("–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
        else:
            logger.warning(f"Unexpected Ollama response structure: {data}")
            raise ValueError("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏")
            
    except requests.exceptions.Timeout:
        logger.exception("Ollama analyze request timeout")
        raise ConnectionError("–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (—Ç–∞–π–º–∞—É—Ç)")
    except requests.exceptions.ConnectionError:
        logger.exception("Ollama analyze connection error")
        raise ConnectionError("–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)")
    except requests.exceptions.HTTPError as e:
        status_code = e.response.status_code if hasattr(e, 'response') and e.response else 'unknown'
        error_body = ""
        if hasattr(e, 'response') and e.response:
            try:
                error_body = e.response.text
                logger.error(f"Ollama HTTP error {status_code}: {error_body}")
            except:
                pass
        logger.exception(f"Ollama HTTP error: {status_code}")
        raise ConnectionError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ (HTTP {status_code})")
    except ValueError as e:
        logger.error(f"Ollama model error: {str(e)}")
        raise
    except Exception as e:
        logger.exception(f"Unexpected error in send_to_ollama_analyze: {type(e).__name__}: {str(e)}")
        raise ConnectionError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {str(e)}")


def _get_ollama_settings_display(user_data: dict = None) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É —Å —Ç–µ–∫—É—â–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –º–æ–¥–µ–ª–∏."""
    temperature = float(user_data.get("ollama_temperature", OLLAMA_TEMPERATURE)) if user_data else OLLAMA_TEMPERATURE
    num_ctx = int(user_data.get("ollama_num_ctx", OLLAMA_NUM_CTX)) if user_data else OLLAMA_NUM_CTX
    num_predict = int(user_data.get("ollama_num_predict", OLLAMA_NUM_PREDICT)) if user_data else OLLAMA_NUM_PREDICT
    system_prompt = user_data.get("ollama_system_prompt", OLLAMA_SYSTEM_PROMPT) if user_data else OLLAMA_SYSTEM_PROMPT
    
    return (
        f"üìä –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏:\n"
        f"‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temperature}\n"
        f"‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ: {num_ctx}\n"
        f"‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {num_predict}\n"
        f"‚Ä¢ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {system_prompt[:50]}{'...' if len(system_prompt) > 50 else ''}"
    )


async def local_model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /local_model - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ä–µ–∂–∏–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Ollama –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"""
    if not update.message:
        return
    
    # –ï—Å–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç - –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º
    if not context.args:
        chat_id = int(update.effective_chat.id) if update.effective_chat else 0
        context.user_data["mode"] = "local_model"
        reset_tz(context)
        reset_forest(context)
        
        settings_text = _get_ollama_settings_display(context.user_data)
        
        await safe_reply_text(
            update,
            f"‚úÖ –†–µ–∂–∏–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Ollama –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω.\n"
            f"–ú–æ–¥–µ–ª—å: {OLLAMA_MODEL}\n\n"
            f"{settings_text}\n\n"
            f"–¢–µ–ø–µ—Ä—å –≤—Å–µ –≤–∞—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å.\n"
            f"–î–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /mode_text –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ä–µ–∂–∏–º.\n\n"
            f"üí° –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫:\n"
            f"‚Ä¢ \"–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É 0.7\"\n"
            f"‚Ä¢ \"–∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ 4096\"\n"
            f"‚Ä¢ \"–∏–∑–º–µ–Ω–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ 512\"\n"
            f"‚Ä¢ \"–ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏\"\n"
            f"‚Ä¢ \"—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏\""
        )
        return
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∫–æ–º–∞–Ω–¥—ã
    text = " ".join(context.args).strip().lower()
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–æ–≤–µ—Å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
    # –ò–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
    temp_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É\s+([\d.]+)', text)
    if temp_match:
        try:
            new_temp = float(temp_match.group(1))
            if 0.0 <= new_temp <= 2.0:
                context.user_data["ollama_temperature"] = new_temp
                await safe_reply_text(update, f"‚úÖ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {new_temp}")
            else:
                await safe_reply_text(update, "‚ùå –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0.0 –¥–æ 2.0")
            return
        except ValueError:
            await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã")
            return
    
    # –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ
    ctx_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ\s+–æ–∫–Ω–æ\s+(\d+)', text)
    if ctx_match:
        try:
            new_ctx = int(ctx_match.group(1))
            if new_ctx > 0:
                context.user_data["ollama_num_ctx"] = new_ctx
                await safe_reply_text(update, f"‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ {new_ctx}")
            else:
                await safe_reply_text(update, "‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
            return
        except ValueError:
            await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞")
            return
    
    # –ò–∑–º–µ–Ω–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
    predict_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+–º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é\s+–¥–ª–∏–Ω—É\s+–æ—Ç–≤–µ—Ç–∞\s+(\d+)', text)
    if predict_match:
        try:
            new_predict = int(predict_match.group(1))
            if new_predict > 0:
                context.user_data["ollama_num_predict"] = new_predict
                await safe_reply_text(update, f"‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {new_predict}")
            else:
                await safe_reply_text(update, "‚ùå –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
            return
        except ValueError:
            await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞")
            return
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if "–ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏" in text or "–ø–æ–∫–∞–∑–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" in text:
        settings_text = _get_ollama_settings_display(context.user_data)
        await safe_reply_text(update, settings_text)
        return
    
    # –°–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if "—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏" in text or "—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" in text:
        # –£–¥–∞–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        context.user_data.pop("ollama_temperature", None)
        context.user_data.pop("ollama_num_ctx", None)
        context.user_data.pop("ollama_num_predict", None)
        context.user_data.pop("ollama_system_prompt", None)
        settings_text = _get_ollama_settings_display(context.user_data)
        await safe_reply_text(update, f"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–±—Ä–æ—à–µ–Ω—ã –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:\n\n{settings_text}")
        return
    
    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –∫–æ–º–∞–Ω–¥–∞ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ –º–æ–¥–µ–ª—å
    question = " ".join(context.args)
    
    try:
        answer = await send_to_ollama(question, context.user_data)
        await safe_reply_text(update, answer)
    except ValueError as e:
        # –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–ª–∏ –æ—Ç –º–æ–¥–µ–ª–∏
        await safe_reply_text(update, f"‚ùå {str(e)}\n\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–∞–Ω–¥–æ–π: —Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
    except ConnectionError as e:
        await safe_reply_text(update, f"‚ùå {str(e)}")
    except Exception as e:
        await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")


# -------------------- ANALYZE COMMAND --------------------

async def analyze_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /analyze - –∞–Ω–∞–ª–∏–∑ JSON —Ñ–∞–π–ª–æ–≤ —Å –ª–æ–≥–∞–º–∏ —á–µ—Ä–µ–∑ Ollama"""
    if not update.message:
        return
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º analyze
    context.user_data["mode"] = "analyze"
    # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞
    context.user_data.pop("analyze_json_content", None)
    
    await safe_reply_text(update, "–û—Ç–ø—Ä–∞–≤—å JSON —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")


# -------------------- ME COMMAND (PERSONAL ASSISTANT) --------------------

async def me_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ö–æ–º–∞–Ω–¥–∞ /me - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ä–µ–∂–∏–º –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    if not update.message:
        return
    
    # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –Ω–∞ "me"
    context.user_data["mode"] = "me"
    reset_tz(context)
    reset_forest(context)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    try:
        profile = load_user_profile()
        profile_info = ""
        if profile.get("name"):
            profile_info = f"\nüë§ –ò–º—è: {profile['name']}"
        if profile.get("interests"):
            profile_info += f"\nüéØ –ò–Ω—Ç–µ—Ä–µ—Å—ã: {', '.join(profile['interests'][:3])}"
            if len(profile['interests']) > 3:
                profile_info += "..."
    except Exception as e:
        logger.warning(f"Error loading profile in me_cmd: {e}")
        profile_info = "\n‚ö†Ô∏è –ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É '–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å' –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è."
    
    await safe_reply_text(
        update,
        f"‚úÖ –†–µ–∂–∏–º –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω.\n"
        f"–ú–æ–¥–µ–ª—å: {ME_MODEL}\n"
        f"{profile_info}\n\n"
        f"–¢–µ–ø–µ—Ä—å –≤—Å–µ –≤–∞—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.\n"
        f"–î–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /mode_text –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ä–µ–∂–∏–º.\n\n"
        f"üí° –ö–æ–º–∞–Ω–¥—ã:\n"
        f"‚Ä¢ \"–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å [—Ç–µ–∫—Å—Ç]\" - –æ–±–Ω–æ–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ–±–µ\n"
        f"‚Ä¢ \"–ö—Ç–æ —è?\" - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å\n"
        f"‚Ä¢ –û–±—ã—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è - –æ–±—â–µ–Ω–∏–µ —Å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º"
    )


# -------------------- ERROR HANDLER --------------------

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.exception("Unhandled error: %s", context.error)
    if isinstance(update, Update) and update.message:
        await safe_reply_text(update, f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {type(context.error).__name__}: {context.error}")


# -------------------- BOT COMMANDS MENU --------------------

async def post_init(app: Application) -> None:
    cmds = [
        BotCommand("start", "–°—Ç–∞—Ä—Ç"),
        BotCommand("help", "–°–ø—Ä–∞–≤–∫–∞"),
        BotCommand("mode_text", f"–†–µ–∂–∏–º text + {_short_model_name(OPENROUTER_MODEL)}"),
        BotCommand("mode_json", "JSON –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"),
        BotCommand("mode_summary", f"–†–µ–∂–∏–º summary + {_short_model_name(OPENROUTER_MODEL)}"),
        BotCommand("summary_debug", "–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ summary (—Ä–µ–∂–∏–º summary)"),
        BotCommand("tz_creation_site", "–°–æ–±—Ä–∞—Ç—å –¢–ó –Ω–∞ —Å–∞–π—Ç (–∏—Ç–æ–≥ JSON)"),
        BotCommand("forest_split", "–ö—Ç–æ –∫–æ–º—É –¥–æ–ª–∂–µ–Ω (–∏—Ç–æ–≥ —Ç–µ–∫—Å—Ç)"),
        BotCommand("thinking_model", "–†–µ—à–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ"),
        BotCommand("expert_group_model", "–ì—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"),
        BotCommand("tokens_test", "–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤ (–≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º)"),
        BotCommand("tokens_next", "–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø"),
        BotCommand("tokens_stop", "–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–≤–æ–¥–∫–∞ –∏ –≤—ã—Ö–æ–¥"),
        BotCommand("ch_temperature", "–ü–æ–∫–∞–∑–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: /ch_temperature 0.7)"),
        BotCommand("ch_memory", "–ü–∞–º—è—Ç—å –í–ö–õ/–í–´–ö–õ (–ø—Ä–∏–º–µ—Ä: /ch_memory off)"),
        BotCommand("clear_memory", "–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞"),
        BotCommand("clear_embeddings", "–£–¥–∞–ª–∏—Ç—å –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"),
        BotCommand("weather_sub", "–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É (–ø—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30)"),
        BotCommand("weather_sub_stop", "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É –Ω–∞ –ø–æ–≥–æ–¥—É (–ø—Ä–∏–º–µ—Ä: /weather_sub_stop –ú–æ—Å–∫–≤–∞)"),
        BotCommand("digest", "–£—Ç—Ä–µ–Ω–Ω—è—è —Å–≤–æ–¥–∫–∞: –ø–æ–≥–æ–¥–∞ + –Ω–æ–≤–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)"),
        BotCommand("embed_create", "–°–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ .md —Ñ–∞–π–ª–∞ (—Å–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª)"),
        BotCommand("embed_docs", "–°–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ docs/"),
        BotCommand("rag_model", "–†–µ–∂–∏–º RAG (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ \"–û—Ç–≤–µ—Ç—å —Å RAG\" –∏–ª–∏ \"–û—Ç–≤–µ—Ç—å –±–µ–∑ RAG\")"),
        BotCommand("register", "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è (–ø—Ä–∏–º–µ—Ä: /register –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á +79991234567)"),
        BotCommand("unregister", "–£–¥–∞–ª–∏—Ç—å —Å–≤–æ—é —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é"),
        BotCommand("train_signup", "–ó–∞–ø–∏—Å—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É (–ø—Ä–∏–º–µ—Ä: /train_signup 15-02-2026 18:00 [–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ])"),
        BotCommand("train_move", "–ü–µ—Ä–µ–Ω–æ—Å –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_move 1 16-02-2026 19:00)"),
        BotCommand("train_cancel", "–û—Ç–º–µ–Ω–∞ –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_cancel 1)"),
        BotCommand("support", "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å RAG (–ø—Ä–∏–º–µ—Ä: /support –º–æ–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∑–∞–ø–∏—Å—å?)"),
        BotCommand("task_list", "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏"),
        BotCommand("local_model", f"–†–µ–∂–∏–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Ollama (–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞)"),
        BotCommand("analyze", "–ê–Ω–∞–ª–∏–∑ JSON –ª–æ–≥–æ–≤ —á–µ—Ä–µ–∑ Ollama"),
        BotCommand("me", "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç"),
    ]
    
    if PR_REVIEW_AVAILABLE:
        cmds.append(BotCommand("review_pr", "–ê–Ω–∞–ª–∏–∑ Pull Request (–ø—Ä–∏–º–µ—Ä: /review_pr 123)"))

    if MODEL_GLM:
        cmds.append(BotCommand("model_glm", f"–ú–æ–¥–µ–ª—å: {_short_model_name(MODEL_GLM)}"))
    if MODEL_GEMMA:
        cmds.append(BotCommand("model_gemma", f"–ú–æ–¥–µ–ª—å: {_short_model_name(MODEL_GEMMA)}"))

    await app.bot.set_my_commands(cmds)


def run() -> None:
    # –ü–æ–¥–∞–≤–ª—è–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –ª–æ–≥–∏ httpx (HTTP –∑–∞–ø—Ä–æ—Å—ã –∫ Telegram API)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    
    init_db()
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    from .embeddings import init_embeddings_table
    init_embeddings_table()

    request = HTTPXRequest(
        connect_timeout=20.0,
        read_timeout=60.0,
        write_timeout=60.0,
        pool_timeout=20.0,
    )

    app = (
        Application.builder()
        .token(TELEGRAM_BOT_TOKEN)
        .request(request)
        .post_init(post_init)
        .build()
    )

    # deps –¥–ª—è tokens_test.py (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É)
    app.bot_data["tokens_deps"] = {
        "get_temperature": get_temperature,
        "get_model": get_model,
        "get_effective_model": get_effective_model,
        "SYSTEM_PROMPT_TEXT": SYSTEM_PROMPT_TEXT,
        "safe_reply_text": safe_reply_text,
    }

    app.add_error_handler(error_handler)

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))

    app.add_handler(CommandHandler("tokens_test", tokens_test_cmd))
    app.add_handler(CommandHandler("tokens_next", tokens_next_cmd))
    app.add_handler(CommandHandler("tokens_stop", tokens_stop_cmd))

    app.add_handler(CommandHandler("ch_temperature", ch_temperature_cmd))
    app.add_handler(CommandHandler("ch_memory", ch_memory_cmd))
    app.add_handler(CommandHandler("clear_memory", clear_memory_cmd))
    app.add_handler(CommandHandler("clear_embeddings", clear_embeddings_cmd))

    if MODEL_GLM:
        app.add_handler(CommandHandler("model_glm", model_glm_cmd))
    if MODEL_GEMMA:
        app.add_handler(CommandHandler("model_gemma", model_gemma_cmd))

    app.add_handler(CommandHandler("mode_text", mode_text_cmd))
    app.add_handler(CommandHandler("mode_json", mode_json_cmd))
    app.add_handler(CommandHandler("mode_summary", mode_summary_cmd))
    app.add_handler(CommandHandler("summary_debug", summary_debug_cmd))
    app.add_handler(CommandHandler("tz_creation_site", tz_creation_site_cmd))
    app.add_handler(CommandHandler("forest_split", forest_split_cmd))
    app.add_handler(CommandHandler("thinking_model", thinking_model_cmd))
    app.add_handler(CommandHandler("expert_group_model", expert_group_model_cmd))
    app.add_handler(CommandHandler("weather_sub", weather_sub_cmd))
    app.add_handler(CommandHandler("weather_sub_stop", weather_sub_stop_cmd))
    app.add_handler(CommandHandler("digest", digest_cmd))
    if PR_REVIEW_AVAILABLE:
        app.add_handler(CommandHandler("review_pr", review_pr_cmd))
    app.add_handler(CommandHandler("embed_create", embed_create_cmd))
    app.add_handler(CommandHandler("embed_docs", embed_docs_cmd))
    app.add_handler(CommandHandler("rag_model", rag_model_cmd))
    app.add_handler(CommandHandler("register", register_cmd))
    app.add_handler(CommandHandler("unregister", unregister_cmd))
    app.add_handler(CommandHandler("train_signup", train_signup_cmd))
    app.add_handler(CommandHandler("train_move", train_move_cmd))
    app.add_handler(CommandHandler("train_cancel", train_cancel_cmd))
    app.add_handler(CommandHandler("support", support_cmd))
    app.add_handler(CommandHandler("task_list", task_list_cmd))
    app.add_handler(CommandHandler("deploy_bot", deploy_bot_cmd))
    app.add_handler(CommandHandler("stop_bot", stop_bot_cmd))
    app.add_handler(CommandHandler("local_model", local_model_cmd))
    app.add_handler(CommandHandler("analyze", analyze_cmd))
    app.add_handler(CommandHandler("me", me_cmd))

    app.add_handler(MessageHandler(filters.Document.ALL, on_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    run()
