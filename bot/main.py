import os
import json
import re
import sqlite3
import logging
from datetime import datetime, timezone
from pathlib import Path

from telegram import Update, BotCommand
from telegram.error import TimedOut, BadRequest
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from telegram.request import HTTPXRequest

from .config import TELEGRAM_BOT_TOKEN, OPENROUTER_MODEL
from .openrouter import chat_completion, chat_completion_raw
from .tokens_test import tokens_test_cmd, tokens_next_cmd, tokens_stop_cmd, tokens_test_intercept

# NEW: summary-mode
from .summarizer import MODE_SUMMARY, build_messages_with_summary, maybe_compress_history, clear_summary, summary_debug_cmd
from .mcp_weather import get_weather_via_mcp  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–≥–æ–¥—ã
from .mcp_news import get_news_via_mcp  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π
from .mcp_docker import site_up_via_mcp, site_screenshot_via_mcp, site_down_via_mcp  # MCP-–∫–ª–∏–µ–Ω—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Docker
from .weather_subscription import start_weather_subscription, stop_weather_subscription  # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É


logger = logging.getLogger(__name__)


def utc_now_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z")


def _short_model_name(m: str) -> str:
    m = (m or "").strip()
    if not m:
        return "default"
    return m.split("/")[-1]


def _get_usage_tokens(data: dict) -> tuple[int | None, int | None, int | None]:
    usage = data.get("usage") or {}
    pt = usage.get("prompt_tokens")
    ct = usage.get("completion_tokens")
    tt = usage.get("total_tokens")

    try:
        pt = int(pt) if pt is not None else None
    except Exception:
        pt = None
    try:
        ct = int(ct) if ct is not None else None
    except Exception:
        ct = None
    try:
        tt = int(tt) if tt is not None else None
    except Exception:
        tt = None

    return pt, ct, tt


def _get_content_from_raw(data: dict) -> str:
    try:
        return (((data.get("choices") or [{}])[0].get("message") or {}).get("content") or "").strip()
    except Exception:
        return ""


def _city_prepositional_case(city: str) -> str:
    """
    –°–∫–ª–æ–Ω—è–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –≤ –ø—Ä–µ–¥–ª–æ–∂–Ω—ã–π –ø–∞–¥–µ–∂ (–≥–¥–µ? –≤ —á—ë–º?).
    –ü—Ä–∏–º–µ—Ä—ã: –ú–æ—Å–∫–≤–∞ -> –ú–æ—Å–∫–≤–µ, –°–∞–º–∞—Ä–∞ -> –°–∞–º–∞—Ä–µ, –°–∞—Ä–∞—Ç–æ–≤ -> –°–∞—Ä–∞—Ç–æ–≤–µ, –¢–æ–º—Å–∫ -> –¢–æ–º—Å–∫–µ.
    """
    city = (city or "").strip()
    if not city:
        return city
    
    # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Å–∫–ª–æ–Ω–µ–Ω–∏—è —Ä—É—Å—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –≥–æ—Ä–æ–¥–æ–≤
    city_lower = city.lower()
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "–∞" (–ú–æ—Å–∫–≤–∞, –°–∞–º–∞—Ä–∞, –¢—É–ª–∞) -> "–µ" (–≤ –ú–æ—Å–∫–≤–µ, –≤ –°–∞–º–∞—Ä–µ, –≤ –¢—É–ª–µ)
    if city_lower.endswith("–∞"):
        return city[:-1] + "–µ"
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "–æ" (–¢—É–ª–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    if city_lower.endswith("–æ"):
        return city[:-1] + "–µ"
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "—å" (–¢–≤–µ—Ä—å, –†—è–∑–∞–Ω—å) -> "–∏" (–≤ –¢–≤–µ—Ä–∏, –≤ –†—è–∑–∞–Ω–∏)
    if city_lower.endswith("—å"):
        return city[:-1] + "–∏"
    
    # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —Å–æ–≥–ª–∞—Å–Ω—É—é (–°–∞—Ä–∞—Ç–æ–≤, –¢–æ–º—Å–∫, –ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫) -> "–µ" (–≤ –°–∞—Ä–∞—Ç–æ–≤–µ, –≤ –¢–æ–º—Å–∫–µ, –≤ –ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–µ)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –±—É–∫–≤—É
    last_char = city_lower[-1]
    if last_char not in "–∞–µ—ë–∏–æ—É—ã—ç—é—è—å":
        return city + "–µ"
    
    # –ï—Å–ª–∏ –Ω–µ –ø–æ–¥–æ—à–ª–æ –Ω–∏ –æ–¥–Ω–æ –ø—Ä–∞–≤–∏–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    return city


# -------------------- TEMPERATURE --------------------

DEFAULT_TEMPERATURE = 0.7
TEMPERATURE_MIN = 0.0
TEMPERATURE_MAX = 2.0

# -------------------- MEMORY SWITCH --------------------

DEFAULT_MEMORY_ENABLED = True  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–∞–º—è—Ç—å –≤–∫–ª—é—á–µ–Ω–∞

# -------------------- MODELS FROM ENV --------------------
# –î–æ–±–∞–≤—å –≤ .env:
# OPENROUTER_MODEL_GLM=z-ai/glm-4.7-flash
# OPENROUTER_MODEL_GEMMA=google/gemma-3-12b-it

MODEL_GLM = (os.getenv("OPENROUTER_MODEL_GLM") or "").strip()
MODEL_GEMMA = (os.getenv("OPENROUTER_MODEL_GEMMA") or "").strip()


# -------------------- SQLITE MEMORY + SETTINGS --------------------

DB_PATH = Path(__file__).resolve().parent / "bot_memory.sqlite3"
MEMORY_LIMIT_MESSAGES = 30  # —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è LLM
MEMORY_CHAT_MODES = ("text", "thinking", "experts")  # –æ–±—â–∞—è –ø–∞–º—è—Ç—å –º–µ–∂–¥—É —ç—Ç–∏–º–∏ —Ä–µ–∂–∏–º–∞–º–∏


def open_db() -> sqlite3.Connection:
    DB_PATH.parent.mkdir(parents=True, exist_ok=True)
    conn = sqlite3.connect(DB_PATH, timeout=30)
    conn.execute("PRAGMA journal_mode=WAL;")
    conn.execute("PRAGMA synchronous=NORMAL;")
    conn.execute("PRAGMA busy_timeout=5000;")
    return conn


def _ensure_column(conn: sqlite3.Connection, table: str, column: str, ddl: str) -> None:
    """
    ddl –ø—Ä–∏–º–µ—Ä: 'ALTER TABLE chat_settings ADD COLUMN memory_enabled INTEGER NOT NULL DEFAULT 1'
    """
    cur = conn.execute(f"PRAGMA table_info({table})")
    cols = [r[1] for r in cur.fetchall()]  # (cid, name, type, notnull, dflt_value, pk)
    if column not in cols:
        conn.execute(ddl)


def init_db() -> None:
    with open_db() as conn:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS messages (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              chat_id INTEGER NOT NULL,
              mode TEXT NOT NULL,
              role TEXT NOT NULL,
              content TEXT NOT NULL,
              created_at TEXT NOT NULL
            )
            """
        )
        conn.execute("CREATE INDEX IF NOT EXISTS idx_messages_chat_id_id ON messages(chat_id, id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_messages_chat_id_mode_id ON messages(chat_id, mode, id)")

        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS chat_settings (
              chat_id INTEGER PRIMARY KEY,
              temperature REAL NOT NULL,
              updated_at TEXT NOT NULL
            )
            """
        )

        # –º–∏–≥—Ä–∞—Ü–∏–∏: –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∞ —Ä–∞–Ω—å—à–µ
        _ensure_column(
            conn,
            table="chat_settings",
            column="memory_enabled",
            ddl="ALTER TABLE chat_settings ADD COLUMN memory_enabled INTEGER NOT NULL DEFAULT 1",
        )
        _ensure_column(
            conn,
            table="chat_settings",
            column="model",
            ddl="ALTER TABLE chat_settings ADD COLUMN model TEXT",
        )

        conn.commit()


def db_get_chat_settings(chat_id: int) -> tuple[float | None, bool | None, str | None]:
    try:
        with open_db() as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.execute(
                "SELECT temperature, memory_enabled, model FROM chat_settings WHERE chat_id = ?",
                (int(chat_id),),
            )
            row = cur.fetchone()
            if not row:
                return None, None, None

            temp = None
            mem = None
            model = None

            try:
                temp = float(row["temperature"])
            except Exception:
                temp = None

            try:
                mem = bool(int(row["memory_enabled"]))
            except Exception:
                mem = None

            try:
                m = row["model"]
                model = str(m).strip() if m else None
            except Exception:
                model = None

            return temp, mem, model
    except Exception as e:
        logger.exception("DB get settings failed: %s", e)
        return None, None, None


def db_set_temperature(chat_id: int, temperature: float) -> None:
    try:
        old_temp, old_mem, old_model = db_get_chat_settings(chat_id)
        mem_val = int(old_mem) if isinstance(old_mem, bool) else int(DEFAULT_MEMORY_ENABLED)
        model_val = (old_model or "").strip() or None

        with open_db() as conn:
            conn.execute(
                """
                INSERT INTO chat_settings(chat_id, temperature, memory_enabled, model, updated_at)
                VALUES(?, ?, ?, ?, ?)
                ON CONFLICT(chat_id) DO UPDATE SET
                  temperature=excluded.temperature,
                  updated_at=excluded.updated_at
                """,
                (int(chat_id), float(temperature), int(mem_val), model_val, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB set temperature failed: %s", e)


def db_set_memory_enabled(chat_id: int, enabled: bool) -> None:
    try:
        old_temp, old_mem, old_model = db_get_chat_settings(chat_id)
        temp_val = float(old_temp) if isinstance(old_temp, (int, float)) else float(DEFAULT_TEMPERATURE)
        model_val = (old_model or "").strip() or None

        with open_db() as conn:
            conn.execute(
                """
                INSERT INTO chat_settings(chat_id, temperature, memory_enabled, model, updated_at)
                VALUES(?, ?, ?, ?, ?)
                ON CONFLICT(chat_id) DO UPDATE SET
                  memory_enabled=excluded.memory_enabled,
                  updated_at=excluded.updated_at
                """,
                (int(chat_id), float(temp_val), int(bool(enabled)), model_val, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB set memory_enabled failed: %s", e)


def db_set_model(chat_id: int, model: str) -> None:
    try:
        old_temp, old_mem, old_model = db_get_chat_settings(chat_id)
        temp_val = float(old_temp) if isinstance(old_temp, (int, float)) else float(DEFAULT_TEMPERATURE)
        mem_val = int(old_mem) if isinstance(old_mem, bool) else int(DEFAULT_MEMORY_ENABLED)
        model_val = (model or "").strip() or None

        with open_db() as conn:
            conn.execute(
                """
                INSERT INTO chat_settings(chat_id, temperature, memory_enabled, model, updated_at)
                VALUES(?, ?, ?, ?, ?)
                ON CONFLICT(chat_id) DO UPDATE SET
                  model=excluded.model,
                  updated_at=excluded.updated_at
                """,
                (int(chat_id), float(temp_val), int(mem_val), model_val, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB set model failed: %s", e)


def db_get_temperature(chat_id: int) -> float | None:
    t, _, _ = db_get_chat_settings(chat_id)
    return t


def db_get_memory_enabled(chat_id: int) -> bool | None:
    _, m, _ = db_get_chat_settings(chat_id)
    return m


def db_get_model(chat_id: int) -> str | None:
    _, _, m = db_get_chat_settings(chat_id)
    return m


def get_temperature(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> float:
    t = context.user_data.get("temperature", None)
    if isinstance(t, (int, float)):
        return float(t)

    db_t = db_get_temperature(chat_id)
    if isinstance(db_t, (int, float)):
        context.user_data["temperature"] = float(db_t)
        return float(db_t)

    context.user_data["temperature"] = float(DEFAULT_TEMPERATURE)
    return float(DEFAULT_TEMPERATURE)


def get_memory_enabled(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> bool:
    v = context.user_data.get("memory_enabled", None)
    if isinstance(v, bool):
        return v

    db_v = db_get_memory_enabled(chat_id)
    if isinstance(db_v, bool):
        context.user_data["memory_enabled"] = bool(db_v)
        return bool(db_v)

    context.user_data["memory_enabled"] = bool(DEFAULT_MEMORY_ENABLED)
    return bool(DEFAULT_MEMORY_ENABLED)


def get_model(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> str:
    v = context.user_data.get("model", None)
    if isinstance(v, str) and v.strip():
        return v.strip()

    db_v = db_get_model(chat_id)
    if isinstance(db_v, str) and db_v.strip():
        context.user_data["model"] = db_v.strip()
        return db_v.strip()

    # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ => openrouter.py –≤–æ–∑—å–º—ë—Ç OPENROUTER_MODEL –∏–∑ config
    return ""


def get_effective_model(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> str:
    selected = get_model(context, chat_id)
    return selected if selected else OPENROUTER_MODEL


def clamp_temperature(value: float) -> float:
    if value < TEMPERATURE_MIN:
        return TEMPERATURE_MIN
    if value > TEMPERATURE_MAX:
        return TEMPERATURE_MAX
    return value


def db_add_message(chat_id: int, mode: str, role: str, content: str) -> None:
    content = (content or "").strip()
    if not content:
        return
    try:
        with open_db() as conn:
            conn.execute(
                "INSERT INTO messages(chat_id, mode, role, content, created_at) VALUES(?,?,?,?,?)",
                (int(chat_id), str(mode), str(role), content, utc_now_iso()),
            )
            conn.commit()
    except Exception as e:
        logger.exception("DB add failed: %s", e)


def db_clear_history(chat_id: int) -> None:
    try:
        with open_db() as conn:
            conn.execute("DELETE FROM messages WHERE chat_id = ?", (int(chat_id),))
            conn.commit()
    except Exception as e:
        logger.exception("DB clear history failed: %s", e)


def db_get_history(chat_id: int, modes: tuple[str, ...], limit: int) -> list[dict]:
    placeholders = ",".join(["?"] * len(modes))
    sql = f"""
        SELECT role, content
        FROM messages
        WHERE chat_id = ? AND mode IN ({placeholders})
        ORDER BY id DESC
        LIMIT ?
    """
    try:
        with open_db() as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.execute(sql, (int(chat_id), *modes, int(limit)))
            rows = cur.fetchall()
    except Exception as e:
        logger.exception("DB read failed: %s", e)
        return []

    rows = list(reversed(rows))
    out: list[dict] = []
    for r in rows:
        role = (r["role"] or "").strip()
        content = (r["content"] or "").strip()
        if role in ("user", "assistant") and content:
            out.append({"role": role, "content": content})
    return out


def build_messages_with_db_memory(system_prompt: str, chat_id: int) -> list[dict]:
    history = db_get_history(chat_id=chat_id, modes=MEMORY_CHAT_MODES, limit=MEMORY_LIMIT_MESSAGES)
    return [{"role": "system", "content": system_prompt}] + history


# -------------------- PROMPTS --------------------

SYSTEM_PROMPT_JSON = """
–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–∏–º –≤–∞–ª–∏–¥–Ω—ã–º JSON-–æ–±—ä–µ–∫—Ç–æ–º. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤–Ω–µ JSON. –ù–∏–∫–∞–∫–æ–≥–æ markdown.

–°—Ö–µ–º–∞ (–≤—Å–µ–≥–¥–∞ –≤—Å–µ –ø–æ–ª—è, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö):
{
  "title": "",
  "time": "",
  "tag": "",
  "answer": "",
  "steps": [],
  "warnings": [],
  "need_clarification": false,
  "clarifying_question": ""
}

–ü—Ä–∞–≤–∏–ª–∞:
- time –≤—Å–µ–≥–¥–∞ –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—ã–º "" (–µ–≥–æ –∑–∞–ø–æ–ª–Ω–∏—Ç –±–æ—Ç).
- steps –∏ warnings –≤—Å–µ–≥–¥–∞ –º–∞—Å—Å–∏–≤—ã —Å—Ç—Ä–æ–∫.
- need_clarification=true -> clarifying_question —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å, –∏–Ω–∞—á–µ "".
- –ù–∏–∫–∞–∫–∏—Ö –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π. –ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤. –¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON.
"""

SYSTEM_PROMPT_TEXT = """
–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤ Telegram. –û—Ç–≤–µ—á–∞–π –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –∑–∞–¥–∞–π –æ–¥–∏–Ω —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å.
"""

SYSTEM_PROMPT_TZ = """
–¢—ã ‚Äî AI-–∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–±–∏—Ä–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –¢–ó –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–π—Ç–∞.

–†–ï–ñ–ò–ú –†–ê–ë–û–¢–´:
1) –ü–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –∏ –∑–∞–¥–∞–π –†–û–í–ù–û –û–î–ò–ù —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å.
2) –ö–æ–≥–¥–∞ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –æ–¥–∏–Ω –≤–∞–ª–∏–¥–Ω—ã–π JSON –ø–æ —Å—Ö–µ–º–µ –Ω–∏–∂–µ (–±–µ–∑ –ª—é–±–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ/–ø–æ—Å–ª–µ).
3) –í–æ–ø—Ä–æ—Å–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∞–ª–æ: —Å—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –≤ 3‚Äì4 –≤–æ–ø—Ä–æ—Å–∞. –ö–∞–∫ —Ç–æ–ª—å–∫–æ –ø–æ–Ω—è—Ç–Ω–æ ‚Äî —Å—Ä–∞–∑—É —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–π JSON.

–°–•–ï–ú–ê JSON (–≤—Å–µ–≥–¥–∞ –≤—Å–µ –ø–æ–ª—è, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö):
{
  "title": "–¢–ó –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–π—Ç–∞",
  "time": "",
  "tag": "tz_site",
  "answer": "",
  "steps": [],
  "warnings": [],
  "need_clarification": false,
  "clarifying_question": ""
}

–ü–†–ê–í–ò–õ–ê:
- –ü–æ–∫–∞ —Ç—ã –∑–∞–¥–∞—ë—à—å –≤–æ–ø—Ä–æ—Å—ã ‚Äî –ù–ï –ü–ò–®–ò JSON.
- –ö–æ–≥–¥–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å ‚Äî –ø–∏—à–∏ –¢–û–õ–¨–ö–û JSON.
- time –≤ JSON –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—ã–º "" (–µ–≥–æ –∑–∞–ø–æ–ª–Ω–∏—Ç –±–æ—Ç).
- steps/warnings –≤—Å–µ–≥–¥–∞ –º–∞—Å—Å–∏–≤—ã —Å—Ç—Ä–æ–∫.
- –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π.
"""

SYSTEM_PROMPT_FOREST = """
–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç, –∫—Ç–æ –∫–æ–º—É —Å–∫–æ–ª—å–∫–æ –¥–æ–ª–∂–µ–Ω –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –∑–∞ –æ–±—â–∏–µ —Ä–∞—Å—Ö–æ–¥—ã (–ø–æ—Ö–æ–¥/–ª–µ—Å/–∫–∞—Ñ–µ).

–í–ê–ñ–ù–û: –≤–µ—Å—å –¥–∏–∞–ª–æ–≥ (–≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã) ‚Äî –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º.
–ö–æ–≥–¥–∞ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Ç—ã –¥–æ–ª–∂–µ–Ω –°–ê–ú –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –∏ –≤—ã–¥–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

–†–ï–ñ–ò–ú –†–ê–ë–û–¢–´:
1) –ü–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –∑–∞–¥–∞–π –†–û–í–ù–û –û–î–ò–ù –≤–æ–ø—Ä–æ—Å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ.
2) –°—Ç–∞—Ä–∞–π—Å—è —É–ª–æ–∂–∏—Ç—å—Å—è –≤ 3‚Äì4 –≤–æ–ø—Ä–æ—Å–∞. –ù–µ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–π.
3) –ö–∞–∫ —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –≤—ã–¥–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∏ –±–æ–ª—å—à–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –∑–∞–¥–∞–≤–∞–π.

–ß–¢–û –ù–£–ñ–ù–û –°–û–ë–†–ê–¢–¨:
- –°–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ (–∏–º–µ–Ω–∞).
- –°–∫–æ–ª—å–∫–æ –∑–∞–ø–ª–∞—Ç–∏–ª –∫–∞–∂–¥—ã–π (–≤ —Ä—É–±–ª—è—Ö).
- –ö–∞–∫ –¥–µ–ª–∏–º —Ä–∞—Å—Ö–æ–¥—ã: "–ø–æ—Ä–æ–≤–Ω—É" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∏–ª–∏ "–ø–æ –¥–æ–ª—è–º" (–µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ —Å–∫–∞–∂–µ—Ç, —Ç–æ–≥–¥–∞ —Å–ø—Ä–æ—Å–∏ –¥–æ–ª–∏).

–ü–†–ï–î–ü–û–ß–¢–ò–¢–ï–õ–¨–ù–´–ô –§–û–†–ú–ê–¢ –°–ë–û–†–ê (—á—Ç–æ–±—ã –≤–æ–ø—Ä–æ—Å–æ–≤ –±—ã–ª–æ –º–∞–ª–æ):
- 1-–π –≤–æ–ø—Ä–æ—Å: "–ö—Ç–æ —É—á–∞—Å—Ç–Ω–∏–∫–∏? (–ø–µ—Ä–µ—á–∏—Å–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)"
- 2-–π –≤–æ–ø—Ä–æ—Å: "–ù–∞–ø–∏—à–∏, –∫—Ç–æ —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–ª–∞—Ç–∏–ª –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: –ò–º—è —Å—É–º–º–∞, –ò–º—è —Å—É–º–º–∞, ..."
- 3-–π –≤–æ–ø—Ä–æ—Å (–µ—Å–ª–∏ –Ω–µ —Å–∫–∞–∑–∞–Ω–æ): "–î–µ–ª–∏–º –ø–æ—Ä–æ–≤–Ω—É? (–¥–∞/–Ω–µ—Ç). –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –∫–∞–∫ –¥–µ–ª–∏–º?"

–ê–õ–ì–û–†–ò–¢–ú (–¥–µ–ª–∞–π —Å–∞–º, –±–µ–∑ Python):
- Total = —Å—É–º–º–∞ –≤—Å–µ—Ö –æ–ø–ª–∞—Ç.
- –ï—Å–ª–∏ –¥–µ–ª–∏–º –ø–æ—Ä–æ–≤–Ω—É: Share = Total / N.
- –ë–∞–ª–∞–Ω—Å —É—á–∞—Å—Ç–Ω–∏–∫–∞ = paid - share.
  - balance > 0: –¥–æ–ª–∂–µ–Ω –ø–æ–ª—É—á–∏—Ç—å
  - balance < 0: –¥–æ–ª–∂–µ–Ω –∑–∞–ø–ª–∞—Ç–∏—Ç—å
- –°–æ—Å—Ç–∞–≤—å –ø–µ—Ä–µ–≤–æ–¥—ã –æ—Ç –¥–æ–ª–∂–Ω–∏–∫–æ–≤ –∫ –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º —Ç–∞–∫, —á—Ç–æ–±—ã –∑–∞–∫—Ä—ã—Ç—å –±–∞–ª–∞–Ω—Å—ã.
- –í—Å–µ–≥–¥–∞ —Å–¥–µ–ª–∞–π –ø—Ä–æ–≤–µ—Ä–∫—É: —Å—É–º–º–∞ –±–∞–ª–∞–Ω—Å–æ–≤ = 0 (–∏–ª–∏ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∏–∑-–∑–∞ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è).

–û–ö–†–£–ì–õ–ï–ù–ò–ï:
- –ï—Å–ª–∏ —Å—É–º–º—ã —Ü–µ–ª—ã–µ ‚Äî —Ä–∞–±–æ—Ç–∞–π –≤ —Ü–µ–ª—ã—Ö.
- –ï—Å–ª–∏ –ø–æ—è–≤–ª—è—é—Ç—Å—è –∫–æ–ø–µ–π–∫–∏ ‚Äî –æ–∫—Ä—É–≥–ª—è–π –¥–æ 2 –∑–Ω–∞–∫–æ–≤ –∏ –≤ –∫–æ–Ω—Ü–µ –ø—Ä–æ–≤–µ—Ä—å, —á—Ç–æ–±—ã –ø–µ—Ä–µ–≤–æ–¥—ã —Å–æ—à–ª–∏—Å—å.

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê –§–ò–ù–ê–õ–ê (–û–î–ò–ù –†–ê–ó, –≤ –∫–æ–Ω—Ü–µ):
1) –ö–æ—Ä–æ—Ç–∫–æ: Total, N, Share (–∏–ª–∏ –ø—Ä–∞–≤–∏–ª–æ –¥–µ–ª–µ–Ω–∏—è)
2) –¢–∞–±–ª–∏—Ü–∞ —Å—Ç—Ä–æ–∫–∞–º–∏:
   –ò–º—è: paid=..., share=..., balance=... (–ø–æ–ª—É—á–∏—Ç—å/–∑–∞–ø–ª–∞—Ç–∏—Ç—å ...)
3) "–§–∏–Ω–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã:" —Å–ø–∏—Å–∫–æ–º "–ò–º—è -> –ò–º—è: —Å—É–º–º–∞"
4) –°—Ç—Ä–æ–∫–∞ "–ü—Ä–æ–≤–µ—Ä–∫–∞: —Å—É–º–º–∞ –±–∞–ª–∞–Ω—Å–æ–≤ = ..."

–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ü–†–ê–í–ò–õ–û:
- –°–ª–æ–≤–æ "FINAL" –ø–∏—à–∏ –¢–û–õ–¨–ö–û –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑.
- –î–æ —Ñ–∏–Ω–∞–ª–∞ "FINAL" –Ω–µ –ø–∏—Å–∞—Ç—å.
"""

SYSTEM_PROMPT_THINKING = """
–¢—ã —Ä–µ—à–∞–µ—à—å –∑–∞–¥–∞—á–∏ –≤ —Ä–µ–∂–∏–º–µ "–ø–æ—à–∞–≥–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ".
–ü—Ä–∞–≤–∏–ª–∞:
- –†–µ—à–∞–π –∑–∞–¥–∞—á—É –ø–æ—à–∞–≥–æ–≤–æ.
- –í –∫–æ–Ω—Ü–µ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: "–ò–¢–û–ì: ...".
- –ü–∏—à–∏ –ø–æ–Ω—è—Ç–Ω–æ –∏ –±–µ–∑ –≤–æ–¥—ã.
"""

SYSTEM_PROMPT_EXPERTS = """
–¢—ã —Ä–µ—à–∞–µ—à—å –∑–∞–¥–∞—á—É –∫–∞–∫ "–≥—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤" –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.

–≠–∫—Å–ø–µ—Ä—Ç—ã:
1) –õ–æ–≥–∏–∫ ‚Äî —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π, –ø–æ–∏—Å–∫ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π.
2) –ú–∞—Ç–µ–º–∞—Ç–∏–∫ ‚Äî –≤—ã—á–∏—Å–ª–µ–Ω–∏—è/—Ñ–æ—Ä–º—É–ª—ã/–∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞).
3) –†–µ–≤–∏–∑–æ—Ä ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ—à–µ–Ω–∏—è –õ–æ–≥–∏–∫–∞ –∏ –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –∏—â–µ—Ç –æ—à–∏–±–∫–∏, –¥–∞—ë—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å–≤–µ—Ä–∫—É.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ —Å—Ç—Ä–æ–≥–æ —Ç–∞–∫–æ–π:
–õ–û–ì–ò–ö:
...

–ú–ê–¢–ï–ú–ê–¢–ò–ö:
...

–†–ï–í–ò–ó–û–†:
...

–ò–¢–û–ì:
(–æ–¥–Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞)

–ü—Ä–∞–≤–∏–ª–∞:
- –í—Å–µ —Ç—Ä–∏ —á–∞—Å—Ç–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å.
- –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –Ω–æ —Ç–∞–∫, —á—Ç–æ–±—ã –±—ã–ª–æ —è—Å–Ω–æ, –ø–æ—á–µ–º—É –∏—Ç–æ–≥ –≤–µ—Ä–Ω—ã–π.
"""


# -------------------- HELPERS --------------------

TELEGRAM_MESSAGE_LIMIT = 3900  # –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ 4096


def split_telegram_text(text: str, limit: int = TELEGRAM_MESSAGE_LIMIT) -> list[str]:
    t = (text or "").strip()
    if not t:
        return [""]

    if len(t) <= limit:
        return [t]

    parts: list[str] = []
    cur = t
    while len(cur) > limit:
        cut = cur.rfind("\n", 0, limit)
        if cut < 200:
            cut = limit
        parts.append(cur[:cut].rstrip())
        cur = cur[cut:].lstrip()
    if cur:
        parts.append(cur)
    return parts


async def safe_reply_text(update: Update, text: str) -> None:
    if not update.message:
        return

    chunks = split_telegram_text(text)
    for ch in chunks:
        try:
            await update.message.reply_text(ch)
        except TimedOut:
            return
        except BadRequest as e:
            msg = str(e).lower()
            if "message is too long" in msg and len(ch) > 500:
                for sub in split_telegram_text(ch, limit=2000):
                    try:
                        await update.message.reply_text(sub)
                    except Exception:
                        return
                continue
            return
        except Exception:
            return


def extract_json_object(text: str) -> str:
    text = (text or "").strip()
    text = re.sub(r"^```(?:json)?\s*|\s*```$", "", text, flags=re.IGNORECASE)
    m = re.search(r"\{.*\}", text, flags=re.DOTALL)
    if not m:
        raise ValueError("JSON object not found in model output")
    return m.group(0)


def normalize_payload(data: dict) -> dict:
    normalized = {
        "title": str(data.get("title", "")).strip() or "–û—Ç–≤–µ—Ç",
        "time": utc_now_iso(),
        "tag": str(data.get("tag", "")).strip() or "general",
        "answer": str(data.get("answer", "")).strip(),
        "steps": data.get("steps", []),
        "warnings": data.get("warnings", []),
        "need_clarification": bool(data.get("need_clarification", False)),
        "clarifying_question": str(data.get("clarifying_question", "")).strip(),
    }

    if not isinstance(normalized["steps"], list):
        normalized["steps"] = []
    if not isinstance(normalized["warnings"], list):
        normalized["warnings"] = []

    normalized["steps"] = [str(x).strip() for x in normalized["steps"] if str(x).strip()]
    normalized["warnings"] = [str(x).strip() for x in normalized["warnings"] if str(x).strip()]

    if normalized["need_clarification"]:
        if not normalized["clarifying_question"]:
            normalized["clarifying_question"] = "–£—Ç–æ—á–Ω–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞: —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã –∏–º–µ–µ—à—å –≤ –≤–∏–¥—É?"
        if not normalized["answer"]:
            normalized["answer"] = normalized["clarifying_question"]
    else:
        normalized["clarifying_question"] = ""

    if not normalized["answer"]:
        normalized["answer"] = "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

    return normalized


def repair_json_with_model(system_prompt: str, raw: str, temperature: float, model: str | None) -> str:
    repair_prompt = (
        system_prompt
        + "\n\n–ò—Å–ø—Ä–∞–≤—å —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç–≤–µ—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω —Å—Ç–∞–ª –≤–∞–ª–∏–¥–Ω—ã–º JSON —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON."
    )
    fixed = chat_completion(
        [
            {"role": "system", "content": repair_prompt},
            {"role": "user", "content": raw or ""},
        ],
        temperature=temperature,
        model=model,
    )
    return fixed


def get_mode(context: ContextTypes.DEFAULT_TYPE) -> str:
    return context.user_data.get("mode", "text")  # text | json | tz | forest | thinking | experts | summary


def looks_like_json(text: str) -> bool:
    t = (text or "").lstrip()
    return (t.startswith("{") and t.endswith("}")) or t.startswith("{")


def is_forest_final(text: str) -> bool:
    t = (text or "").lstrip()
    return t.upper().startswith("FINAL")


def strip_forest_final_marker(text: str) -> str:
    lines = (text or "").splitlines()
    if not lines:
        return ""
    if lines[0].strip().upper() == "FINAL":
        return "\n".join(lines[1:]).strip()
    return (text or "").strip()


def user_asked_to_show_result(user_text: str) -> bool:
    t = (user_text or "").strip().lower()
    keywords = ["–ø–æ–∫–∞–∂–∏", "–≤—ã–≤–µ–¥–∏", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç", "—Ä–∞—Å—á", "–∏—Ç–æ–≥", "—Ñ–∏–Ω–∞–ª", "–ø–µ—Ä–µ–≤–æ–¥—ã", "–∫—Ç–æ –∫–æ–º—É"]
    return any(k in t for k in keywords)


def reset_tz(context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data.pop("tz_history", None)
    context.user_data.pop("tz_questions", None)
    context.user_data.pop("tz_done", None)


def reset_forest(context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data.pop("forest_history", None)
    context.user_data.pop("forest_questions", None)
    context.user_data.pop("forest_done", None)
    context.user_data.pop("forest_result", None)


# -------------------- COMMANDS --------------------

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    mode = get_mode(context)
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    t = get_temperature(context, chat_id)
    mem = get_memory_enabled(context, chat_id)
    current_model = get_effective_model(context, chat_id)

    lines = [
        "–ü—Ä–∏–≤–µ—Ç!",
        "",
        "–ö–æ–º–∞–Ω–¥—ã:",
        f"/mode_text ‚Äî —Ä–µ–∂–∏–º text + {_short_model_name(OPENROUTER_MODEL)}",
        "/mode_json ‚Äî JSON –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        f"/mode_summary ‚Äî —Ä–µ–∂–∏–º summary + {_short_model_name(OPENROUTER_MODEL)} (—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏)",
        "/tz_creation_site ‚Äî —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –¢–ó (–≤–æ–ø—Ä–æ—Å—ã —Ç–µ–∫—Å—Ç–æ–º, –∏—Ç–æ–≥ JSON)",
        "/forest_split ‚Äî –∫—Ç–æ –∫–æ–º—É –¥–æ–ª–∂–µ–Ω (–≤–æ–ø—Ä–æ—Å—ã —Ç–µ–∫—Å—Ç–æ–º, –∏—Ç–æ–≥ —Ç–µ–∫—Å—Ç–æ–º)",
        "/thinking_model ‚Äî —Ä–µ—à–∞–π –ø–æ—à–∞–≥–æ–≤–æ",
        "/expert_group_model ‚Äî –≥—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤",
        "/tokens_test ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤ (—Ä–µ–∂–∏–º: –∫–æ—Ä–æ—Ç–∫–∏–π/–¥–ª–∏–Ω–Ω—ã–π/–ø–µ—Ä–µ–ª–∏–º–∏—Ç)",
        "/tokens_next ‚Äî —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø —Ç–µ—Å—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤",
        "/tokens_stop ‚Äî —Å–≤–æ–¥–∫–∞ –∏ –≤—ã—Ö–æ–¥ –∏–∑ —Ç–µ—Å—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤",
        "/ch_temperature ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: /ch_temperature 0.7)",
        "/ch_memory ‚Äî –ø–∞–º—è—Ç—å –í–ö–õ/–í–´–ö–õ (–ø—Ä–∏–º–µ—Ä: /ch_memory off)",
        "/clear_memory ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞",
    ]

    if MODEL_GLM:
        lines.append(f"/model_glm ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GLM)}")
    if MODEL_GEMMA:
        lines.append(f"/model_gemma ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GEMMA)}")

    lines.extend([
        "",
        f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {mode}",
        f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {t}",
        f"–ü–∞–º—è—Ç—å: {'–í–ö–õ' if mem else '–í–´–ö–õ'}",
        f"–ú–æ–¥–µ–ª—å: {current_model}",
    ])

    await safe_reply_text(update, "\n".join(lines))


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    lines = [
        "–ö–æ–º–∞–Ω–¥—ã:",
        f"/mode_text ‚Äî —Ä–µ–∂–∏–º text + {_short_model_name(OPENROUTER_MODEL)}",
        "/mode_json ‚Äî JSON –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        f"/mode_summary ‚Äî —Ä–µ–∂–∏–º summary + {_short_model_name(OPENROUTER_MODEL)} (—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏)",
        "/tz_creation_site ‚Äî —Å–æ–±—Ä–∞—Ç—å –¢–ó –Ω–∞ —Å–∞–π—Ç (–≤ –∫–æ–Ω—Ü–µ JSON)",
        "/forest_split ‚Äî –ø–æ—Å—á–∏—Ç–∞—Ç—å –∫—Ç–æ –∫–æ–º—É –¥–æ–ª–∂–µ–Ω (–≤ –∫–æ–Ω—Ü–µ —Ç–µ–∫—Å—Ç)",
        "/thinking_model ‚Äî —Ä–µ—à–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ",
        "/expert_group_model ‚Äî —Ä–µ—à–∏—Ç—å –∫–∞–∫ –≥—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤",
        "/tokens_test ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤ (—Ä–µ–∂–∏–º)",
        "/tokens_next ‚Äî —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø —Ç–µ—Å—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤",
        "/tokens_stop ‚Äî —Å–≤–æ–¥–∫–∞ –∏ –≤—ã—Ö–æ–¥ –∏–∑ —Ç–µ—Å—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤",
        "/ch_temperature ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: /ch_temperature 1.2)",
        "/ch_memory ‚Äî –ø–∞–º—è—Ç—å –í–ö–õ/–í–´–ö–õ (–ø—Ä–∏–º–µ—Ä: /ch_memory on)",
        "/clear_memory ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø–∞–º—è—Ç–∏",
    ]

    if MODEL_GLM:
        lines.append(f"/model_glm ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –Ω–∞ {MODEL_GLM}")
    if MODEL_GEMMA:
        lines.append(f"/model_gemma ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –Ω–∞ {MODEL_GEMMA}")

    await safe_reply_text(update, "\n".join(lines))


async def ch_temperature_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args:
        t = get_temperature(context, chat_id)
        await safe_reply_text(
            update,
            f"–¢–µ–∫—É—â–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {t}\n"
            f"–ò–∑–º–µ–Ω–∏—Ç—å: /ch_temperature <—á–∏—Å–ª–æ –æ—Ç {TEMPERATURE_MIN} –¥–æ {TEMPERATURE_MAX}>\n"
            "–ü—Ä–∏–º–µ—Ä—ã: /ch_temperature 0, /ch_temperature 0.7, /ch_temperature 1.2"
        )
        return

    raw = (context.args[0] or "").replace(",", ".").strip()
    try:
        val = float(raw)
    except Exception:
        await safe_reply_text(update, "–ù–µ –ø–æ–Ω—è–ª —á–∏—Å–ª–æ. –ü—Ä–∏–º–µ—Ä: /ch_temperature 0.7")
        return

    val = clamp_temperature(val)

    context.user_data["temperature"] = val
    db_set_temperature(chat_id, val)

    await safe_reply_text(update, f"–û–∫. –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {val}")


async def ch_memory_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    /ch_memory
    /ch_memory on|off
    """
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args:
        mem = get_memory_enabled(context, chat_id)
        await safe_reply_text(
            update,
            f"–ü–∞–º—è—Ç—å —Å–µ–π—á–∞—Å: {'–í–ö–õ' if mem else '–í–´–ö–õ'}\n"
            "–ò–∑–º–µ–Ω–∏—Ç—å: /ch_memory on –∏–ª–∏ /ch_memory off\n"
            "–ü—Ä–∏–º–µ—Ä: /ch_memory off (–¥–ª—è —á–µ—Å—Ç–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã)"
        )
        return

    v = (context.args[0] or "").strip().lower()
    truthy = {"on", "1", "true", "yes", "y", "–¥–∞", "–≤–∫–ª"}
    falsy = {"off", "0", "false", "no", "n", "–Ω–µ—Ç", "–≤—ã–∫–ª"}

    if v in truthy:
        enabled = True
    elif v in falsy:
        enabled = False
    else:
        await safe_reply_text(update, "–ù–µ –ø–æ–Ω—è–ª. –ò—Å–ø–æ–ª—å–∑—É–π: /ch_memory on –∏–ª–∏ /ch_memory off")
        return

    context.user_data["memory_enabled"] = enabled
    db_set_memory_enabled(chat_id, enabled)

    await safe_reply_text(update, f"–û–∫. –ü–∞–º—è—Ç—å: {'–í–ö–õ' if enabled else '–í–´–ö–õ'}")


async def clear_memory_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    db_clear_history(chat_id)

    # NEW: —á–∏—Å—Ç–∏–º summary-—Ç–∞–±–ª–∏—Ü—É —Ç–æ–∂–µ
    try:
        clear_summary(chat_id, mode=MODE_SUMMARY)
    except Exception:
        pass

    await safe_reply_text(update, "–û–∫. –ü–∞–º—è—Ç—å —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞.")


async def model_glm_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not MODEL_GLM:
        await safe_reply_text(update, "–ú–æ–¥–µ–ª—å OPENROUTER_MODEL_GLM –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ .env")
        return
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    context.user_data["model"] = MODEL_GLM
    db_set_model(chat_id, MODEL_GLM)
    await safe_reply_text(update, f"–û–∫. –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {MODEL_GLM}")


async def model_gemma_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not MODEL_GEMMA:
        await safe_reply_text(update, "–ú–æ–¥–µ–ª—å OPENROUTER_MODEL_GEMMA –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ .env")
        return
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    context.user_data["model"] = MODEL_GEMMA
    db_set_model(chat_id, MODEL_GEMMA)
    await safe_reply_text(update, f"–û–∫. –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {MODEL_GEMMA}")


async def mode_text_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    context.user_data["mode"] = "text"
    reset_tz(context)
    reset_forest(context)

    # –°–±—Ä–æ—Å –Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ .env (OPENROUTER_MODEL)
    context.user_data.pop("model", None)
    db_set_model(chat_id, "")

    await safe_reply_text(update, f"–û–∫. –†–µ–∂–∏–º: text. –ú–æ–¥–µ–ª—å: {OPENROUTER_MODEL}")


async def mode_json_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "json"
    reset_tz(context)
    reset_forest(context)

    payload = {
        "title": "–†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω",
        "time": utc_now_iso(),
        "tag": "system",
        "answer": "–û–∫. –†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: json",
        "steps": [],
        "warnings": [],
        "need_clarification": False,
        "clarifying_question": "",
    }
    context.user_data["last_payload"] = payload
    await safe_reply_text(update, json.dumps(payload, ensure_ascii=False, indent=2))


# NEW: summary mode command
async def mode_summary_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    context.user_data["mode"] = MODE_SUMMARY
    reset_tz(context)
    reset_forest(context)

    # –í summary-—Ä–µ–∂–∏–º–µ –ø–∞–º—è—Ç—å –Ω—É–∂–Ω–∞ –≤—Å–µ–≥–¥–∞
    context.user_data["memory_enabled"] = True
    db_set_memory_enabled(chat_id, True)

    await safe_reply_text(update, "–û–∫. –†–µ–∂–∏–º: summary (—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏: summary –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏).")


async def thinking_model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "thinking"
    reset_tz(context)
    reset_forest(context)
    await safe_reply_text(update, "–û–∫. –†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: thinking_model (–ø–æ—à–∞–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ).")


async def expert_group_model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "experts"
    reset_tz(context)
    reset_forest(context)
    await safe_reply_text(update, "–û–∫. –†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: expert_group_model (–õ–æ–≥–∏–∫/–ú–∞—Ç–µ–º–∞—Ç–∏–∫/–†–µ–≤–∏–∑–æ—Ä).")


async def tz_creation_site_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "tz"
    context.user_data["tz_history"] = []
    context.user_data["tz_questions"] = 0
    context.user_data["tz_done"] = False
    reset_forest(context)

    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    temperature = get_temperature(context, chat_id)
    model = get_model(context, chat_id) or None

    first = (chat_completion(
        [
            {"role": "system", "content": SYSTEM_PROMPT_TZ},
            {"role": "user", "content": "–ù–∞—á–Ω–∏. –ó–∞–¥–∞–π –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å, —á—Ç–æ–±—ã —Å–æ–±—Ä–∞—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –¢–ó –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–π—Ç–∞."},
        ],
        temperature=temperature,
        model=model,
    ) or "").strip()

    if looks_like_json(first):
        await send_final_tz_json(update, context, first, temperature=temperature, model=model)
        return

    context.user_data["tz_questions"] = 1
    context.user_data["tz_history"].append({"role": "assistant", "content": first})
    await safe_reply_text(update, first)


async def forest_split_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    context.user_data["mode"] = "forest"
    context.user_data["forest_history"] = []
    context.user_data["forest_questions"] = 0
    context.user_data["forest_done"] = False
    context.user_data.pop("forest_result", None)
    reset_tz(context)

    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    temperature = get_temperature(context, chat_id)
    model = get_model(context, chat_id) or None

    first = (chat_completion(
        [
            {"role": "system", "content": SYSTEM_PROMPT_FOREST},
            {"role": "user", "content": "–ù–∞—á–Ω–∏. –ó–∞–¥–∞–π –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –∫—Ç–æ –∫–æ–º—É —Å–∫–æ–ª—å–∫–æ –¥–æ–ª–∂–µ–Ω."},
        ],
        temperature=temperature,
        model=model,
    ) or "").strip()

    context.user_data["forest_questions"] = 1
    context.user_data["forest_history"].append({"role": "assistant", "content": first})
    await safe_reply_text(update, first)


# -------------------- WEATHER SUBSCRIPTION --------------------
async def weather_sub_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ –ø–æ–≥–æ–¥—É —Å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–º —Å–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö.
    –§–æ—Ä–º–∞—Ç: /weather_sub <–ì–æ—Ä–æ–¥> <–≤—Ä–µ–º—è_–≤_—Å–µ–∫—É–Ω–¥–∞—Ö>
    –ü—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30
    """
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args or len(context.args) < 2:
        await safe_reply_text(
            update,
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /weather_sub <–ì–æ—Ä–æ–¥> <–≤—Ä–µ–º—è_–≤_—Å–µ–∫—É–Ω–¥–∞—Ö>\n"
            "–ü—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30\n"
            "–ü–æ–¥–ø–∏—Å–∫–∞ –±—É–¥–µ—Ç —Å–æ–±–∏—Ä–∞—Ç—å –ø–æ–≥–æ–¥—É –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å summary –∫–∞–∂–¥—ã–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Å–µ–∫—É–Ω–¥—ã.",
        )
        return

    city = context.args[0].strip()
    try:
        summary_interval = int(context.args[1])
        if summary_interval < 10:
            await safe_reply_text(update, "–ò–Ω—Ç–µ—Ä–≤–∞–ª summary –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –º–µ–Ω–µ–µ 10 —Å–µ–∫—É–Ω–¥.")
            return
    except ValueError:
        await safe_reply_text(update, "–í—Ä–µ–º—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö).")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–¥–ø–∏—Å–∫—É
    try:
        start_weather_subscription(
            chat_id=chat_id,
            city=city,
            summary_interval=summary_interval,
            bot=context.bot,
            context=context,
            db_add_message=db_add_message,
        )
    except Exception as e:
        logger.exception(f"Failed to start weather subscription: {e}")
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–æ–¥–ø–∏—Å–∫–∏: {e}")


async def weather_sub_stop_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ –ø–æ–≥–æ–¥—É.
    –§–æ—Ä–º–∞—Ç: /weather_sub_stop <–ì–æ—Ä–æ–¥>
    """
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0

    if not context.args or len(context.args) < 1:
        await safe_reply_text(update, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /weather_sub_stop <–ì–æ—Ä–æ–¥>\n–ü—Ä–∏–º–µ—Ä: /weather_sub_stop –ú–æ—Å–∫–≤–∞")
        return

    city = context.args[0].strip()
    stopped = stop_weather_subscription(chat_id=chat_id, city=city, context=context)

    if stopped:
        await safe_reply_text(update, f"‚úÖ –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É –¥–ª—è {city} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    else:
        await safe_reply_text(update, f"‚ùå –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É –¥–ª—è {city} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")


# -------------------- DIGEST COMMAND --------------------

async def digest_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É—Ç—Ä–µ–Ω–Ω–µ–π —Å–≤–æ–¥–∫–∏: –ø–æ–≥–æ–¥–∞ + –Ω–æ–≤–æ—Å—Ç–∏.
    –§–æ—Ä–º–∞—Ç: /digest <–≥–æ—Ä–æ–¥ –ø–æ–≥–æ–¥—ã>, <—Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π>
    –ü—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
    """
    if not update.message:
        return
    
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã: –≥–æ—Ä–æ–¥ –∏ —Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    if not context.args:
        await safe_reply_text(
            update,
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /digest <–≥–æ—Ä–æ–¥ –ø–æ–≥–æ–¥—ã>, <—Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π>\n"
            "–ü—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\n"
            "–ü—Ä–∏–º–µ—Ä: /digest –°–∞–º–∞—Ä–∞, —Å–ø–æ—Ä—Ç"
        )
        return
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç–æ–π
    full_text = " ".join(context.args)
    parts = [p.strip() for p in full_text.split(",", 1)]
    
    if len(parts) < 2:
        await safe_reply_text(
            update,
            "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /digest <–≥–æ—Ä–æ–¥>, <—Ç–µ–º–∞>\n"
            "–ü—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"
        )
        return
    
    city = parts[0]
    news_topic = parts[1]
    
    if not city or not news_topic:
        await safe_reply_text(update, "–ì–æ—Ä–æ–¥ –∏ —Ç–µ–º–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–∫–∞–∑–∞–Ω—ã.")
        return
    
    await update.message.chat.send_action("typing")
    
    # –°–∫–ª–æ–Ω—è–µ–º –≥–æ—Ä–æ–¥ –≤ –ø—Ä–µ–¥–ª–æ–∂–Ω—ã–π –ø–∞–¥–µ–∂ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ
    city_prep = _city_prepositional_case(city)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–≥–æ–¥—É —á–µ—Ä–µ–∑ MCP
    weather_text = await get_weather_via_mcp(city)
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ MCP (5 –Ω–æ–≤–æ—Å—Ç–µ–π)
    news_text = await get_news_via_mcp(news_topic, count=5)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º Markdown —Ñ–∞–π–ª
    from datetime import datetime, timedelta, timezone
    
    # –°–∞–º–∞—Ä—Å–∫–æ–µ –≤—Ä–µ–º—è (UTC+4)
    SAMARA_OFFSET = timedelta(hours=4)
    SAMARA_TIMEZONE = timezone(SAMARA_OFFSET)
    now = datetime.now(SAMARA_TIMEZONE)
    date_str = now.strftime("%d.%m.%Y %H:%M")
    
    markdown_content = f"""# –°–≤–æ–¥–∫–∞ –ø–æ–≥–æ–¥—ã –≤ {city_prep} –∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–µ {news_topic}
**–î–∞—Ç–∞:** {date_str}

## –ü–æ–≥–æ–¥–∞: {city}

{weather_text}

## –ù–æ–≤–æ—Å—Ç–∏: {news_topic}

{news_text}

---
*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏*
"""
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º Markdown —Ñ–∞–π–ª
    digest_dir = Path(__file__).resolve().parent / "digests"
    digest_dir.mkdir(exist_ok=True)
    filename = f"digest_{chat_id}_{now.strftime('%Y%m%d_%H%M%S')}.md"
    filepath = digest_dir / filename
    
    try:
        filepath.write_text(markdown_content, encoding="utf-8")
    except Exception as e:
        logger.exception(f"Failed to save digest file: {e}")
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ò–ò
    mode = MODE_SUMMARY
    temperature = get_temperature(context, chat_id)
    model = get_model(context, chat_id) or None
    
    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò
    system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å–≤–æ–¥–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–≥–æ–¥–µ –∏ –Ω–æ–≤–æ—Å—Ç—è—Ö.
–°–¥–µ–ª–∞–π —Å–≤–æ–¥–∫—É –∫—Ä–∞—Ç–∫–æ–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –∏ –ø—Ä–∏—è—Ç–Ω–æ–π –¥–ª—è —á—Ç–µ–Ω–∏—è.
–ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≥–æ–¥–µ –∏ –Ω–æ–≤–æ—Å—Ç—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã."""
    
    user_prompt = f"""–°–æ–∑–¥–∞–π —Å–≤–æ–¥–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö:

–ü–û–ì–û–î–ê:
{weather_text}

–ù–û–í–û–°–¢–ò:
{news_text}

–í–ê–ñ–ù–û: –ù–∞—á–Ω–∏ —Å–≤–æ–¥–∫—É —Å —Ñ—Ä–∞–∑—ã "–°–≤–æ–¥–∫–∞ –ø–æ–≥–æ–¥—ã –≤ {city_prep} –∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–µ {news_topic}!" (–±–µ–∑ –∫–∞–≤—ã—á–µ–∫).
–ó–∞—Ç–µ–º —Å—Ñ–æ—Ä–º–∏—Ä—É–π –∫—Ä–∞—Ç–∫—É—é –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—É—é —Å–≤–æ–¥–∫—É, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–≥–æ–¥—É –∏ –Ω–æ–≤–æ—Å—Ç–∏."""
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò —á–µ—Ä–µ–∑ mode_summary
    try:
        messages = build_messages_with_summary(system_prompt, chat_id=chat_id, mode=mode)
        messages.append({"role": "user", "content": user_prompt})
        
        data = chat_completion_raw(messages, temperature=temperature, model=model)
        ai_response = _get_content_from_raw(data)
        
        if not ai_response:
            ai_response = f"–ü–æ–≥–æ–¥–∞: {weather_text}\n\n–ù–æ–≤–æ—Å—Ç–∏: {news_text}"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        db_add_message(chat_id, mode, "user", f"/digest {city}, {news_topic}")
        db_add_message(chat_id, mode, "assistant", ai_response)
        
        # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        try:
            maybe_compress_history(chat_id, temperature=0.0, mode=mode)
        except Exception:
            pass
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò
        await safe_reply_text(update, ai_response)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º Markdown —Ñ–∞–π–ª
        try:
            with open(filepath, "rb") as f:
                await update.message.reply_document(
                    document=f,
                    filename=filename,
                    caption=f"üìÑ Markdown —Ñ–∞–π–ª —Å–æ —Å–≤–æ–¥–∫–æ–π: {city}, {news_topic}"
                )
        except Exception as e:
            logger.exception(f"Failed to send digest file: {e}")
            await safe_reply_text(update, f"‚ö†Ô∏è –°–≤–æ–¥–∫–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª: {e}")
    
    except Exception as e:
        logger.exception(f"Failed to generate digest: {e}")
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–≤–æ–¥–∫–∏: {e}")


# -------------------- TZ FLOW --------------------

async def send_final_tz_json(update: Update, context: ContextTypes.DEFAULT_TYPE, raw: str, temperature: float, model: str | None) -> None:
    try:
        json_str = extract_json_object(raw)
        data = json.loads(json_str)
        payload = normalize_payload(data)
    except Exception:
        try:
            fixed_raw = repair_json_with_model(SYSTEM_PROMPT_TZ, raw, temperature=temperature, model=model)
            json_str = extract_json_object(fixed_raw)
            data = json.loads(json_str)
            payload = normalize_payload(data)
        except Exception as e2:
            err_payload = {
                "title": "–û—à–∏–±–∫–∞",
                "time": utc_now_iso(),
                "tag": "error",
                "answer": "–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–ø–∞—Ä—Å–∏—Ä—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¢–ó.",
                "steps": [],
                "warnings": [str(e2)],
                "need_clarification": False,
                "clarifying_question": "",
            }
            await safe_reply_text(update, json.dumps(err_payload, ensure_ascii=False, indent=2))
            return

    context.user_data["tz_done"] = True
    context.user_data["last_payload"] = payload
    await safe_reply_text(update, json.dumps(payload, ensure_ascii=False, indent=2))


async def handle_tz_message(update: Update, context: ContextTypes.DEFAULT_TYPE, user_text: str, temperature: float, model: str | None) -> None:
    if context.user_data.get("tz_done"):
        await safe_reply_text(update, "–¢–ó —É–∂–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –∑–∞–Ω–æ–≤–æ ‚Äî –≤—ã–∑–æ–≤–∏ /tz_creation_site.")
        return

    history = context.user_data.get("tz_history", [])
    questions_asked = int(context.user_data.get("tz_questions", 0))

    history.append({"role": "user", "content": user_text})

    force_finalize = questions_asked >= 4

    messages = [{"role": "system", "content": SYSTEM_PROMPT_TZ}]
    messages.extend(history)
    if force_finalize:
        messages.append({"role": "user", "content": "–°—Ñ–æ—Ä–º–∏—Ä—É–π —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –¢–ó –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON –ø–æ —Å—Ö–µ–º–µ."})

    try:
        raw = (chat_completion(messages, temperature=temperature, model=model) or "").strip()
    except Exception as e:
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
        return

    if looks_like_json(raw):
        await send_final_tz_json(update, context, raw, temperature=temperature, model=model)
        return

    history.append({"role": "assistant", "content": raw})
    context.user_data["tz_history"] = history
    context.user_data["tz_questions"] = questions_asked + 1
    await safe_reply_text(update, raw)


# -------------------- FOREST FLOW --------------------

async def handle_forest_message(update: Update, context: ContextTypes.DEFAULT_TYPE, user_text: str, temperature: float, model: str | None) -> None:
    if context.user_data.get("forest_done"):
        if user_asked_to_show_result(user_text):
            res = (context.user_data.get("forest_result") or "").strip()
            if res:
                await safe_reply_text(update, res)
            else:
                await safe_reply_text(update, "–†–∞—Å—á—ë—Ç –≥–æ—Ç–æ–≤, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω. –ó–∞–ø—É—Å—Ç–∏ /forest_split –∑–∞–Ω–æ–≤–æ.")
            return
        await safe_reply_text(update, "–†–∞—Å—á—ë—Ç —É–∂–µ –≥–æ—Ç–æ–≤. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –∑–∞–Ω–æ–≤–æ ‚Äî –≤—ã–∑–æ–≤–∏ /forest_split.")
        return

    history = context.user_data.get("forest_history", [])
    questions_asked = int(context.user_data.get("forest_questions", 0))

    history.append({"role": "user", "content": user_text})

    force_finalize = questions_asked >= 6

    messages = [{"role": "system", "content": SYSTEM_PROMPT_FOREST}]
    messages.extend(history)
    if force_finalize:
        messages.append({
            "role": "user",
            "content": "–•–≤–∞—Ç–∏—Ç –≤–æ–ø—Ä–æ—Å–æ–≤. –°—Ñ–æ—Ä–º–∏—Ä—É–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å. –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ FINAL, –¥–∞–ª–µ–µ –æ—Ç—á—ë—Ç —Ç–µ–∫—Å—Ç–æ–º."
        })

    try:
        raw = (chat_completion(messages, temperature=temperature, model=model) or "").strip()
    except Exception as e:
        await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
        return

    if not raw:
        await safe_reply_text(update, "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏.")
        return

    if is_forest_final(raw):
        report = strip_forest_final_marker(raw)
        if not report:
            await safe_reply_text(update, "–û—à–∏–±–∫–∞: —Ñ–∏–Ω–∞–ª –±–µ–∑ –æ—Ç—á—ë—Ç–∞. –ó–∞–ø—É—Å—Ç–∏ /forest_split –∑–∞–Ω–æ–≤–æ.")
            return

        context.user_data["forest_done"] = True
        context.user_data["forest_result"] = report
        history.append({"role": "assistant", "content": raw})
        context.user_data["forest_history"] = history
        await safe_reply_text(update, report)
        return

    history.append({"role": "assistant", "content": raw})
    context.user_data["forest_history"] = history
    context.user_data["forest_questions"] = questions_asked + 1
    await safe_reply_text(update, raw)


# -------------------- MAIN TEXT HANDLER --------------------

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not update.message:
        return

    text = (update.message.text or "").strip()
    if not text:
        return

    # –ø–µ—Ä–µ—Ö–≤–∞—Ç —Ä–µ–∂–∏–º–∞ —Ç–µ—Å—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
    if await tokens_test_intercept(update, context, text):
        return

    await update.message.chat.send_action("typing")

    mode = get_mode(context)
    chat_id = int(update.effective_chat.id) if update.effective_chat else 0
    temperature = get_temperature(context, chat_id)
    memory_enabled = get_memory_enabled(context, chat_id)
    model = get_model(context, chat_id) or None

    if mode == "tz":
        await handle_tz_message(update, context, text, temperature=temperature, model=model)
        return

    if mode == "forest":
        await handle_forest_message(update, context, text, temperature=temperature, model=model)
        return

    # ---- CHAT MODES (text/thinking/experts/summary) ----
    if mode in ("text", "thinking", "experts", MODE_SUMMARY):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∞–π—Ç–æ–º –≤ —Ä–µ–∂–∏–º–µ summary
        if mode == MODE_SUMMARY:
            # –ö–æ–º–∞–Ω–¥–∞ "–ü–æ–¥–Ω–∏–º–∏ —Å–∞–π—Ç"
            if re.match(r"^(?:–ø–æ–¥–Ω–∏–º–∏|–ø–æ–¥–Ω—è—Ç—å|–∑–∞–ø—É—Å—Ç–∏|–∑–∞–ø—É—Å—Ç–∏—Ç—å)\s+—Å–∞–π—Ç$", text, re.IGNORECASE):
                await update.message.chat.send_action("typing")
                result = await site_up_via_mcp()
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –≤ –ë–î
                db_add_message(chat_id, mode, "user", text)
                db_add_message(chat_id, mode, "assistant", result)
                # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
                try:
                    maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                except Exception:
                    pass
                await safe_reply_text(update, result)
                return
            
            # –ö–æ–º–∞–Ω–¥–∞ "–°–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω" –∏–ª–∏ "–°–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç"
            if re.match(r"^(?:—Å–¥–µ–ª–∞–π|—Å–æ–∑–¥–∞–π|—Å–Ω—è—Ç—å)\s+—Å–∫—Ä–∏–Ω(?:—à–æ—Ç)?$", text, re.IGNORECASE):
                await update.message.chat.send_action("typing")
                screenshot_path = await site_screenshot_via_mcp()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ –ë–î
                db_add_message(chat_id, mode, "user", text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ø–æ–ª—É—á–µ–Ω
                if screenshot_path and Path(screenshot_path).exists():
                    try:
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º PNG —Ñ–∞–π–ª –≤ Telegram
                        with open(screenshot_path, "rb") as f:
                            await update.message.reply_document(
                                document=f,
                                filename="site.png",
                                caption="üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–∞–π—Ç–∞"
                            )
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ë–î
                        db_add_message(chat_id, mode, "assistant", f"–°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ–∑–¥–∞–Ω: {screenshot_path}")
                    except Exception as e:
                        logger.exception(f"Failed to send screenshot: {e}")
                        await safe_reply_text(update, f"–°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ–∑–¥–∞–Ω, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å: {e}")
                else:
                    # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                    db_add_message(chat_id, mode, "assistant", screenshot_path)
                    await safe_reply_text(update, screenshot_path)
                
                # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
                try:
                    maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                except Exception:
                    pass
                return
            
            # –ö–æ–º–∞–Ω–¥–∞ "–û—Å—Ç–∞–Ω–æ–≤–∏ —Å–∞–π—Ç"
            if re.match(r"^(?:–æ—Å—Ç–∞–Ω–æ–≤–∏|–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å|–≤—ã–∫–ª—é—á–∏|–≤—ã–∫–ª—é—á–∏—Ç—å)\s+—Å–∞–π—Ç$", text, re.IGNORECASE):
                await update.message.chat.send_action("typing")
                result = await site_down_via_mcp()
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –≤ –ë–î
                db_add_message(chat_id, mode, "user", text)
                db_add_message(chat_id, mode, "assistant", result)
                # –°–∂–∏–º–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
                try:
                    maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                except Exception:
                    pass
                await safe_reply_text(update, result)
                return
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–≥–æ–¥—ã –≤ —Ä–µ–∂–∏–º–µ summary (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ü–æ–≥–æ–¥–∞ –ú–æ—Å–∫–≤–∞" –∏–ª–∏ "–ü–æ–≥–æ–¥–∞ –°–∞–º–∞—Ä–∞")
        weather_request_handled = False
        if mode == MODE_SUMMARY:
            # –ü–∞—Ç—Ç–µ—Ä–Ω: "–ü–æ–≥–æ–¥–∞" + –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
            weather_match = re.match(r"^(?:–ø–æ–≥–æ–¥–∞|weather)\s+(.+)$", text, re.IGNORECASE)
            if weather_match:
                city = weather_match.group(1).strip()
                if city:
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–≥–æ–¥—É —á–µ—Ä–µ–∑ MCP –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    weather_text = await get_weather_via_mcp(city)
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –≤ –ë–î –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
                    db_add_message(chat_id, mode, "user", text)
                    db_add_message(chat_id, mode, "assistant", weather_text)
                    
                    # –í—ã–∑—ã–≤–∞–µ–º —Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ (–∫–∞–∫ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π)
                    try:
                        maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
                    except Exception:
                        pass
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–≥–æ–¥–æ–π
                    await safe_reply_text(update, weather_text)
                    weather_request_handled = True
                    return

        if mode == "thinking":
            system_prompt = SYSTEM_PROMPT_THINKING
        elif mode == "experts":
            system_prompt = SYSTEM_PROMPT_EXPERTS
        else:
            system_prompt = SYSTEM_PROMPT_TEXT

        if memory_enabled:
            # NEW: summary-context builder
            if mode == MODE_SUMMARY:
                messages = build_messages_with_summary(system_prompt, chat_id=chat_id, mode=MODE_SUMMARY)
            else:
                messages = build_messages_with_db_memory(system_prompt, chat_id=chat_id)
        else:
            messages = [{"role": "system", "content": system_prompt}]  # –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏

        messages.append({"role": "user", "content": text})

        # SUMMARY: –Ω—É–∂–µ–Ω raw, —á—Ç–æ–±—ã –≤–∑—è—Ç—å usage
        if mode == MODE_SUMMARY:
            try:
                data = chat_completion_raw(messages, temperature=temperature, model=model)
                answer = _get_content_from_raw(data)
                pt, ct, tt = _get_usage_tokens(data)
                req_id = str(data.get("id") or "").strip()
            except Exception as e:
                await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
                return

            answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

            # –ø–∏—à–µ–º –≤ –ë–î (summary –≤—Å–µ–≥–¥–∞ —Å –ø–∞–º—è—Ç—å—é)
            db_add_message(chat_id, mode, "user", text)
            db_add_message(chat_id, mode, "assistant", answer)

            try:
                maybe_compress_history(chat_id, temperature=0.0, mode=MODE_SUMMARY)
            except Exception:
                pass

            # 1) –æ—Ç–≤–µ—Ç
            def fmt(x: int | None) -> str:
                return str(x) if isinstance(x, int) else "n/a"

            rid = f", id={req_id}" if req_id else ""
            combined = f"{answer}\n\n–¢–æ–∫–µ–Ω—ã: –∑–∞–ø—Ä–æ—Å={fmt(pt)}, –æ—Ç–≤–µ—Ç={fmt(ct)}, –≤—Å–µ–≥–æ={fmt(tt)}{rid}"
            await safe_reply_text(update, combined)
            return


        # –ù–ï summary ‚Äî –∫–∞–∫ –±—ã–ª–æ
        try:
            answer = (chat_completion(messages, temperature=temperature, model=model) or "").strip()
        except Exception as e:
            await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
            return

        answer = answer or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

        # –ø–∏—à–µ–º –≤ –ë–î —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–∞–º—è—Ç—å –≤–∫–ª—é—á–µ–Ω–∞
        if memory_enabled:
            db_add_message(chat_id, mode, "user", text)
            db_add_message(chat_id, mode, "assistant", answer)

        await safe_reply_text(update, answer)
        return

    # ---- JSON MODE (–±–µ–∑ –ø–∞–º—è—Ç–∏) ----
    raw = ""
    try:
        raw = chat_completion(
            [
                {"role": "system", "content": SYSTEM_PROMPT_JSON},
                {"role": "user", "content": text},
            ],
            temperature=temperature,
            model=model,
        ) or ""

        json_str = extract_json_object(raw)
        data = json.loads(json_str)
        payload = normalize_payload(data)

    except Exception:
        try:
            fixed_raw = repair_json_with_model(SYSTEM_PROMPT_JSON, raw or text, temperature=temperature, model=model)
            json_str = extract_json_object(fixed_raw)
            data = json.loads(json_str)
            payload = normalize_payload(data)
        except Exception as e2:
            err_payload = {
                "title": "–û—à–∏–±–∫–∞",
                "time": utc_now_iso(),
                "tag": "error",
                "answer": "–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–ø–∞—Ä—Å–∏—Ä—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç.",
                "steps": [],
                "warnings": [str(e2)],
                "need_clarification": False,
                "clarifying_question": "",
            }
            await safe_reply_text(update, json.dumps(err_payload, ensure_ascii=False, indent=2))
            return

    context.user_data["last_payload"] = payload
    await safe_reply_text(update, json.dumps(payload, ensure_ascii=False, indent=2))


# -------------------- ERROR HANDLER --------------------

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.exception("Unhandled error: %s", context.error)
    if isinstance(update, Update) and update.message:
        await safe_reply_text(update, f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {type(context.error).__name__}: {context.error}")


# -------------------- BOT COMMANDS MENU --------------------

async def post_init(app: Application) -> None:
    cmds = [
        BotCommand("start", "–°—Ç–∞—Ä—Ç"),
        BotCommand("help", "–°–ø—Ä–∞–≤–∫–∞"),
        BotCommand("mode_text", f"–†–µ–∂–∏–º text + {_short_model_name(OPENROUTER_MODEL)}"),
        BotCommand("mode_json", "JSON –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"),
        BotCommand("mode_summary", f"–†–µ–∂–∏–º summary + {_short_model_name(OPENROUTER_MODEL)}"),
        BotCommand("summary_debug", "–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ summary (—Ä–µ–∂–∏–º summary)"),
        BotCommand("tz_creation_site", "–°–æ–±—Ä–∞—Ç—å –¢–ó –Ω–∞ —Å–∞–π—Ç (–∏—Ç–æ–≥ JSON)"),
        BotCommand("forest_split", "–ö—Ç–æ –∫–æ–º—É –¥–æ–ª–∂–µ–Ω (–∏—Ç–æ–≥ —Ç–µ–∫—Å—Ç)"),
        BotCommand("thinking_model", "–†–µ—à–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ"),
        BotCommand("expert_group_model", "–ì—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"),
        BotCommand("tokens_test", "–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤ (–≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º)"),
        BotCommand("tokens_next", "–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø"),
        BotCommand("tokens_stop", "–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–≤–æ–¥–∫–∞ –∏ –≤—ã—Ö–æ–¥"),
        BotCommand("ch_temperature", "–ü–æ–∫–∞–∑–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: /ch_temperature 0.7)"),
        BotCommand("ch_memory", "–ü–∞–º—è—Ç—å –í–ö–õ/–í–´–ö–õ (–ø—Ä–∏–º–µ—Ä: /ch_memory off)"),
        BotCommand("clear_memory", "–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞"),
        BotCommand("weather_sub", "–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É (–ø—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30)"),
        BotCommand("weather_sub_stop", "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É –Ω–∞ –ø–æ–≥–æ–¥—É (–ø—Ä–∏–º–µ—Ä: /weather_sub_stop –ú–æ—Å–∫–≤–∞)"),
        BotCommand("digest", "–£—Ç—Ä–µ–Ω–Ω—è—è —Å–≤–æ–¥–∫–∞: –ø–æ–≥–æ–¥–∞ + –Ω–æ–≤–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)"),
    ]

    if MODEL_GLM:
        cmds.append(BotCommand("model_glm", f"–ú–æ–¥–µ–ª—å: {_short_model_name(MODEL_GLM)}"))
    if MODEL_GEMMA:
        cmds.append(BotCommand("model_gemma", f"–ú–æ–¥–µ–ª—å: {_short_model_name(MODEL_GEMMA)}"))

    await app.bot.set_my_commands(cmds)


def run() -> None:
    init_db()

    request = HTTPXRequest(
        connect_timeout=20.0,
        read_timeout=60.0,
        write_timeout=60.0,
        pool_timeout=20.0,
    )

    app = (
        Application.builder()
        .token(TELEGRAM_BOT_TOKEN)
        .request(request)
        .post_init(post_init)
        .build()
    )

    # deps –¥–ª—è tokens_test.py (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É)
    app.bot_data["tokens_deps"] = {
        "get_temperature": get_temperature,
        "get_model": get_model,
        "get_effective_model": get_effective_model,
        "SYSTEM_PROMPT_TEXT": SYSTEM_PROMPT_TEXT,
        "safe_reply_text": safe_reply_text,
    }

    app.add_error_handler(error_handler)

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))

    app.add_handler(CommandHandler("tokens_test", tokens_test_cmd))
    app.add_handler(CommandHandler("tokens_next", tokens_next_cmd))
    app.add_handler(CommandHandler("tokens_stop", tokens_stop_cmd))

    app.add_handler(CommandHandler("ch_temperature", ch_temperature_cmd))
    app.add_handler(CommandHandler("ch_memory", ch_memory_cmd))
    app.add_handler(CommandHandler("clear_memory", clear_memory_cmd))

    if MODEL_GLM:
        app.add_handler(CommandHandler("model_glm", model_glm_cmd))
    if MODEL_GEMMA:
        app.add_handler(CommandHandler("model_gemma", model_gemma_cmd))

    app.add_handler(CommandHandler("mode_text", mode_text_cmd))
    app.add_handler(CommandHandler("mode_json", mode_json_cmd))
    app.add_handler(CommandHandler("mode_summary", mode_summary_cmd))
    app.add_handler(CommandHandler("summary_debug", summary_debug_cmd))
    app.add_handler(CommandHandler("tz_creation_site", tz_creation_site_cmd))
    app.add_handler(CommandHandler("forest_split", forest_split_cmd))
    app.add_handler(CommandHandler("thinking_model", thinking_model_cmd))
    app.add_handler(CommandHandler("expert_group_model", expert_group_model_cmd))
    app.add_handler(CommandHandler("weather_sub", weather_sub_cmd))
    app.add_handler(CommandHandler("weather_sub_stop", weather_sub_stop_cmd))
    app.add_handler(CommandHandler("digest", digest_cmd))


    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    run()
