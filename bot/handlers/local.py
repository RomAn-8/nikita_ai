"""Local model and analyze handlers."""

import re
from telegram import Update
from telegram.ext import ContextTypes

from ..core.errors import safe_reply_text
from ..handlers.base import Handler
from ..config import OLLAMA_MODEL, OLLAMA_TEMPERATURE, OLLAMA_NUM_CTX, OLLAMA_NUM_PREDICT, OLLAMA_SYSTEM_PROMPT
from ..utils.helpers import reset_tz, reset_forest
from ..services.llm import send_to_ollama, get_ollama_settings_display


class LocalModelHandler(Handler):
    """Handler for /local_model command."""
    
    async def handle(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle /local_model command."""
        if not update.message:
            return
        
        if not context.args:
            agent_context = self.get_agent_context(update, context)
            agent_context.update_mode("local_model")
            reset_tz(context)
            reset_forest(context)
            
            settings_text = _get_ollama_settings_display(context.user_data)
            
            await safe_reply_text(
                update,
                f"‚úÖ –†–µ–∂–∏–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Ollama –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω.\n"
                f"–ú–æ–¥–µ–ª—å: {OLLAMA_MODEL}\n\n"
                f"{settings_text}\n\n"
                f"–¢–µ–ø–µ—Ä—å –≤—Å–µ –≤–∞—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å.\n"
                f"–î–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /mode_text –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ä–µ–∂–∏–º.\n\n"
                f"üí° –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫:\n"
                f"‚Ä¢ \"–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É 0.7\"\n"
                f"‚Ä¢ \"–∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ 4096\"\n"
                f"‚Ä¢ \"–∏–∑–º–µ–Ω–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ 512\"\n"
                f"‚Ä¢ \"–ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏\"\n"
                f"‚Ä¢ \"—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏\""
            )
            return
        
        text = " ".join(context.args).strip().lower()
        
        temp_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É\s+([\d.]+)', text)
        if temp_match:
            try:
                new_temp = float(temp_match.group(1))
                if 0.0 <= new_temp <= 2.0:
                    context.user_data["ollama_temperature"] = new_temp
                    await safe_reply_text(update, f"‚úÖ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {new_temp}")
                else:
                    await safe_reply_text(update, "‚ùå –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0.0 –¥–æ 2.0")
                return
            except ValueError:
                await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã")
                return
        
        ctx_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ\s+–æ–∫–Ω–æ\s+(\d+)', text)
        if ctx_match:
            try:
                new_ctx = int(ctx_match.group(1))
                if new_ctx > 0:
                    context.user_data["ollama_num_ctx"] = new_ctx
                    await safe_reply_text(update, f"‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ {new_ctx}")
                else:
                    await safe_reply_text(update, "‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
                return
            except ValueError:
                await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞")
                return
        
        predict_match = re.search(r'–∏–∑–º–µ–Ω–∏—Ç—å\s+–º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é\s+–¥–ª–∏–Ω—É\s+–æ—Ç–≤–µ—Ç–∞\s+(\d+)', text)
        if predict_match:
            try:
                new_predict = int(predict_match.group(1))
                if new_predict > 0:
                    context.user_data["ollama_num_predict"] = new_predict
                    await safe_reply_text(update, f"‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {new_predict}")
                else:
                    await safe_reply_text(update, "‚ùå –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
                return
            except ValueError:
                await safe_reply_text(update, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞")
                return
        
        if "–ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏" in text or "–ø–æ–∫–∞–∑–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" in text:
            settings_text = get_ollama_settings_display(context.user_data)
            await safe_reply_text(update, settings_text)
            return
        
        if "—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏" in text or "—Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" in text:
            context.user_data.pop("ollama_temperature", None)
            context.user_data.pop("ollama_num_ctx", None)
            context.user_data.pop("ollama_num_predict", None)
            context.user_data.pop("ollama_system_prompt", None)
            settings_text = get_ollama_settings_display(context.user_data)
            await safe_reply_text(update, f"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–±—Ä–æ—à–µ–Ω—ã –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:\n\n{settings_text}")
            return
        
        question = " ".join(context.args)
        
        try:
            answer = await send_to_ollama(question, context.user_data)
            await safe_reply_text(update, answer)
        except ValueError as e:
            await safe_reply_text(update, f"‚ùå {str(e)}\n\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–∞–Ω–¥–æ–π: —Å–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
        except ConnectionError as e:
            await safe_reply_text(update, f"‚ùå {str(e)}")
        except Exception as e:
            await safe_reply_text(update, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")


class AnalyzeHandler(Handler):
    """Handler for /analyze command."""
    
    async def handle(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle /analyze command."""
        if not update.message:
            return
        
        agent_context = self.get_agent_context(update, context)
        agent_context.update_mode("analyze")
        context.user_data.pop("analyze_json_content", None)
        
        await safe_reply_text(update, "–û—Ç–ø—Ä–∞–≤—å JSON —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")


async def local_model_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Command function for /local_model."""
    handler = LocalModelHandler()
    await handler.handle(update, context)


async def analyze_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Command function for /analyze."""
    handler = AnalyzeHandler()
    await handler.handle(update, context)
