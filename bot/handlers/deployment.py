"""Deployment handlers."""

import os
import asyncio
from pathlib import Path
from telegram import Update
from telegram.ext import ContextTypes

from ..core.errors import safe_reply_text
from ..handlers.base import Handler
from ..mcp_client import (
    deploy_check_docker, deploy_upload_image, deploy_load_image,
    deploy_create_compose, deploy_create_env, deploy_start_bot,
    deploy_check_container, deploy_stop_bot
)
from ..config import (
    OPENROUTER_API_KEY, OPENROUTER_MODEL, EMBEDDING_MODEL,
    RAG_SIM_THRESHOLD, RAG_TOP_K, OLLAMA_MODEL, OLLAMA_TIMEOUT,
    OLLAMA_TEMPERATURE, OLLAMA_NUM_CTX, OLLAMA_NUM_PREDICT, OLLAMA_SYSTEM_PROMPT
)
import logging

logger = logging.getLogger(__name__)


class DeployBotHandler(Handler):
    """Handler for /deploy_bot command."""
    
    async def handle(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle /deploy_bot command."""
        if not update.message:
            return
        
        try:
            deploy_ssh_host = os.getenv("DEPLOY_SSH_HOST", "").strip()
            deploy_ssh_port = int(os.getenv("DEPLOY_SSH_PORT", "22"))
            deploy_ssh_username = os.getenv("DEPLOY_SSH_USERNAME", "").strip()
            deploy_ssh_password = os.getenv("DEPLOY_SSH_PASSWORD", "").strip()
            deploy_image_tar_path = os.getenv("DEPLOY_IMAGE_TAR_PATH", "").strip()
            deploy_remote_path = os.getenv("DEPLOY_REMOTE_PATH", "/opt/nikita_ai").strip()
            deploy_bot_token = os.getenv("DEPLOY_BOT_TOKEN", "").strip()
            
            deploy_openrouter_api_key = OPENROUTER_API_KEY
            deploy_openrouter_model = OPENROUTER_MODEL
            deploy_embedding_model = EMBEDDING_MODEL
            deploy_rag_sim_threshold = str(RAG_SIM_THRESHOLD)
            deploy_rag_top_k = str(RAG_TOP_K)
            deploy_ollama_base_url = "http://127.0.0.1:11434"
            deploy_ollama_model = OLLAMA_MODEL
            deploy_ollama_timeout = str(OLLAMA_TIMEOUT)
            deploy_ollama_temperature = str(OLLAMA_TEMPERATURE)
            deploy_ollama_num_ctx = str(OLLAMA_NUM_CTX)
            deploy_ollama_num_predict = str(OLLAMA_NUM_PREDICT)
            deploy_ollama_system_prompt = OLLAMA_SYSTEM_PROMPT
            
            missing_vars = []
            if not deploy_ssh_host:
                missing_vars.append("DEPLOY_SSH_HOST")
            if not deploy_ssh_username:
                missing_vars.append("DEPLOY_SSH_USERNAME")
            if not deploy_ssh_password:
                missing_vars.append("DEPLOY_SSH_PASSWORD")
            if not deploy_image_tar_path:
                missing_vars.append("DEPLOY_IMAGE_TAR_PATH")
            if not deploy_bot_token:
                missing_vars.append("DEPLOY_BOT_TOKEN")
            
            if missing_vars:
                await safe_reply_text(
                    update,
                    f"âŒ ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ:\n" + "\n".join(f"â€¢ {var}" for var in missing_vars)
                )
                return
            
            image_path = Path(deploy_image_tar_path)
            if not image_path.exists():
                await safe_reply_text(update, f"âŒ Ð¤Ð°Ð¹Ð» Ð¾Ð±Ñ€Ð°Ð·Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {deploy_image_tar_path}")
                return
            
            image_name = "nikita_ai"
            image_tag = "latest"
            
            await safe_reply_text(update, "ðŸš€ ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð´ÐµÐ¿Ð»Ð¾Ð¹ Ð±Ð¾Ñ‚Ð° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€...")
            
            await safe_reply_text(update, "ðŸ“¦ ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÑŽ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Docker Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ...")
            docker_result = await deploy_check_docker(deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password)
            if not docker_result or docker_result.get("status") != "installed":
                error_msg = docker_result.get("message", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°") if docker_result else "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ Docker"
                await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ Docker: {error_msg}")
                return
            await safe_reply_text(update, f"âœ… {docker_result.get('message', 'Docker Ð³Ð¾Ñ‚Ð¾Ð²')}")
            
            remote_image_path = f"{deploy_remote_path}/{image_path.name}"
            await safe_reply_text(update, f"ðŸ“¤ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¾Ð±Ñ€Ð°Ð· Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€: {deploy_image_tar_path}...")
            upload_result = await deploy_upload_image(
                deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
                deploy_image_tar_path, remote_image_path
            )
            if not upload_result or upload_result.get("status") != "success":
                error_msg = upload_result.get("message", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°") if upload_result else "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¾Ð±Ñ€Ð°Ð·Ð°"
                await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¾Ð±Ñ€Ð°Ð·Ð°: {error_msg}")
                return
            await safe_reply_text(update, f"âœ… {upload_result.get('message', 'ÐžÐ±Ñ€Ð°Ð· Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½')}")
            
            await safe_reply_text(update, "ðŸ³ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¾Ð±Ñ€Ð°Ð· Ð² Docker...")
            load_result = await deploy_load_image(
                deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
                remote_image_path
            )
            if not load_result or load_result.get("status") != "success":
                error_msg = load_result.get("message", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°") if load_result else "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¾Ð±Ñ€Ð°Ð·Ð° Ð² Docker"
                await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¾Ð±Ñ€Ð°Ð·Ð° Ð² Docker: {error_msg}")
                return
            await safe_reply_text(update, f"âœ… {load_result.get('message', 'ÐžÐ±Ñ€Ð°Ð· Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½ Ð² Docker')}")
            
            compose_path = f"{deploy_remote_path}/docker-compose.yml"
            compose_content = f"""services:
  bot:
    image: {image_name}:{image_tag}
    container_name: nikita_ai_bot
    restart: unless-stopped
    network_mode: host
    env_file:
      - .env
    environment:
      - DB_PATH=/app/data/bot_memory.sqlite3
    volumes:
      - ./data:/app/data
      - ./digests:/app/bot/digests
    user: "0:0"
"""
            await safe_reply_text(update, "ðŸ“ Ð¡Ð¾Ð·Ð´Ð°ÑŽ docker-compose.yml...")
            compose_result = await deploy_create_compose(
                deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
                compose_content, compose_path
            )
            if not compose_result or compose_result.get("status") != "success":
                error_msg = compose_result.get("message", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°") if compose_result else "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ docker-compose.yml"
                await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ docker-compose.yml: {error_msg}")
                return
            compose_msg = compose_result.get('message', 'docker-compose.yml ÑÐ¾Ð·Ð´Ð°Ð½')
            if compose_result.get('skipped'):
                await safe_reply_text(update, f"â­ï¸ {compose_msg}")
            else:
                await safe_reply_text(update, f"âœ… {compose_msg}")
            
            env_path = f"{deploy_remote_path}/.env"
            env_content = f"""TELEGRAM_BOT_TOKEN={deploy_bot_token}
OPENROUTER_API_KEY={deploy_openrouter_api_key}
OPENROUTER_MODEL={deploy_openrouter_model}
EMBEDDING_MODEL={deploy_embedding_model}
RAG_SIM_THRESHOLD={deploy_rag_sim_threshold}
RAG_TOP_K={deploy_rag_top_k}
OLLAMA_BASE_URL={deploy_ollama_base_url}
OLLAMA_MODEL={deploy_ollama_model}
OLLAMA_TIMEOUT={deploy_ollama_timeout}
OLLAMA_TEMPERATURE={deploy_ollama_temperature}
OLLAMA_NUM_CTX={deploy_ollama_num_ctx}
OLLAMA_NUM_PREDICT={deploy_ollama_num_predict}
OLLAMA_SYSTEM_PROMPT={deploy_ollama_system_prompt}
"""
            await safe_reply_text(update, "ðŸ“ ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÑŽ .env Ñ„Ð°Ð¹Ð»...")
            env_result = await deploy_create_env(
                deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
                env_content, env_path
            )
            if not env_result or env_result.get("status") != "success":
                error_msg = env_result.get("message", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°") if env_result else "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ .env Ñ„Ð°Ð¹Ð»Ð°"
                await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ .env Ñ„Ð°Ð¹Ð»Ð°: {error_msg}")
                return
            env_msg = env_result.get('message', '.env Ñ„Ð°Ð¹Ð» ÑÐ¾Ð·Ð´Ð°Ð½')
            if env_result.get('skipped'):
                await safe_reply_text(update, f"â­ï¸ {env_msg}")
            else:
                await safe_reply_text(update, f"âœ… {env_msg}")
            
            await safe_reply_text(update, "ðŸš€ Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð±Ð¾Ñ‚Ð°...")
            start_result = await deploy_start_bot(
                deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
                compose_path
            )
            if not start_result or start_result.get("status") != "success":
                error_msg = start_result.get("message", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°") if start_result else "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ Ð±Ð¾Ñ‚Ð°"
                await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ Ð±Ð¾Ñ‚Ð°: {error_msg}")
                return
            
            await asyncio.sleep(3)
            
            await safe_reply_text(update, "ðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÑŽ ÑÑ‚Ð°Ñ‚ÑƒÑ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð°...")
            container_result = await deploy_check_container(
                deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password
            )
            
            if container_result:
                container_status = container_result.get("container_status", "Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾")
                container_list = container_result.get("container_list", "")
                container_id = container_result.get("container_id", "")
                logs = container_result.get("logs", "")
                logs_preview = logs[-1000:] if len(logs) > 1000 else logs
                
                status_msg = f"âœ… Ð”ÐµÐ¿Ð»Ð¾Ð¹ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!\n\n"
                status_msg += f"Ð‘Ð¾Ñ‚ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ {deploy_ssh_host}\n"
                status_msg += f"ÐŸÑƒÑ‚ÑŒ: {deploy_remote_path}\n"
                status_msg += f"ÐšÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€: nikita_ai_bot\n"
                status_msg += f"Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: {container_status}\n"
                if container_id:
                    status_msg += f"ID: {container_id}\n"
                if container_list:
                    status_msg += f"\nÐ’ÑÐµ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ñ‹:\n{container_list}\n"
                status_msg += f"\nÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð»Ð¾Ð³Ð¸:\n```\n{logs_preview}\n```"
                
                await safe_reply_text(update, status_msg)
            else:
                await safe_reply_text(
                    update,
                    f"âœ… Ð”ÐµÐ¿Ð»Ð¾Ð¹ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!\n\n"
                    f"Ð‘Ð¾Ñ‚ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ {deploy_ssh_host}\n"
                    f"ÐŸÑƒÑ‚ÑŒ: {deploy_remote_path}\n"
                    f"ÐšÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€: nikita_ai_bot\n\n"
                    f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð»Ð¾Ð³Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð°. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ: docker logs nikita_ai_bot"
                )
            
        except Exception as e:
            logger.exception(f"Error in deploy_bot_cmd: {e}")
            await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´ÐµÐ¿Ð»Ð¾Ðµ: {e}")


class StopBotHandler(Handler):
    """Handler for /stop_bot command."""
    
    async def handle(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle /stop_bot command."""
        if not update.message:
            return
        
        try:
            deploy_ssh_host = os.getenv("DEPLOY_SSH_HOST", "").strip()
            deploy_ssh_port = int(os.getenv("DEPLOY_SSH_PORT", "22"))
            deploy_ssh_username = os.getenv("DEPLOY_SSH_USERNAME", "").strip()
            deploy_ssh_password = os.getenv("DEPLOY_SSH_PASSWORD", "").strip()
            deploy_remote_path = os.getenv("DEPLOY_REMOTE_PATH", "/opt/nikita_ai").strip()
            
            if not deploy_ssh_host or not deploy_ssh_username or not deploy_ssh_password:
                await safe_reply_text(
                    update,
                    "âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: ÐÐµ Ð·Ð°Ð´Ð°Ð½Ñ‹ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð´ÐµÐ¿Ð»Ð¾Ñ.\n\n"
                    "ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð·Ð°Ð´Ð°Ñ‚ÑŒ:\n"
                    "- DEPLOY_SSH_HOST\n"
                    "- DEPLOY_SSH_USERNAME\n"
                    "- DEPLOY_SSH_PASSWORD"
                )
                return
            
            compose_path = f"{deploy_remote_path}/docker-compose.yml"
            
            args = context.args or []
            remove_volumes = "--remove-volumes" in args or "-v" in args
            remove_images = "--remove-images" in args or "-i" in args
            
            if not args:
                await safe_reply_text(
                    update,
                    f"âš ï¸ ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð±Ð¾Ñ‚Ð° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ {deploy_ssh_host}\n\n"
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:\n"
                    f"/stop_bot - Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€\n"
                    f"/stop_bot -v - Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¸ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ\n"
                    f"/stop_bot -i - Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¸ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¾Ð±Ñ€Ð°Ð·Ñ‹\n"
                    f"/stop_bot -v -i - Ð¿Ð¾Ð»Ð½Ð¾Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ"
                )
                return
            
            await safe_reply_text(update, "ðŸ›‘ ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÑŽ Ð±Ð¾Ñ‚Ð°...")
            
            stop_result = await deploy_stop_bot(
                deploy_ssh_host, deploy_ssh_port, deploy_ssh_username, deploy_ssh_password,
                compose_path, remove_volumes=remove_volumes, remove_images=remove_images
            )
            
            if stop_result and stop_result.get("status") == "success":
                message = stop_result.get("message", "Ð‘Ð¾Ñ‚ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½")
                await safe_reply_text(update, f"âœ… {message}")
            else:
                error_msg = stop_result.get("message", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°") if stop_result else "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ Ð±Ð¾Ñ‚Ð°"
                await safe_reply_text(update, f"âŒ {error_msg}")
            
        except Exception as e:
            logger.exception(f"Error in stop_bot_cmd: {e}")
            await safe_reply_text(update, f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ Ð±Ð¾Ñ‚Ð°: {e}")


async def deploy_bot_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Command function for /deploy_bot."""
    handler = DeployBotHandler()
    await handler.handle(update, context)


async def stop_bot_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Command function for /stop_bot."""
    handler = StopBotHandler()
    await handler.handle(update, context)
