"""Help command handler."""

from telegram import Update
from telegram.ext import ContextTypes

from ..core.errors import safe_reply_text
from ..handlers.base import Handler
from ..services.context_manager import get_temperature, get_memory_enabled, get_model
from ..services.memory import add_message
from ..services.database import db_add_message
from ..services.llm import call_llm
from ..config import OPENROUTER_MODEL, RAG_SIM_THRESHOLD, RAG_TOP_K, EMBEDDING_MODEL
from ..embeddings import search_relevant_chunks, has_embeddings, list_indexed_documents
from ..mcp_client import get_git_branch
from ..utils.text import _short_model_name
from ..core.prompts import SYSTEM_PROMPT_TEXT
from ..services.database import build_messages_with_db_memory
from ..config import MODEL_GLM, MODEL_GEMMA, PR_REVIEW_AVAILABLE


class HelpHandler(Handler):
    """Handler for /help command."""
    
    async def handle(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle /help command."""
        if not update.message:
            return
        
        # If no args - show command list
        if not context.args:
            lines = [
                "üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:",
                "",
                "üîß –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∂–∏–º—ã:",
                f"/mode_text ‚Äî —Ä–µ–∂–∏–º text + {_short_model_name(OPENROUTER_MODEL)}",
                "/mode_json ‚Äî JSON –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
                f"/mode_summary ‚Äî —Ä–µ–∂–∏–º summary + {_short_model_name(OPENROUTER_MODEL)} (—Å–∂–∞—Ç–∏–µ –∏—Å—Ç–æ—Ä–∏–∏)",
                "/summary_debug ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ summary (—Ä–µ–∂–∏–º summary)",
            ]
            
            if MODEL_GLM:
                lines.append(f"/model_glm ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GLM)}")
            if MODEL_GEMMA:
                lines.append(f"/model_gemma ‚Äî –º–æ–¥–µ–ª—å {_short_model_name(MODEL_GEMMA)}")
            
            lines.extend([
                "",
                "ü§ñ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã:",
                "/tz_creation_site ‚Äî —Å–æ–±—Ä–∞—Ç—å –¢–ó –Ω–∞ —Å–∞–π—Ç (–∏—Ç–æ–≥ JSON)",
                "/forest_split ‚Äî –∫—Ç–æ –∫–æ–º—É –¥–æ–ª–∂–µ–Ω (–∏—Ç–æ–≥ —Ç–µ–∫—Å—Ç)",
                "/thinking_model ‚Äî —Ä–µ—à–∞—Ç—å –ø–æ—à–∞–≥–æ–≤–æ",
                "/expert_group_model ‚Äî –≥—Ä—É–ø–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤",
                "",
                "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:",
                "/ch_temperature ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø—Ä–∏–º–µ—Ä: /ch_temperature 0.7)",
                "/ch_memory ‚Äî –ø–∞–º—è—Ç—å –í–ö–õ/–í–´–ö–õ (–ø—Ä–∏–º–µ—Ä: /ch_memory off)",
                "/clear_memory ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å —á–∞—Ç–∞",
                "/clear_embeddings ‚Äî —É–¥–∞–ª–∏—Ç—å –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏",
                "",
                "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:",
                "/tokens_test ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤ (–≤–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º)",
                "/tokens_next ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø",
                "/tokens_stop ‚Äî —Ç–µ—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤: —Å–≤–æ–¥–∫–∞ –∏ –≤—ã—Ö–æ–¥",
                "",
                "üìö RAG –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏:",
                "/embed_create ‚Äî —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ .md —Ñ–∞–π–ª–∞ (—Å–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª)",
                "/embed_docs ‚Äî —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ docs/",
                "/rag_model ‚Äî —Ä–µ–∂–∏–º RAG",
                "",
                "üí¨ –°–ª–æ–≤–µ—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã (–≤ —Ä–µ–∂–∏–º–µ RAG):",
                "‚Ä¢ \"RAG+—Ñ–∏–ª—å—Ç—Ä\" –∏–ª–∏ \"RAG+—Ñ–∏–ª—å—Ç—Ä <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –ø–æ–∏—Å–∫ —Å –ø–æ—Ä–æ–≥–æ–º –ø–æ—Ö–æ–∂–µ—Å—Ç–∏",
                "‚Ä¢ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞\" –∏–ª–∏ \"RAG –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –ø–æ–∏—Å–∫ –±–µ–∑ –ø–æ—Ä–æ–≥–∞",
                "‚Ä¢ \"–ë–µ–∑ RAG\" –∏–ª–∏ \"–ë–µ–∑ RAG <–≤–æ–ø—Ä–æ—Å>\" ‚Äî –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –ø–æ–∏—Å–∫–∞",
                "",
                "üå§Ô∏è –ü–æ–≥–æ–¥–∞:",
                "/weather_sub ‚Äî –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ–≥–æ–¥—É (–ø—Ä–∏–º–µ—Ä: /weather_sub –ú–æ—Å–∫–≤–∞ 30)",
                "/weather_sub_stop ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É (–ø—Ä–∏–º–µ—Ä: /weather_sub_stop –ú–æ—Å–∫–≤–∞)",
                "/digest ‚Äî —É—Ç—Ä–µ–Ω–Ω—è—è —Å–≤–æ–¥–∫–∞: –ø–æ–≥–æ–¥–∞ + –Ω–æ–≤–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä: /digest –ú–æ—Å–∫–≤–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)",
                "",
                "üë§ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –∑–∞–ø–∏—Å–∏:",
                "/register ‚Äî —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è (–ø—Ä–∏–º–µ—Ä: /register –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á +79991234567)",
                "/unregister ‚Äî —É–¥–∞–ª–∏—Ç—å —Å–≤–æ—é —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é",
                "/train_signup ‚Äî –∑–∞–ø–∏—Å—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É (–ø—Ä–∏–º–µ—Ä: /train_signup 15-02-2026 18:00 [–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ])",
                "/train_move ‚Äî –ø–µ—Ä–µ–Ω–æ—Å –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_move 1 16-02-2026 19:00)",
                "/train_cancel ‚Äî –æ—Ç–º–µ–Ω–∞ –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä: /train_cancel 1)",
                "/support ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å RAG (–ø—Ä–∏–º–µ—Ä: /support –º–æ–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∑–∞–ø–∏—Å—å?)",
                "/task_list ‚Äî —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞—á–∞–º–∏ (—Å–ª–æ–≤–µ—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è, –ø—Ä–æ—Å–º–æ—Ç—Ä–∞, —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–¥–∞—á)",
                "",
                "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç:",
                "/voice ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ –æ—Ç–≤–µ—Ç–∞, –¥–ª—è –≤—ã—Ö–æ–¥–∞: /stop –∏–ª–∏ /cancel)",
                "",
                "ü§ñ –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏:",
                "/local_model ‚Äî —Ä–µ–∂–∏–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Ollama (–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞, –∑–∞—Ç–µ–º –ø—Ä–æ—Å—Ç–æ –ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è)",
                "/analyze ‚Äî –∞–Ω–∞–ª–∏–∑ JSON —Ñ–∞–π–ª–æ–≤ —Å –ª–æ–≥–∞–º–∏ —á–µ—Ä–µ–∑ Ollama (–æ—Ç–ø—Ä–∞–≤—å—Ç–µ JSON —Ñ–∞–π–ª, –∑–∞—Ç–µ–º –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å)",
                "/me ‚Äî –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ–º–∞–Ω–¥—ã: '–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å', '–ö—Ç–æ —è?')",
                "",
                "üöÄ –î–µ–ø–ª–æ–π:",
                "/deploy_bot ‚Äî –¥–µ–ø–ª–æ–π –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä (—Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)",
                "/stop_bot ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–æ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ (–æ–ø—Ü–∏–∏: -v —É–¥–∞–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ, -i —É–¥–∞–ª–∏—Ç—å –æ–±—Ä–∞–∑—ã)",
            ])
            
            if PR_REVIEW_AVAILABLE:
                lines.append("/review_pr ‚Äî –∞–Ω–∞–ª–∏–∑ Pull Request (–ø—Ä–∏–º–µ—Ä: /review_pr 123)")
            
            lines.extend([
                "",
                "üìñ –°–ø—Ä–∞–≤–∫–∞:",
                "/help ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–µ–∫—Ç–µ",
            ])
            
            await safe_reply_text(update, "\n".join(lines))
            return
        
        # If args provided - use RAG to answer question
        question_text = " ".join(context.args).strip()
        if not question_text:
            await safe_reply_text(update, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–µ–∫—Ç–µ. –ü—Ä–∏–º–µ—Ä: /help –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç RAG —Å–∏—Å—Ç–µ–º–∞?")
            return
        
        await update.message.chat.send_action("typing")
        
        agent_context = self.get_agent_context(update, context)
        chat_id = agent_context.chat_id
        temperature = agent_context.temperature
        memory_enabled = agent_context.memory_enabled
        model = agent_context.model
        
        # Check for embeddings
        if not has_embeddings(EMBEDDING_MODEL):
            await safe_reply_text(
                update,
                "‚ö†Ô∏è –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.\n"
                "–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /embed_create.\n"
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ README.md –∏ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ docs/ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."
            )
            return
        
        # Check if question is about git branch
        question_lower = question_text.lower()
        is_git_branch_question = any(keyword in question_lower for keyword in [
            "–≤–µ—Ç–∫–∞", "–≤–µ—Ç–∫—É", "–≤–µ—Ç–∫–∏", "branch", "git branch", "—Ç–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞",
            "–∫–∞–∫–∞—è –≤–µ—Ç–∫–∞", "–∫–∞–∫—É—é –≤–µ—Ç–∫—É", "–∫–∞–∫–∏–µ –≤–µ—Ç–∫–∏"
        ])
        
        # Get git branch via MCP (optional)
        git_branch_name = None
        try:
            git_branch_name = await get_git_branch()
        except Exception as e:
            import logging
            logging.getLogger(__name__).debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å git –≤–µ—Ç–∫—É —á–µ—Ä–µ–∑ MCP: {e}")
        
        # If question about git branch and we got info - answer directly
        if is_git_branch_question and git_branch_name:
            await safe_reply_text(update, f"üåø –¢–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞ git: `{git_branch_name}`")
            return
        elif is_git_branch_question and not git_branch_name:
            await safe_reply_text(
                update,
                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ç–∫—É git.\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:\n"
                "- MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω (http://127.0.0.1:8000/mcp)\n"
                "- –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è MCP —Å–µ—Ä–≤–µ—Ä–∞ —è–≤–ª—è–µ—Ç—Å—è git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º"
            )
            return
        
        # Search relevant chunks
        filtered_chunks = []
        try:
            relevant_chunks = search_relevant_chunks(
                question_text,
                model=EMBEDDING_MODEL,
                top_k=RAG_TOP_K,
                min_similarity=RAG_SIM_THRESHOLD,
                apply_threshold=True
            )
            filtered_chunks = [chunk for chunk in relevant_chunks if chunk["similarity"] >= RAG_SIM_THRESHOLD]
            
            if not filtered_chunks:
                relevant_chunks_no_threshold = search_relevant_chunks(
                    question_text,
                    model=EMBEDDING_MODEL,
                    top_k=RAG_TOP_K * 2,
                    min_similarity=0.0,
                    apply_threshold=False
                )
                filtered_chunks = [chunk for chunk in relevant_chunks_no_threshold if chunk["similarity"] > 0.3]
        except Exception as e:
            import logging
            logging.getLogger(__name__).exception(f"Error searching relevant chunks: {e}")
            await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {e}")
            return
        
        if not filtered_chunks:
            indexed_docs = list_indexed_documents(EMBEDDING_MODEL)
            error_msg = "‚ö†Ô∏è –ù–µ –Ω–∞—à–ª–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å."
            if indexed_docs:
                error_msg += f"\n\n–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: {', '.join(indexed_docs[:5])}"
                if len(indexed_docs) > 5:
                    error_msg += f" –∏ –µ—â–µ {len(indexed_docs) - 5}"
            else:
                error_msg += "\n\n–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
                error_msg += "- `/embed_create` –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ README.md\n"
                error_msg += "- `/embed_docs` –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–∞–ø–∫–∏ docs/"
            error_msg += "\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é."
            await safe_reply_text(update, error_msg)
            return
        
        # Build context for LLM
        context_parts = ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞:\n"]
        for i, chunk in enumerate(filtered_chunks, 1):
            context_parts.append(f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} (doc_name={chunk['doc_name']}, chunk_index={chunk['chunk_index']}, score={chunk['similarity']:.4f})]:")
            context_parts.append(chunk["text"])
            context_parts.append("")
        
        context_parts.append(f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –ø—Ä–æ–µ–∫—Ç–µ: {question_text}")
        if git_branch_name:
            context_parts.append(f"\n–¢–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞ git: {git_branch_name}")
        context_parts.append("\n–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤—ã—à–µ.")
        context_parts.append("–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞, —É–∫–∞–∂–∏ —ç—Ç–æ –≤ –æ—Ç–≤–µ—Ç–µ.")
        
        user_content = "\n".join(context_parts)
        
        # Build messages for LLM
        system_prompt = SYSTEM_PROMPT_TEXT
        if memory_enabled:
            messages = build_messages_with_db_memory(system_prompt, chat_id=chat_id)
        else:
            messages = [{"role": "system", "content": system_prompt}]
        
        messages.append({"role": "user", "content": user_content})
        
        # Call LLM
        try:
            answer = call_llm(messages, temperature=temperature, model=model)
            answer = (answer or "").strip() or "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."
        except Exception as e:
            await safe_reply_text(update, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
            return
        
        # Save to DB
        mode = "text"
        db_add_message(chat_id, mode, "user", f"/help {question_text}")
        db_add_message(chat_id, mode, "assistant", answer)
        
        await safe_reply_text(update, answer)


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Command function for /help."""
    handler = HelpHandler()
    await handler.handle(update, context)
